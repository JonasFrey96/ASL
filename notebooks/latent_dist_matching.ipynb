{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "from random import randint\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "__all__ = ['distribution_matching']\n",
    "\n",
    "def compute_metric_class_similarity_score(candidate_feature, buffer_features ):\n",
    "    \"\"\"\n",
    "    candidate_feature: 128 dimensional\n",
    "    buffer_features: Nx128 all features from the targeted classes\n",
    "    \"\"\"\n",
    "#     import pdb \n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    metric = F.cosine_similarity(\n",
    "        candidate_feature[None,:,None].repeat(buffer_features.shape[0],1,1).type(torch.float32), \n",
    "        buffer_features[:,:,None].type(torch.float32),\n",
    "        dim=1, eps=1e-6) \n",
    "#     print(metric)\n",
    "#     import pdb \n",
    "#     pdb.set_trace()\n",
    "    return metric.min()\n",
    "    \n",
    "def compute_image_similiarity_score(candidate_image_features, buffer_features_all):\n",
    "    \"\"\"\n",
    "    candidate_feature: Cx128 dimensional\n",
    "    buffer_features: NBxCx128  \n",
    "    \"\"\"\n",
    "    image_score = 0\n",
    "    valid_features_can = candidate_image_features.sum(dim=1) != 0 \n",
    "    \n",
    "    # buffer_features_of_interrest = buffer_features[NB,valid_features_can] # we only have to look at a subset of features\n",
    "    indices_valid_features_can = torch.where(valid_features_can != False)\n",
    "    print(\"TRES\", indices_valid_features_can)\n",
    "    for cla in indices_valid_features_can[0].tolist():\n",
    "        features = buffer_features_all[:,cla,:]\n",
    "        valid_buffer_elements_for_this_cla = features.sum(dim=1) != 0\n",
    "        if valid_buffer_elements_for_this_cla.sum() == 0:\n",
    "            # this class does not exist in the buffer so far\n",
    "            image_score += 0\n",
    "        else:\n",
    "            valid_cla_buffer_features = features[valid_buffer_elements_for_this_cla]\n",
    "            score = compute_metric_class_similarity_score(candidate_image_features[cla], \n",
    "                                                          valid_cla_buffer_features)\n",
    "            image_score += score\n",
    "    \n",
    "    #similarity lower is better\n",
    "    \n",
    "    #normalize the image score to not favour images with less classes\n",
    "    image_score /= indices_valid_features_can.sum()\n",
    "    \n",
    "    return image_score\n",
    "    \n",
    "\n",
    "def interclass_dissimilarity(latent_features, label_dist, K_return=50, iterations= 1000, early_stopping = 0.00001):\n",
    "    \"\"\" returns k indexe from globale_indices such that the returned indexed match the total feature distribution the best\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    latent_features: torch.tensor NRxCx128 \n",
    "    label_dist : torch.tensor NRxC\n",
    "    K_return : int, optional\n",
    "            number of returned indices, by default 50\n",
    "    \"\"\"\n",
    "    label_probs = label_dist.sum(dim=0) / label_dist.sum(dim=[0,1])\n",
    "    allowed_selection = torch.ceil( label_probs * K_return )\n",
    "    indices = torch.where( allowed_selection != 0)\n",
    "    res = torch.argsort(allowed_selection, dim=-1, descending=False)\n",
    "    appearing_classes = allowed_selection[res] != 0\n",
    "    \n",
    "    rising_indices_class_count = res[appearing_classes] \n",
    "    rising_value_class_count = allowed_selection[rising_indices_class_count]\n",
    "    \n",
    "    print(rising_value_class_count)\n",
    "    print(rising_indices_class_count)\n",
    "    aggregator_array = torch.zeros(allowed_selection.shape[0] )\n",
    "    \n",
    "    init_selection = torch.randperm( latent_features.shape[0] )[:K_return]\n",
    "    buffer_features_all = latent_features[init_selection,:,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for nyu_id, nr_to_select in zip(rising_indices_class_count.list(),rising_value_class_count.list())    \n",
    "      \n",
    "    for i in range(10):\n",
    "        swap_candidate = torch.randint(0,K_return, (1,))\n",
    "        while True:\n",
    "            replacement_candidate = torch.randint(0,latent_features.shape[0],(1,))[0]\n",
    "            if replacement_candidate not in init_selection:\n",
    "                break\n",
    "        \n",
    "        init_selection\n",
    "        print(swap_candidate, replacement_candidate)\n",
    "        compute_image_similiarity_score( latent_features[replacement_candidate], buffer_features_all)\n",
    "        \n",
    "        \n",
    "    # print(allowed_selection, indices)\n",
    "    return True, True\n",
    "\n",
    "#     return selected, old_metric\n",
    "selected, metric = interclass_dissimilarity(latent_features, label_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions we have to answer:\n",
    "\"\"\"\n",
    "Should we use the pixelwise information -> We kind of do this already when we check how we sample it\n",
    "-> Can we utlize the network to check if the selected sample is a good one. \n",
    "-> Could we just maximize the intra class dissimilarity \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# def test():\n",
    "if True:\n",
    "    from PIL import Image\n",
    "    import os, sys\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    os.chdir('/home/jonfrey/ASL')\n",
    "    sys.path.append('/home/jonfrey/ASL')\n",
    "    sys.path.append('/home/jonfrey/ASL/src')\n",
    "    from visu import Visualizer\n",
    "    \n",
    "    vis = Visualizer('/home/jonfrey/tmp', logger=None, epoch=0, store=True, num_classes=41)\n",
    "\n",
    "    label_dist = torch.load( '/media/scratch1/jonfrey/models/master_thesis/dev/uncertainty_integration3/labels_tensor_0.pt')\n",
    "    globale_indices = torch.load( '/media/scratch1/jonfrey/models/master_thesis/dev/uncertainty_integration3/indices_tensor_0.pt')\n",
    "    latent_features = torch.load( '/media/scratch1/jonfrey/models/master_thesis/dev/uncertainty_integration3/latent_feature_tensor_0.pt')\n",
    "    \n",
    "    st = time.time()\n",
    "    selected, metric = interclass_dissimilarity(latent_features, label_dist)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    selected_globale_indices = globale_indices[selected]\n",
    "    t =  time.time()-st\n",
    "    print(selected.sum(), metric, 'Total time',t)                 \n",
    "    # features = features_l.clone()\n",
    "    # globale_indices = globale_indices_l.clone()\n",
    "    # K_return=50\n",
    "    # print(new_metric)\n",
    "    \n",
    "    res = vis.plot_bar(features.sum(dim=0), x_label='Label', y_label='Count',\n",
    "            sort=False, reverse=True, title= 'All', \n",
    "            tag=f'Pixelwise_Class_Count_Task', method='left',jupyter=True)\n",
    "    display(Image.fromarray(res))\n",
    "\n",
    "\n",
    "    res = vis.plot_bar(features[selected,:].sum(dim=0), x_label='Label', y_label='Count',\n",
    "            sort=False, reverse=True, title= 'Selected',\n",
    "            tag=f'Pixelwise_Class_Count_Task', method='left',jupyter=True)\n",
    "\n",
    "    \n",
    "    display(Image.fromarray(res))\n",
    "\n",
    "# test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
