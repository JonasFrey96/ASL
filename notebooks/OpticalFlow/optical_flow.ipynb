{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('core')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from raft import RAFT\n",
    "from utils import flow_viz\n",
    "from utils.utils import InputPadder\n",
    "from torchvision import transforms as tf \n",
    "import torch\n",
    "import time \n",
    "from pathlib import Path\n",
    "import imageio\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Import image\n",
    "image = cv2.imread(\"input_path\")\n",
    "#Show the image with matplotlib\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "def demo(args):\n",
    "    model = torch.nn.DataParallel(RAFT(args))\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "    model = model.module\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images = glob.glob(os.path.join(args.path, '*.png')) + \\\n",
    "                 glob.glob(os.path.join(args.path, '*.jpg'))\n",
    "        \n",
    "        images = sorted(images)\n",
    "\n",
    "        for imfile1, imfile2 in zip(images[:-1], images[1:]):\n",
    "            image1 = load_image(imfile1)\n",
    "            image2 = load_image(imfile2)\n",
    "\n",
    "            padder = InputPadder(image1.shape)\n",
    "            image1, image2 = padder.pad(image1, image2)\n",
    "\n",
    "            flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n",
    "            # viz(image1, flow_up)\n",
    "\n",
    "di = {\n",
    "    'model': 'models/raft-kitti.pth',\n",
    "    'small': False,\n",
    "    'mixed_precision': True,\n",
    "    'alternate_corr': False,\n",
    "}\n",
    "    \n",
    "class DotDict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "args = DotDict(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import matplotlib\n",
    "\n",
    "base = \"/home/jonfrey/datasets/scannet\"\n",
    "image_pths = [str(p) for p in glob( base+'/**/*.jpg', recursive=True ) if str(p).find('color') != -1]\n",
    "fun = lambda x : x.split('/')[-3][-7:] + '_'+ str( \"0\"*(6-len( x.split('/')[-1][:-4]))) + x.split('/')[-1][:-4]  \n",
    "image_pths.sort(key=fun)\n",
    "image_pths = [i for i in  image_pths if i.find(\"scene0000_00\") != -1]\n",
    "image_pths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args['model'] = '/media/scratch1/jonfrey/results/rpose/models/raft-sintel.pth'\n",
    "DEVICE = 'cuda:0'\n",
    "image_pths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(RAFT(args))\n",
    "model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "model = model.module\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-glucose",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tra = torch.nn.Sequential(\n",
    "tf.Resize((484,648))\n",
    ")\n",
    "tra_up = torch.nn.Sequential(\n",
    "tf.Resize((968, 1296))\n",
    ")\n",
    "\n",
    "def writeFlowKITTI(filename, uv):\n",
    "    uv = 64.0 * uv + 2**15\n",
    "    valid = np.ones([uv.shape[0], uv.shape[1], 1])\n",
    "    uv = np.concatenate([uv, valid], axis=-1).astype(np.uint16)\n",
    "    cv2.imwrite(filename, uv[..., ::-1])\n",
    "\n",
    "def viz(img, flo):\n",
    "    img = img[0].permute(1,2,0).cpu().numpy()\n",
    "    flo = flo[0].permute(1,2,0).cpu().numpy()\n",
    "    \n",
    "    # map flow to rgb image\n",
    "    flo = flow_viz.flow_to_image(flo)\n",
    "    img_flo = np.concatenate([img, flo], axis=0)\n",
    "    plt.imshow(img_flo/255 )\n",
    "    plt.show()\n",
    "\n",
    "def load_image(imfile):\n",
    "    img = np.array(Image.open(imfile)).astype(np.uint8)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    print(img.shape)\n",
    "    img = img[:, 12:-12, 12:-12]\n",
    "    return img[None].to(DEVICE)\n",
    "\n",
    "\n",
    "def estimate_flow(f1, f2, name, model):\n",
    "    image1 = load_image(f1)\n",
    "    image2 = load_image(f2)\n",
    "    \n",
    "    flow_low, flow_up = model(image1, image2, iters=12, test_mode=True)\n",
    "\n",
    "    ls = ['/'] + f1.split('/')[:-2]+[ name,\"flow_low_\" +f1.split('/')[-1][:-4]+'.png' ]\n",
    "    p1 = os.path.join(*ls )\n",
    "    ls = ['/'] + f1.split('/')[:-2]+[ name,\"flow_up_\" + f1.split('/')[-1][:-4]+'.png' ]\n",
    "    p2 = os.path.join(*ls )\n",
    "    \n",
    "    direct =  os.path.join(*ls[:-1] )\n",
    "    Path( str(direct) ).mkdir(parents=False, exist_ok=True)\n",
    "    print( p1 )\n",
    "    writeFlowKITTI(p1, flow_low.detach().cpu()[0].permute(1,2,0) )\n",
    "    writeFlowKITTI(p2, flow_up.detach().cpu()[0].permute(1,2,0) )\n",
    "    \n",
    "    \n",
    "sub= 10\n",
    "scene = \"xxx\"\n",
    "old_frame = None\n",
    "base_name = f\"flow_sub_{sub}\"\n",
    "st = time.time()\n",
    "with torch.no_grad():\n",
    "    for j, i in enumerate( image_pths):\n",
    "        if i.split('/')[-3] == scene:\n",
    "            if int( i.split('/')[-1][:-4] ) % sub == 0:\n",
    "                #do flow\n",
    "                estimate_flow(old_frame, i, base_name, model)            \n",
    "                old_frame = i\n",
    "        else:\n",
    "            scene = i.split('/')[-3]\n",
    "            old_frame = i\n",
    "        if j > 1000000:\n",
    "            break\n",
    "        if j % 100 == 0:\n",
    "            print(j, '   ', time.time()-st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
