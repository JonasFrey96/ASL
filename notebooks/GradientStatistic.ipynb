{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "### Gradient Statistics:\n",
    "- Layerwise/Modulewise Norm, Varaince\n",
    "- Gradient Variance/Mean for same samples with different augmentation\n",
    "- Gradient after each Epoch on same Task\n",
    "- Gradient over the corse of training a full network\n",
    "- Can we use the Data statistics of the augmented gradients to clustet examples ? \n",
    "\n",
    "### Observation:\n",
    "- Does a high loss mean we get high mean gradient values: \n",
    "    - Exp take full dataset. \n",
    "    - Augment each sample 10 times\n",
    "    - Compute statistics\n",
    "    - Logg also mean and variance value\n",
    "    - Compute scatter plot of this\n",
    "        \n",
    "- Compare the variance of data augmentation to the full dataset:\n",
    "    - We assume the variance of the dataset should be largern than the variance of the sample sample\n",
    "    \n",
    "- Can we observe that after the first layer the network gets invariant to for example color jolor jit ? \n",
    "    \n",
    "    \n",
    "### Where we should have a closer look:\n",
    "- Is there a way to compare samples based on there loss function ? \n",
    "    - Benefits:\n",
    "        - Feature Maps are not invariant to translation (Therefore we used the variation where we assosicated a feature vector to a label). If we look at the loss induced on the parameters ths should be more sophisticated ?\n",
    "        - If two samples would change the model in the same ways -> They might contain the same constraints\n",
    "        - Better metric for measuring similarity\n",
    "        \n",
    "- So what we currently do when we replay samples is to force the weight update to include the gradient induced by the replay sampled within the memory. \n",
    "- Can we compute the gradient update over mutiple samples and store them as a \"Key Direction in Weight Space for a given Task\" or are we losing a lot of desirable properties of SGD by doing so ? This GradientAccumulation could we added when learning a new task. \n",
    "- Will this stay fixed over a lot of update steps ?\n",
    "\n",
    "\n",
    "# GEM:\n",
    "- Store samples in memory\n",
    "- Compute gradient over each element in memory.\n",
    "- Solve LQ-Programm to project gradient st. when NN is assumed to be linear no constraint is violated. \n",
    "- New gradient smallest distance to \"original\" gradient based on L2 Norm non violating the constraint.\n",
    "\n",
    "- For each update requires gradient computation over full memory.\n",
    "\n",
    "# A-GEM:\n",
    "- Store samples in memory\n",
    "- Compute gradient of memory batch\n",
    "- Compute gradient of new samples\n",
    "- Apply update rule based on inner product of new and old batch (simple gradient projection)\n",
    "\n",
    "- For each update requires gradient comutation over batch in memory.\n",
    "\n",
    "\n",
    "# Proposed: \n",
    "- Put samples into memory based on gradient (keep most restrictive ones around)\n",
    "- Can we keep the gradient fixed over training for an epoch for small batch sizes ?\n",
    "- Can we compute a desired \"Weight\" for each sample in the memory ? Apply GD-Times for a Single Sample until good loss achieved -> store the resulting weight as a target weight for this Sample ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gradient statistic -> over full dataset\n",
    "# For each weight -> mean and std.\n",
    "\n",
    "import os\n",
    "import sys \n",
    "os.chdir(os.path.join(os.getenv('HOME'), 'ASL'))\n",
    "sys.path.insert(0, os.path.join(os.getenv('HOME'), 'ASL'))\n",
    "sys.path.append(os.path.join(os.path.join(os.getenv('HOME'), 'ASL') + '/src'))\n",
    "\n",
    "from torchvision import transforms as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils_asl import file_path, load_yaml\n",
    "from models_asl import FastSCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP MODEL\n",
    "\n",
    "eval_cfg_path=\"cfg/eval/eval.yml\"\n",
    "env_cfg_path = os.path.join('cfg/env', os.environ['ENV_WORKSTATION_NAME']+ '.yml')\n",
    "env_cfg = load_yaml(env_cfg_path)\t\n",
    "eval_cfg = load_yaml(eval_cfg_path)\n",
    "device= \"cuda\"\n",
    "model = FastSCNN(**eval_cfg['model']['cfg'])\n",
    "\n",
    "\n",
    "p = os.path.join( env_cfg['base'], eval_cfg['checkpoint_load'])\n",
    "print(p)\n",
    "\n",
    "def load(model, p):\n",
    "    if os.path.isfile( p ):\n",
    "        res = torch.load(p)\n",
    "        new_statedict = {}\n",
    "        for k in res['state_dict'].keys():\n",
    "            if k.find('model.') != -1: \n",
    "                new_statedict[ k[6:]] = res['state_dict'][k]\n",
    "        res = model.load_state_dict( new_statedict, strict=True)\n",
    "        print('Restoring weights: ' + str(res))\n",
    "    else:\n",
    "        raise Exception('Checkpoint not a file')\n",
    "    return model\n",
    "model = load(model,p)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_asl import get_dataset\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "\n",
    "# SETUP DATALOADER\n",
    "dataset_test = get_dataset(\n",
    "  **eval_cfg['dataset'],\n",
    "  env = env_cfg,\n",
    "  output_trafo = None\n",
    "  )\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test,\n",
    "  shuffle = False,\n",
    "  num_workers = 0,\n",
    "  pin_memory = True,\n",
    "  batch_size = 2, \n",
    "  drop_last = True)\n",
    "\n",
    "globale_idx_to_image_path = dataset_test.image_pths\n",
    "from visu import Visualizer\n",
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import TaskCreator\n",
    "from datasets_asl import get_dataloader_train, eval_lists_into_dataloaders\n",
    "\n",
    "def get_mutiple_dataloaders(exp, env, train=True):\n",
    "    tc = TaskCreator(**exp['task_generator'],output_size=exp['dataset']['output_size'])\n",
    "    ret_list = []\n",
    "    for t in tc:\n",
    "        task, eval_lists = t\n",
    "        dataloader_train, dataloader_buffer= get_dataloader_train(d_train= task.dataset_train_cfg,\n",
    "                                                              env=env,exp = exp)\n",
    "        if train: \n",
    "            ret_list.append( dataloader_train )\n",
    "        else: \n",
    "            # RETURNS ALL VALIDATION DATALOADERS\n",
    "            return eval_lists_into_dataloaders(eval_lists, env=env, exp=exp)\n",
    "    return ret_list\n",
    "        \n",
    "dataloader_list = get_mutiple_dataloaders(exp = eval_cfg , env = env_cfg, train=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [ '/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task0-epoch=29--step=016259.ckpt',\n",
    "'/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task1-epoch=63--step=030846.ckpt',\n",
    "'/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task2-epoch=95--step=045503.ckpt',\n",
    "'/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task3-epoch=135--step=060290.ckpt']\n",
    "print( model_paths )\n",
    "for f in dataloader_list:\n",
    "    print(f.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_grad( named_params ):\n",
    "    summary_grad = {}\n",
    "    for i, (n,p) in enumerate( named_params ):\n",
    "        mod = n.split('.')[1]\n",
    "        key = mod + '_weight' if n.find('conv.') != -1 else  mod + '_bias'    \n",
    "        if key not in summary_grad.keys():\n",
    "            summary_grad[key] = [torch.abs( p.grad.view(-1).detach() )]\n",
    "        else:\n",
    "            summary_grad[key].append( torch.abs(p.grad.view(-1).detach()) )\n",
    "    for k in summary_grad.keys():\n",
    "        summary_grad[k] = torch.cat( summary_grad[k] )\n",
    "\n",
    "    return summary_grad\n",
    "\n",
    "def get_grad_indidividual( named_params ):\n",
    "    summary_grad = {}\n",
    "    for i, (n,p) in enumerate( named_params ):\n",
    "        summary_grad[n] = [torch.abs( p.grad.view(-1).detach() )]\n",
    "\n",
    "    for k in summary_grad.keys():\n",
    "        summary_grad[k] = torch.cat( summary_grad[k] )\n",
    "\n",
    "    return summary_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welfords Online Algorithm\n",
    "https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm\n",
    "\n",
    "Online mean and variance estimation:\n",
    "\n",
    "$\n",
    "\\bar x_n = \\frac{(n-1) \\, \\bar x_{n-1} + x_n}{n} = \\bar x_{n-1} + \\frac{x_n - \\bar x_{n-1}}{n} \\!\n",
    "$\n",
    "\n",
    "$\n",
    "{\\displaystyle s_{n}^{2}={\\frac {n-2}{n-1}}\\,s_{n-1}^{2}+{\\frac {(x_{n}-{\\bar {x}}_{n-1})^{2}}{n}}=s_{n-1}^{2}+{\\frac {(x_{n}-{\\bar {x}}_{n-1})^{2}}{n}}-{\\frac {s_{n-1}^{2}}{n-1}},\\quad n>1}\n",
    "{\\displaystyle \\sigma _{n}^{2}={\\frac {(n-1)\\,\\sigma _{n-1}^{2}+(x_{n}-{\\bar {x}}_{n-1})(x_{n}-{\\bar {x}}_{n})}{n}}=\\sigma _{n-1}^{2}+{\\frac {(x_{n}-{\\bar {x}}_{n-1})(x_{n}-{\\bar {x}}_{n})-\\sigma _{n-1}^{2}}{n}}.}\n",
    "$\n",
    "\n",
    "$\n",
    "{\\displaystyle \\sigma _{n}^{2}={\\frac {(n-1)\\,\\sigma _{n-1}^{2}+(x_{n}-{\\bar {x}}_{n-1})(x_{n}-{\\bar {x}}_{n})}{n}}=\\sigma _{n-1}^{2}+{\\frac {(x_{n}-{\\bar {x}}_{n-1})(x_{n}-{\\bar {x}}_{n})-\\sigma _{n-1}^{2}}{n}}.}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_update(existingAggregate, newValue):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    count += 1\n",
    "    delta = newValue - mean\n",
    "    if delta.isnan().any():\n",
    "        print( \"count\", counte, \" is nan\")\n",
    "    \n",
    "    mean += delta / count\n",
    "    delta2 = newValue - mean\n",
    "    M2 += delta * delta2\n",
    "    return (count, mean, M2)\n",
    "\n",
    "# Retrieve the mean, variance and sample variance from an aggregate\n",
    "def t_finalize(existingAggregate):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    if count < 2:\n",
    "        return float(\"nan\")\n",
    "    else:\n",
    "        (mean, variance, sampleVariance) = (mean, M2 / count, M2 / (count - 1))\n",
    "        return (mean, variance, sampleVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_mean(dataloader_test, model, \n",
    "                 augmentation=True, nr_image_samples=1, accumulate_same_image= 50):\n",
    "    mean = None\n",
    "    count = {}\n",
    "    trafo = tf.Compose([\n",
    "      tf.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
    "      tf.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "    ])\n",
    "    for i in range(accumulate_same_image):\n",
    "        # SETUP DATALOADER\n",
    "        for j, batch in enumerate( dataloader_test ):\n",
    "#             try:\n",
    "#                 print( )\n",
    "#             except:\n",
    "\n",
    "            \n",
    "            \n",
    "            # START EVALUATION  \n",
    "            images = (batch[0]).cuda()\n",
    "            target = batch[1].cuda()\n",
    "            ori_img = batch[2]\n",
    "            replayed = batch[3]\n",
    "            BS = images.shape[0]\n",
    "            global_idx = batch[4] \n",
    "            \n",
    "            \n",
    "#             print(\"AugRun: \", i, \"Locale ID: \", j, \"Gloable ID: \", global_idx, \"Re: \", replayed, \"faild:\", target[target!=-1].sum())\n",
    "            if augmentation:\n",
    "                images = trafo(images)\n",
    "                \n",
    "            ret = model(images)\n",
    "            \n",
    "            loss = F.cross_entropy(ret[0], target, ignore_index=-1)\n",
    "            torch.autograd.backward(loss)\n",
    "\n",
    "            summary_grad = get_grad_indidividual( model.named_parameters() )\n",
    "\n",
    "            # Apply Welford\n",
    "            if mean is None:\n",
    "                # INIT RUNNING MEAN AND VARIANCE\n",
    "                mean = summary_grad \n",
    "                var = copy.deepcopy( summary_grad )\n",
    "                count = { n:0 for n in summary_grad.keys()}\n",
    "            else:\n",
    "                if count[list( summary_grad.keys())[0]] == 1:\n",
    "                    for k in var.keys():\n",
    "                        var[k] = torch.abs( var[k] - summary_grad[k])  \n",
    "                \n",
    "                for k in var.keys():\n",
    "                    # UPDATE RUNNING MEAN AND VARIANCE\n",
    "                    count[k], mean[k], var[k] = t_update( (count[k], mean[k], var[k]), \n",
    "                                                             summary_grad[k]  )\n",
    "            model.zero_grad()\n",
    "            \n",
    "            su = 0\n",
    "            for m in mean.values():\n",
    "                su += m.sum()\n",
    "                \n",
    "#             print( su )\n",
    "            \n",
    "            if j >= nr_image_samples:\n",
    "                model.zero_grad()\n",
    "                \n",
    "                break\n",
    "\n",
    "    sample_var = {}\n",
    "    # Finalize Welford \n",
    "    \n",
    "    for k in summary_grad.keys():\n",
    "        mean[k], var[k], sample_var[k] = t_finalize( (count[k], mean[k], var[k]) )\n",
    "    return mean, var\n",
    "\n",
    "def plot_summary(var, mean, mean_only= True, var_only=False, name=\"\" ):\n",
    "    layer_aggregation_var = []\n",
    "    layer_aggregation_mean = []\n",
    "    for k in var.keys():\n",
    "        layer_aggregation_var.append( var[k].mean() )\n",
    "        layer_aggregation_mean.append( mean[k].mean() )\n",
    "    if not mean_only and var_only:\n",
    "        return visu.plot_bar( layer_aggregation_var , x_label= \"Variance\", y_label='Layerwise-Mean of Grad-Varaince over Sampeles', title=\"Overview all Layers\" +name , sort=False, reverse=False, jupyter=False)\n",
    "    return visu.plot_bar( layer_aggregation_mean , x_label= \"Mean\", y_label='Layerwise-Mean of Grad-Mean over Sampeles', title=\"Overview all Layers\" + name , sort=False, reverse=False, jupyter=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataloader_list:\n",
    "    print(len(d),len( d.dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(4):\n",
    "    imgs = []\n",
    "    for i in range(4):\n",
    "        model = load(model,model_paths[i])\n",
    "        print( model_paths[i], \"batches\" , len(dataloader_list[jj]) )\n",
    "        var, mean = get_val_mean( dataloader_test= dataloader_list[jj], model = model, \n",
    "                                 augmentation=True, nr_image_samples=999, accumulate_same_image= 1)\n",
    "        imgs.append( plot_summary(var, mean, mean_only= False, var_only=True, name= f'Samples from Task {jj}. Model Checkpoint Task {i}' ) )\n",
    "\n",
    "    from torchvision.utils import make_grid\n",
    "    imgs_torch = [torch.from_numpy(i) for i in imgs]\n",
    "    imgs_torch = torch.stack( imgs_torch , dim = 0) \n",
    "    \n",
    "    grid_images = make_grid(imgs_torch.permute(0,3,1,2), nrow = 2,padding = 2,\n",
    "                  scale_each = False, pad_value = 0)\n",
    "    visu.plot_image( grid_images, jupyter= True, store=True, tag=f'100_samples_fro_task{jj}_with_augmentation_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.named_parameters():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"classifier_weight\"\n",
    "visu.plot_bar( mean[k][::100] , x_label= k, y_label='Mean Value', title=k, sort=False, reverse=False, jupyter=True)\n",
    "\n",
    "k = \"extractor_bias\"\n",
    "visu.plot_bar( mean[k][::100] , x_label= k, y_label='Mean Value', title=k, sort=False, reverse=False, jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean[k][::100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_welfords_online_algorithm():\n",
    "    # For a new value newValue, compute the new count, new mean, the new M2.\n",
    "    # mean accumulates the mean of the entire dataset\n",
    "    # M2 aggregates the squared distance from the mean\n",
    "    # count aggregates the number of samples seen so far\n",
    "    def update(existingAggregate, newValue):\n",
    "        (count, mean, M2) = existingAggregate\n",
    "        count += 1\n",
    "        delta = newValue - mean\n",
    "        mean += delta / count\n",
    "        delta2 = newValue - mean\n",
    "        M2 += delta * delta2\n",
    "        return (count, mean, M2)\n",
    "\n",
    "    # Retrieve the mean, variance and sample variance from an aggregate\n",
    "    def finalize(existingAggregate):\n",
    "        (count, mean, M2) = existingAggregate\n",
    "        if count < 2:\n",
    "            return float(\"nan\")\n",
    "        else:\n",
    "            (mean, variance, sampleVariance) = (mean, M2 / count, M2 / (count - 1))\n",
    "            return (mean, variance, sampleVariance)\n",
    "\n",
    "    rva = np.random.randint( 0,100, (1000) )\n",
    "    rv = rva.tolist()\n",
    "    a = update( (0, 0, 0), 10 )\n",
    "\n",
    "    for v in rv[1:]:\n",
    "        a = update( a, v)\n",
    "    a = finalize( a )\n",
    "    print(a)\n",
    "    print( rva.mean(), rva.std()**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track3",
   "language": "python",
   "name": "track3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
