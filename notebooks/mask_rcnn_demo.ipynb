{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import os\n",
    "import sys \n",
    "os.chdir(os.path.join(os.getenv('HOME'), 'ASL'))\n",
    "sys.path.insert(0, os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd() + '/src'))\n",
    "from visu import Visualizer\n",
    "\n",
    "#data\n",
    "img_pth = \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/738.jpg\"\n",
    "with open('/home/jonfrey/ASL/cfg/dataset/mappings/coco2017_nyu.pkl', 'rb') as handle:\n",
    "    mappings = pickle.load(handle)\n",
    "#visu\n",
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=True, num_classes=41)\n",
    "\n",
    "#model\n",
    "device = 'cpu'\n",
    "cfg = get_cfg()\n",
    "cfg['DEVICE'] = device\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "model = DefaultPredictor(cfg)\n",
    "model.model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "img = np.array( Image.open(img_pth) )\n",
    "outputs = model( img )\n",
    "\n",
    "_,H,W = outputs['instances'][0].pred_masks.shape\n",
    "\n",
    "label = torch.zeros( (H,W) ,dtype=torch.long )\n",
    "for i in range(len( outputs['instances'])):\n",
    "    inst = outputs['instances'][i]\n",
    "    if inst.scores[0] > 0.5:\n",
    "        coco200 = int( inst.pred_classes ) \n",
    "        label[ inst.pred_masks[0] ] = mappings['coco2017_id_nyu_id'][coco200] + 1\n",
    "        print( mappings[\"coco2017_id_name\"][str(coco200)], mappings['coco2017_id_nyu_name'][coco200], inst.scores[0])\n",
    "        \n",
    "visu.plot_detectron( img = img, label = label, tag='test', jupyter=True, store=False,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import cv2 as cv\n",
    "from scipy.interpolate import griddata\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "def txt_to_camera_info(cam_p, img_p):\n",
    "    data = np.loadtxt(cam_p)\n",
    "    img = imageio.imread(img_p)\n",
    "    return data[:3, :3], (img.shape[0],img.shape[1])\n",
    "\n",
    "class SuperpixelDepth():\n",
    "    def __init__(self, scannet_scene_dir= \"/home/jonfrey/Datasets/scannet/scans/scene0000_00\" ):\n",
    "        \n",
    "        self.K_image, size_image = txt_to_camera_info(f\"{scannet_scene_dir}/intrinsic/intrinsic_color.txt\", \n",
    "                                                 f\"{scannet_scene_dir}/color/0.jpg\")\n",
    "        self.K_depth, size_depth = txt_to_camera_info(f\"{scannet_scene_dir}/intrinsic/intrinsic_depth.txt\", \n",
    "                                                 f\"{scannet_scene_dir}/depth/0.png\")\n",
    "        # maps from image to depth\n",
    "        self.map1, self.map2 = cv.initUndistortRectifyMap(\n",
    "            self.K_depth,\n",
    "            np.array([0,0,0,0]),\n",
    "            np.eye(3),\n",
    "            self.K_image,\n",
    "            size_image[::-1], # (W,H)\n",
    "            cv.CV_32FC1)\n",
    "        \n",
    "        self.grid_x, self.grid_y = np.mgrid[0:size_image[0], 0:size_image[1]]\n",
    "        \n",
    "        points = np.stack([self.grid_x, self.grid_y],axis=2).reshape((-1,2))\n",
    "        self.h_p = np.ones( (points.shape[0],3) )\n",
    "        self.h_p[:,:2] = points \n",
    "        \n",
    "    def get( self, depth_p, n_segments = 100, min_depth= 0.3, max_depth=3 , cap = 3,tag=\"\", visu=None, plot=False, jupyter=False):\n",
    "        \n",
    "        depth = imageio.imread( depth_p )\n",
    "        img = imageio.imread( depth_p.replace(\"depth\",\"color\")[:-4]+'.jpg' )\n",
    "\n",
    "        depth_new = cv.remap( depth,\n",
    "                     self.map1,\n",
    "                     self.map2,\n",
    "                     interpolation=cv.INTER_NEAREST,\n",
    "                     borderMode=cv.BORDER_CONSTANT,\n",
    "                     borderValue=0)\n",
    "\n",
    "        values =depth_new.flatten()\n",
    "        m = np.logical_and( values > min_depth * 1000, values < max_depth * 1000)\n",
    "        depth_filled = griddata(self.h_p[:,:2] [m,:], values[m], (self.grid_x, self.grid_y), method='nearest')\n",
    "\n",
    "        \n",
    "        pcd = ((np.linalg.inv( self.K_image ) @ self.h_p.T) * ( depth_filled.reshape(-1) / 1000 )).T.reshape( (*depth_filled.shape,3))\n",
    "        pdc_clamp = (np.clip( pcd, a_min= -cap, a_max = cap) + cap )/(2*cap)\n",
    "        \n",
    "        segments_slic = slic( pdc_clamp*256, n_segments=n_segments, compactness=10, sigma=4,start_label=0)\n",
    "\n",
    "        \n",
    "        if plot:\n",
    "            img = visu.plot_depth(depth_filled/1000, vmin=min_depth, vmax= max_depth, tag=tag+\"_depth_filled\", jupyter=jupyter)\n",
    "            segments_slic_plot = np.mod( segments_slic, np.full( segments_slic.shape,40 ))\n",
    "            res = visu.plot_detectron( img = img, label = segments_slic_plot, tag=tag+\"_seg_depth\", jupyter=jupyter,alpha=0.1)\n",
    "        \n",
    "        return segments_slic\n",
    "        \n",
    "scannet_scene_dir= \"/home/jonfrey/Datasets/scannet/scans/scene0000_00\"\n",
    "spd = SuperpixelDepth( scannet_scene_dir )\n",
    "depth_p = os.path.join( scannet_scene_dir, \"depth\", \"0.png\")\n",
    "spd.get( depth_p, plot=False )     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "\n",
    "class Oracle():\n",
    "    def __init__(self):\n",
    "        self.jupyter = False\n",
    "        self.store = True\n",
    "        \n",
    "        with open('/home/jonfrey/ASL/cfg/dataset/mappings/coco2017_nyu.pkl', 'rb') as handle:\n",
    "            self.mappings = pickle.load(handle)\n",
    "        \n",
    "        #model\n",
    "        device =\"cpu\"# 'cuda:0'\n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "        model = DefaultPredictor(cfg)\n",
    "        model.model.to(device)\n",
    "\n",
    "        #visu\n",
    "        visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=True, num_classes=41)\n",
    "        \n",
    "        self.model = model\n",
    "        self.visu = visu\n",
    "        \n",
    "        \n",
    "        # depth\n",
    "        scannet_scene_dir= \"/home/jonfrey/Datasets/scannet/scans/scene0000_00\"\n",
    "        self.spd = SuperpixelDepth( scannet_scene_dir )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def inference(self, img_pth, tag=\"\", plot=True):\n",
    "        img = np.array( Image.open(img_pth) )\n",
    "        outputs = self.model( img )\n",
    "\n",
    "        _,H,W = outputs['instances'][0].pred_masks.shape\n",
    "\n",
    "        label = torch.zeros( (H,W) ,dtype=torch.long )\n",
    "        for i in range(len( outputs['instances'])):\n",
    "            inst = outputs['instances'][i]\n",
    "            if inst.scores[0] > 0.5:\n",
    "                coco200 = int( inst.pred_classes ) \n",
    "                label[ inst.pred_masks[0] ] = mappings['coco2017_id_nyu_id'][coco200] + 1\n",
    "        if plot:\n",
    "            self.visu.plot_detectron( img = img, label = label, tag=tag+\"_mask_rcnn\", jupyter=self.jupyter,alpha=0.3)\n",
    "        return label\n",
    "        \n",
    "    def get_superpixel_image(self, img_pth, n_segments=40, tag=\"\",  plot=True):\n",
    "        img = np.array( Image.open( img_pth) )\n",
    "        segments_slic = slic(img_as_float(img), n_segments=n_segments, compactness=20, sigma=5,\n",
    "                             start_label=0)\n",
    "        if plot:\n",
    "            segments_slic_plot = np.mod( segments_slic, np.full(segments_slic.shape,40 ))\n",
    "            self.visu.plot_detectron( img = img, label = segments_slic_plot, tag=tag+\"_seg_image\", jupyter=self.jupyter,alpha=0.3)\n",
    "        \n",
    "        return segments_slic\n",
    "    \n",
    "    def get_superpixel_depth(self, depth_pth, n_segments=40, tag=\"\",  plot=True):\n",
    "        return self.spd.get( depth_pth , n_segments=n_segments, tag=tag, plot=plot, visu=self.visu, jupyter=self.jupyter)   \n",
    "        \n",
    "        \n",
    "    def combined(self, img_pth, depth_pth, n_segments=100, tag=\"\",  plot=True ):\n",
    "        d_seg = self.get_superpixel_depth(depth_pth, n_segments=n_segments, tag=tag,plot=plot)\n",
    "        i_seg = self.get_superpixel_image(img_pth, n_segments=n_segments, tag=tag,plot=plot)\n",
    "        \n",
    "        shift_n = int(n_segments).bit_length()\n",
    "        shift_mult = 2 ** shift_n\n",
    "        \n",
    "        com_seg = d_seg + (i_seg * shift_mult )\n",
    "        \n",
    "        res, index, inverse = np.unique( com_seg, return_index=True, return_inverse=True)\n",
    "        if plot:\n",
    "            img = np.array( Image.open( img_pth) )\n",
    "            plot_inverse = np.mod( inverse, np.full( inverse.shape,40 ))\n",
    "            self.visu.plot_detectron( img = img, label = plot_inverse.reshape( d_seg.shape ), tag=tag+\"_seg_combined\", jupyter=self.jupyter, store=False,alpha=0.3)\n",
    "        return inverse.reshape( d_seg.shape )\n",
    "    \n",
    "    def oracle( self, img_pth, depth_pth, pred_pth, n_segments= 100,  tag=\"\", plot=False):\n",
    "        seg = self.combined(img_pth, depth_pth, n_segments=100, tag=tag, plot=plot )\n",
    "        \n",
    "        pred = imageio.imread( pred_pth )\n",
    "        mask_rcnn = self.inference( img_pth, tag=tag, plot=plot)\n",
    "        \n",
    "        out = np.zeros( pred.shape )\n",
    "        for s in range(seg.max()):\n",
    "            m = seg == s\n",
    "            val, counts = np.unique( pred[m], return_counts=True)\n",
    "            if val[np.argmax( counts )] != 0:\n",
    "                out[m] = val[np.argmax( counts )]\n",
    "            else:\n",
    "                val, counts = np.unique( mask_rcnn[m], return_counts=True)\n",
    "                out[m] = val[np.argmax( counts )]\n",
    "                \n",
    "        if plot:\n",
    "            img = np.array( Image.open( img_pth) )\n",
    "            self.visu.plot_detectron( img = img, label =pred, tag=tag+ '_network', jupyter=self.jupyter, alpha=0.6)\n",
    "            \n",
    "            self.visu.plot_detectron( img = img, label =out, tag=tag+ '_final', jupyter=self.jupyter, alpha=0.6)\n",
    "        return out\n",
    "    \n",
    "        \n",
    "                \n",
    "    \n",
    "oracle = Oracle()\n",
    "# oracle.inference( \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/738.jpg\" )\n",
    "# oracle.get_superpixel_image( \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/738.jpg\" )\n",
    "# oracle.get_superpixel_depth( \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/depth/738.png\" )\n",
    "# plot_inverse = oracle.combined( \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/730.jpg\",\n",
    "#                 \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/depth/730.png\" )\n",
    "\n",
    "pred_pth = \"/home/jonfrey/Datasets/labels_generated/new_format_scene0-10_reprojected/scene0000_00/new_format_scene0-10_reprojected/map_probs_with_confidence_0.5/730.png\"\n",
    "img_pth = \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/730.jpg\"\n",
    "\n",
    "img = np.array( Image.open( img_pth) )\n",
    "out = oracle.oracle( \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/730.jpg\",\n",
    "                \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/depth/730.png\",\n",
    "                pred_pth, plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "ls = [str(s) for s in Path( \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/\" ).rglob(\"*.jpg\") if int((str(s).split('/')[-1][:-4]))% 10 == 0   ]##\n",
    "ls.sort(key= lambda x: int(x.split('/')[-1][:-4]))\n",
    "oracle = Oracle()\n",
    "pred_pth = \"/home/jonfrey/Datasets/labels_generated/new_format_scene0-10_reprojected/scene0000_00/new_format_scene0-10_reprojected/map_probs_with_confidence_0.5/730.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ea7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, p in enumerate( ls) :\n",
    "    if j < 540: continue\n",
    "    print(f\"{j}/{len(ls)}\")\n",
    "    scene = p.split('/')[-3]\n",
    "    idx = int ( p.split('/')[-1][:-4])\n",
    "    oracle.visu.epoch = idx \n",
    "    out = oracle.oracle( \n",
    "        p, p.replace(\"color\",\"depth\").replace(\".jpg\",\".png\"),\n",
    "        f\"/home/jonfrey/Datasets/labels_generated/new_format_scene0-10_reprojected/{scene}/new_format_scene0-10_reprojected/map_probs_with_confidence_0.5/{idx}.png\", plot=False)\n",
    "    \n",
    "    out_path = f\"/home/jonfrey/Datasets/labels_generated/new_format_scene0-10_oracle/{scene}/new_format_scene0-10_oracle/oracle/{idx}.png\"\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    imageio.imwrite(out_path, np.uint8( out ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad12f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
