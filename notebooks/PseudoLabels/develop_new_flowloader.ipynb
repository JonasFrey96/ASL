{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "os.chdir(os.path.join(os.getenv('HOME'), 'ASL'))\n",
    "sys.path.insert(0, os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd() + '/src'))\n",
    "\n",
    "from pseudo_label import OpticalFlowLoader\n",
    "\n",
    "#TODO: Jonas Frey\n",
    "# list of things that need to change if cropping scannet at first: \n",
    "# -> crop all labels\n",
    "# -> crop in flow generation\n",
    "# -> crop when loading gt/label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "arr = imageio.imread(\"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/0.jpg\")\n",
    "arr.shape\n",
    "from PIL import Image\n",
    "b = 11\n",
    "arr2 = arr[b:968-b,b:1296-b]\n",
    "arr2.shape\n",
    "Image.fromarray(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e572c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visu import Visualizer\n",
    "visualizer = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c9e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import one_hot\n",
    "from math import ceil\n",
    "import torchvision\n",
    "\n",
    "\"\"\"\n",
    "TODO: Jonas Frey\n",
    "Fully regenerate the flow with the correct center crop to get rid of the boarder induces by the rectification step.\n",
    "\"\"\"\n",
    "\n",
    "def make_grid_sqaure( img, padding=5, pad_value= 0):\n",
    "    nrow = ceil(len(img)**0.5)\n",
    "    img = torch.from_numpy( np.stack( img, axis=0)).permute(0,3,1,2)\n",
    "    img = torchvision.utils.make_grid( img , nrow = nrow, padding = padding, pad_value = pad_value).permute(1,2,0).numpy()\n",
    "    return np.uint8(img)\n",
    "    \n",
    "class PseudoLabelGenerator():\n",
    "    def __init__(self, confidence='equal', \n",
    "            flow_mode='sequential', visualizer= None):\n",
    "        \"\"\"  \n",
    "        confidence:\n",
    "          'equal': perfect optical flow -> all project labels are equally good\n",
    "          'linear': linear rate -> per frame\n",
    "          'exponential': exponential rate -> per frame \n",
    "        flow_mode:\n",
    "          'sequential': #-> 0->1, 1->2, 2->3\n",
    "        \"\"\"\n",
    "        assert flow_mode == 'sequential', f\"Not defined flow mode: {flow_mode}\"\n",
    "        self.visualizer = visualizer\n",
    "    \n",
    "    def calculate_label(self, flows, labels, images = None):\n",
    "        \n",
    "        print(\"VISU Input\")\n",
    "        self.visu( flows, labels, images)\n",
    "        \n",
    "        seg_forwarded = self._forward_index( flows, labels )\n",
    "        \n",
    "        print(\"VISU Output\")\n",
    "        self.visu( flows, seg_forwarded, images)\n",
    "        \n",
    "        out = {}\n",
    "        for k in seg_forwarded[0].keys():\n",
    "            all_labels = [labels[i]['pretrain25k'] for i in range(len(labels))]\n",
    "            if len( all_labels[0].shape ) == 2:\n",
    "                # COUNT BASED\n",
    "                ar = np.stack( all_labels , axis= 0)\n",
    "\n",
    "                uni = np.unique( ar)\n",
    "                uni = uni[uni!= 0]\n",
    "                l = np.zeros( (41,* all_labels[0].shape) )\n",
    "                for j,u in enumerate(uni):\n",
    "                    l[ u ] = np.sum( ar == u, axis=0)\n",
    "                out[k] = l.argmax( axis = 0)\n",
    "            else:\n",
    "                # SUM BASED\n",
    "                ar = np.stack( all_labels , axis= 0).sum(axis=0)\n",
    "                out[k] = ar.argmax( axis = 2)\n",
    "            \n",
    "            if self.visualizer != None:\n",
    "                self.visualizer.plot_detectron( images[0], out[k], tag=f\"Output {k}\", jupyter=True)\n",
    "            \n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def _get_confidence_values( self, seq_length ):\n",
    "        if self._confidence == 'equal':\n",
    "            return [float( 1/seq_length)] * seq_length \n",
    "\n",
    "        if self._confidence == 'linear':\n",
    "            ret = []\n",
    "            lin_rate = 0.1\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = 1 - lin_rate* (seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "                \n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "        elif self._confidence == 'exponential':\n",
    "            ret = []\n",
    "            exp_rate = 0.8\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = exp_rate**(seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "    def _labels_add_channels(self, labels):\n",
    "        for j, frame in enumerate( labels):\n",
    "            for k in frame.keys():\n",
    "                print(frame[k].shape)\n",
    "                if len(frame[k].shape) == 2:\n",
    "                    labels[j][k] = frame[k][:,:,None]\n",
    "        return labels\n",
    "\n",
    "    def _forward_index(self, flows, labels ):\n",
    "        \"\"\"\n",
    "        # OUTPUT OF OpticalFlowLoader # labels = H,W or H,W,C\n",
    "        \"\"\" \n",
    "        labels = self._labels_add_channels(labels) # -> H,W,C C (1 or 40)\n",
    "        \n",
    "        print(\"labels[0]['pretrain25k'].shape\",labels[0]['pretrain25k'].shape)\n",
    "        H,W,_ = flows[0][0].shape\n",
    "        \n",
    "        labels_forwarded = []\n",
    "        \n",
    "        for i in range(0,len(flows)):\n",
    "            # START AT OLDEST FLOW\n",
    "            flow = flows[i][0]\n",
    "            valid = flows[i][1]\n",
    "            \n",
    "            labels_forwarded.append( labels[i] ) # each entry is a dict with mutiple labels\n",
    "            \n",
    "            h_, w_ = np.mgrid[0:H, 0:W].astype(np.float32)\n",
    "            h_ -= flow[:,:,1]\n",
    "            w_ -= flow[:,:,0]\n",
    "            \n",
    "            for labels_frame in labels_forwarded:\n",
    "                for k in labels_frame.keys():\n",
    "                    if labels_frame[k].shape[2] != 1:\n",
    "                        # soft label with prob\n",
    "                        forw = cv2.remap( labels_frame[k] , w_, h_, \n",
    "                                                      interpolation=cv2.INTER_LINEAR, \n",
    "                                                      borderMode=cv2.BORDER_CONSTANT, \n",
    "                                                      borderValue=0)\n",
    "                        labels_frame[k] = forw\n",
    "                    else:\n",
    "                        # hard label\n",
    "                        forw = cv2.remap( labels_frame[k], w_, h_, \n",
    "                                                      interpolation=cv2.INTER_NEAREST, \n",
    "                                                      borderMode=cv2.BORDER_CONSTANT, \n",
    "                                                      borderValue=0)[:,:,None]\n",
    "                        if i == len(flows)-1:\n",
    "                            labels_frame[k] = forw[:,:,0]\n",
    "                        else:\n",
    "                            labels_frame[k] = forw\n",
    "                    \n",
    "        return labels_forwarded\n",
    "    \n",
    "    def visu(self, flows, labels, images):\n",
    "        if self.visualizer is not None:\n",
    "            \n",
    "            for label_name in labels[0].keys():\n",
    "                detectron_plots = []\n",
    "                for _f,label_dict, img in zip(flows, labels, images):\n",
    "                    flow,valid = _f \n",
    "                    plo = visualizer.plot_detectron( img, label_dict[label_name] , jupyter=False) \n",
    "                    detectron_plots.append(plo)\n",
    "                grid = make_grid_sqaure( detectron_plots , padding=5, pad_value= 0)\n",
    "                print(\"label_name \",label_name)\n",
    "                res = visualizer.plot_image(grid, tag=label_name, jupyter=True) \n",
    "\n",
    "ofl = OpticalFlowLoader( lookahead=4)\n",
    "ofl.register_predictions(\"pretrain25k\", \"/home/jonfrey/Datasets/labels_generated/labels_pretrain25k/scans\")\n",
    "ofl.register_predictions(\"gt\", \"/home/jonfrey/Datasets/scannet/scans\")\n",
    "plg = PseudoLabelGenerator(visualizer = visualizer)\n",
    "\n",
    "for j,val in enumerate( ofl):\n",
    "  flows, labels, images = val\n",
    "  if j == 0: break\n",
    "        \n",
    "plg.calculate_label(flows, labels, images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adda5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#             plo = visualizer.plot_detectron( img, label_dict[label_name] , jupyter=False) \n",
    "\n",
    "uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10085c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8992b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flows), len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class PseudoLabelGenerator():\n",
    "    def __init__(self, confidence='equal', \n",
    "            flow_mode='sequential'):\n",
    "        \"\"\"  \n",
    "        confidence:\n",
    "          'equal': perfect optical flow -> all project labels are equally good\n",
    "          'linear': linear rate -> per frame\n",
    "          'exponential': exponential rate -> per frame \n",
    "        flow_mode:\n",
    "          'sequential': #-> 0->1, 1->2, 2->3\n",
    "        \"\"\"\n",
    "        assert flow_mode == 'sequential', f\"Not defined flow mode: {flow_mode}\"\n",
    "    \n",
    "    def __len__(self):\n",
    "      return self._pll.length\n",
    "\n",
    "    def get_gt_label(self, index):\n",
    "        seg, depth, flow, paths = self._pll[index] \n",
    "        return seg[0][1]\n",
    "    \n",
    "    def get_img(self, index):\n",
    "        return self._pll.getImage(index)\n",
    "    \n",
    "    def get_depth(self, index):\n",
    "        seg, depth, flow, paths = self._pll[index]\n",
    "        return depth[0]\n",
    "    \n",
    "    def calculate_label(self, index=None, seg=[],flow=[], image= None ):\n",
    "        if not index is None:\n",
    "            seg_forwarded= self._forward_index(index, self._pre_fusion_function) #return H,W,C\n",
    "        else:\n",
    "            seg_forwarded = self._forward_index(index, seg, flow, self._pre_fusion_function)\n",
    "        \n",
    "        if self._visu_active:\n",
    "            self._visu_seg_forwarded(seg_forwarded)\n",
    "\n",
    "        # -1 39 -> 0 -> 40 We assume that the network is also able to predict the invalid class\n",
    "        # In reality this is not the case but this way we can use the ground truth labels for testing\n",
    "        \n",
    "        if seg_forwarded[0].shape[2] == 1:\n",
    "            for i in range(len( seg_forwarded) ):\n",
    "                seg_forwarded[i] += 1\n",
    "                seg_forwarded[i][seg_forwarded[i]>40] = 40\n",
    "        confidence_values_list = self._get_confidence_values(seq_length= len(seg_forwarded))\n",
    "        if seg_forwarded[0].shape[2] == 1:\n",
    "            import pdb; pdb.set_trace()\n",
    "            one_hot_acc = np.zeros( (*seg_forwarded[0].shape, self._nc+1), dtype=np.float32) # H,W,C\n",
    "            \n",
    "            for conf, seg in zip(confidence_values_list, seg_forwarded):    \n",
    "                one_hot_acc += (np.eye(self._nc+1)[seg.astype(np.int32)]).astype(np.float32) * conf\n",
    "            one_hot_acc = one_hot_acc[:,:,0,:]\n",
    "            invalid_labels = np.sum( one_hot_acc[:,:,1:],axis=2 ) == 0\n",
    "            \n",
    "        \n",
    "        label = np.argmax( one_hot_acc[:,:,1:], axis=2 )\n",
    "        label[ invalid_labels ] = -1 \n",
    "        \n",
    "#         if self._visu_active:\n",
    "#             print(\"Aggregated Label\")\n",
    "#             self._visu.plot_segmentation(seg= label+1, jupyter=True)\n",
    "\n",
    "#         if self._refine_superpixel:\n",
    "#             if image is None:\n",
    "#                 img = self._pll.getImage(index).astype(np.float32)/256\n",
    "#             else:\n",
    "#                 img = image\n",
    "                \n",
    "#             label_super, img, segments = self._superpixel_label(img, label)\n",
    "#             if self._visu_active:\n",
    "#                 print(\"Label Superpixel\")\n",
    "#                 self._visu.plot_segmentation(seg= label_super + 1, jupyter=True)  \n",
    "#                 self._visu.plot_image(img=img, jupyter=True)  \n",
    "#                 self._visu_superpixels(img, segments)\n",
    "#             label = label_super\n",
    "#         print( \"Time rest\", time.time()-st)\n",
    "#         if self._get_depth_superpixel:\n",
    "#             self._superpixel_depth(depth_forwarded[-1], label)\n",
    "        return label, (seg_forwarded[-1]-1).astype(np.int32)\n",
    "    \n",
    "    def _get_confidence_values( self, seq_length ):\n",
    "        if self._confidence == 'equal':\n",
    "            return [float( 1/seq_length)] * seq_length \n",
    "\n",
    "        if self._confidence == 'linear':\n",
    "            ret = []\n",
    "            lin_rate = 0.1\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = 1 - lin_rate* (seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "\n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "        elif self._confidence == 'exponential':\n",
    "            ret = []\n",
    "            exp_rate = 0.8\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = exp_rate**(seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "\n",
    "    def _forward_index(self, index=None, seg=[],flow=[] ,pre_fusion_function=None ):\n",
    "        \"\"\"\n",
    "        seg[0] , C,H,W\n",
    "        \n",
    "        pre_fusion_function should be used to integrate the depth measurments \n",
    "        to the semseg before forward projection !\n",
    "\n",
    "        seg_forwarded[0] -> oldest_frame\n",
    "        seg_forwarded[len(seg_forwarded)] -> latest_frame not forwarded\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if not index is None:\n",
    "            if pre_fusion_function is None:\n",
    "                seg, _, flow, _ = self._pll[index]\n",
    "            else:\n",
    "                seg, _, flow, _ = pre_fusion_function( self._pll[index] )\n",
    "        \n",
    "        if len( seg[0].shape ) == 3 and seg[0].shape[0] != 1:\n",
    "            soft = True\n",
    "        else:\n",
    "            soft = False\n",
    "            \n",
    "        assert self._flow_mode == 'sequential'\n",
    "        seg_forwarded = []\n",
    "        \n",
    "        for j in range(len( seg )):\n",
    "            seg[j] = np.moveaxis( seg[j], [0,1,2], [2,0,1] ) #C,H,W -> H,W,C\n",
    "        \n",
    "        for i in range(0,len(seg)-1):\n",
    "            i = len(seg)-1-i\n",
    "            seg_forwarded.append( seg[i].astype(np.float32) )\n",
    "\n",
    "            \n",
    "            # start at oldest frame\n",
    "            if i != 0:\n",
    "                f = flow[i][0]\n",
    "            else:\n",
    "                f = np.zeros(flow[i][0].shape, dtype=np.float32)\n",
    "            \n",
    "            h_, w_ = np.mgrid[0:self._H, 0:self._W].astype(np.float32)\n",
    "            h_ -= f[:,:,1]\n",
    "            w_ -= f[:,:,0]\n",
    "\n",
    "            j = 0\n",
    "            for s in seg_forwarded : #  seg_forwarded, depth_forwarded\n",
    "                if soft:\n",
    "                    s = cv2.remap( s, w_, h_, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "                else:\n",
    "                    s = cv2.remap( s[None], w_, h_, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=-1)[None]\n",
    "                seg_forwarded[j] = s\n",
    "                \n",
    "                j += 1\n",
    "    \n",
    "        if not soft:\n",
    "            for i in range(len( seg_forwarded) ):\n",
    "                seg_forwarded[i] = np.moveaxis(  seg_forwarded[i] , [0,1,2], [2,0,1] )\n",
    "        seg_forwarded.append( seg[0] )\n",
    "        return seg_forwarded # H,W,C\n",
    "\n",
    "\n",
    "    def _visu_seg_forwarded(self, seg):\n",
    "        s = int( len(seg) ** 0.5 )\n",
    "        ba = torch.zeros( (int(s*s),3, *seg[0].shape), dtype= torch.float32 )\n",
    "        for i in range( int(s*s) ) :\n",
    "            ba[i,:] = torch.from_numpy( seg[-(i+1)] )[None,:,:].repeat(3,1,1)\n",
    "        grid_ba = make_grid( ba ,nrow = s ,padding = 2,\n",
    "          scale_each = False, pad_value = -1)[0]\n",
    "        self._visu.plot_segmentation(seg= grid_ba +1 , jupyter=True)\n",
    "\n",
    "    def _superpixel_label(self, img, label, segments=250):\n",
    "        assert segments < 256 #I think slic fails if segments > 256 given that a 8bit uint is returend!\n",
    "\n",
    "        segments = slic(img, n_segments = segments, sigma = 5, start_label=0)\n",
    "        # show the output of SLIC\n",
    "        out_label = copy.copy(label)\n",
    "        for i in range(0,segments.max()):\n",
    "            m1 = segments == i\n",
    "            m = m1 * ( label != -1 )\n",
    "            unique_val, unique_counts = np.unique( label [m], return_counts=True)\n",
    "            # fill a segment preferable not with invalid !\n",
    "            if unique_counts.shape[0] == 0:\n",
    "                val = -1\n",
    "            else:\n",
    "                ma = unique_counts == unique_counts.max()\n",
    "                while ma.sum() != 1:\n",
    "                    ma[np.random.randint(0,ma.shape[0])] = False\n",
    "                val = unique_val[ma]\n",
    "            out_label[m1] = val \n",
    "\n",
    "        return out_label, img, segments\n",
    "    \n",
    "    def _visu_superpixels(self, img, segments):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from skimage.segmentation import mark_boundaries\n",
    "        fig = plt.figure(\"Superpixels -- segments\" )\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.imshow(mark_boundaries(img, segments))\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# plg_ws_2 = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "#                            visu=visu,\n",
    "#                            window_size=window_size_2,\n",
    "#                           cfg_loader = {\"ignore_depth\": True},\n",
    "#                           visu_active=plot,\n",
    "#                           refine_superpixel=False)\n",
    "# pseudo_2, _ = plg_ws_2.calculate_label(\n",
    "#                         index=None, \n",
    "#                         seg= seg[:window_size_2], \n",
    "#                         flow= flow_list[:window_size_2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
