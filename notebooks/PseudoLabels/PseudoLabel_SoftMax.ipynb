{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion based on consistency\n",
    "# tempretaure, weighting, Expected calibration error \n",
    "\n",
    "# average the softmax output\n",
    "# superpixel for depth segmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"/home/jonfrey/ASL\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/\"\"\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/pseudo_label\"\"\")\n",
    "\n",
    "from pseudo_label.yolo import YoloHelper\n",
    "from pseudo_label.deeplab import DeeplabHelper\n",
    "from pseudo_label.fast_scnn import FastSCNNHelper\n",
    "\n",
    "import numpy as np\n",
    "from visu import Visualizer\n",
    "import imageio\n",
    "\n",
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)\n",
    "\n",
    "yh = YoloHelper()\n",
    "dlh = DeeplabHelper(device=\"cuda:0\")\n",
    "fsh = FastSCNNHelper(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_asl import get_dataset\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "import yaml\n",
    "import coloredlogs\n",
    "coloredlogs.install()\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from utils_asl import load_yaml\n",
    "\n",
    "env_cfg_path = os.path.join('cfg/env', os.environ['ENV_WORKSTATION_NAME']+ '.yml')\n",
    "env_cfg = load_yaml(env_cfg_path)\n",
    "eval_cfg = load_yaml(\"/home/jonfrey/ASL/cfg/eval/eval.yml\")\n",
    "\n",
    "# SETUP DATALOADER\n",
    "dataset_test = get_dataset(\n",
    "    **eval_cfg['dataset'],\n",
    "    env = env_cfg,\n",
    "    output_trafo = None,\n",
    "    )\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test,\n",
    "    shuffle = False,\n",
    "    num_workers = 0,\n",
    "    pin_memory = eval_cfg['loader']['pin_memory'],\n",
    "    batch_size = 1, \n",
    "    drop_last = True)\n",
    "\n",
    "st = time.time()\n",
    "globale_idx_to_image_path = dataset_test.image_pths\n",
    "\n",
    "eval_cfg['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d29bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import TaskGenerator\n",
    "tc = TaskGenerator(**eval_cfg['task_generator'], output_size=(640,1280) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_acc(label, gt , names = ['deeplab', 'yolo', 'fastscnn', 'gt'] ):\n",
    "    m = gt != -1\n",
    "    acc_indi = {}\n",
    "    for l,n in zip(label,names):\n",
    "        correct = ( l[m] == gt[m]).sum()\n",
    "        m2 = m * (l != -1)\n",
    "        total = m2.sum()\n",
    "        acc_indi[n] = correct/total\n",
    "        \n",
    "    # Optimal upper bound\n",
    "    m = gt != -1\n",
    "    m_correct = np.zeros( label[0].shape )\n",
    "    for l,n in zip(label,names):\n",
    "        m_est = l == gt\n",
    "        m_correct[m_est] = 1\n",
    "        \n",
    "    \n",
    "    acc_upper_bound = m_correct[m].sum() / m.sum()\n",
    "    acc_indi['upper_bound'] = acc_upper_bound\n",
    "    return acc_indi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structured-hygiene",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8fb1f55488c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m pllo = PseudoLabelLoaderOnline(base_flow = '/home/jonfrey/results/scannet_pseudo_label/scannet',\n\u001b[0;32m---> 45\u001b[0;31m                         \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_pths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                         sub=10)\n\u001b[1;32m     47\u001b[0m \u001b[0mpllo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "os.chdir(\"/home/jonfrey/ASL\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/\"\"\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/pseudo_label\"\"\")\n",
    "\n",
    "from pseudo_label import *\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "\n",
    "class PseudoLabelLoaderOnline():\n",
    "    def __init__(self, base_flow, image_paths, h=960, w=1280, sub=10):\n",
    "        self.image_paths = image_paths\n",
    "        self.sub = sub\n",
    "        self.base_flow = base_flow\n",
    "        self.H, self.W= h,w \n",
    "        \n",
    "    def get_flow(self, global_idx):\n",
    "        flow = []\n",
    "        for idx in global_idx:\n",
    "            fp = os.path.join( \n",
    "                self.base_flow, \n",
    "                dataset_test.image_pths[ idx].split('/')[-3], \n",
    "                f'flow_sub_{self.sub}',\n",
    "                dataset_test.image_pths[ idx].split('/')[-1][:-4]+'.png' )\n",
    "            try:\n",
    "                print(\"Flow Path\", fp)\n",
    "                flow.append( readFlowKITTI( fp, H=self.H ,W=self.W))\n",
    "            except:\n",
    "                return False, False \n",
    "        flow.reverse()\n",
    "        return True, flow\n",
    "    \n",
    "        \n",
    "pllo = PseudoLabelLoaderOnline(base_flow = '/home/jonfrey/results/scannet_pseudo_label/scannet',\n",
    "                        image_paths = dataset_test.image_pths,\n",
    "                        sub=10)\n",
    "pllo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "TODO:\n",
    "- Depth\n",
    "- BoundingBox Predicitons\n",
    "\"\"\"\n",
    "from torch.nn.functional import one_hot\n",
    "class PseudoLabelGenerator():\n",
    "    def __init__(self, base_path, sub=10, confidence='equal', \n",
    "            flow_mode='sequential', H=640, W=1280, \n",
    "            nc=40, refine_superpixel=True,\n",
    "            get_depth_superpixel=False,window_size=10,\n",
    "            visu=None, pre_fusion_function=None, visu_active=True, cfg_loader={}):\n",
    "        \"\"\"  \n",
    "        confidence:\n",
    "          'equal': perfect optical flow -> all project labels are equally good\n",
    "          'linear': linear rate -> per frame\n",
    "          'exponential': exponential rate -> per frame \n",
    "        flow_mode:\n",
    "          'sequential': #-> 0->1, 1->2, 2->3\n",
    "          'target': 0->3 1->3 2->3\n",
    "        \"\"\"\n",
    "        self._visu_active = visu_active\n",
    "        self._sub = sub\n",
    "        self._flow_mode = flow_mode #'sequential' #-> 0->1, 1->2, 2->3 # 'target' 0->3 1->3 2->3\n",
    "        self._H,self._W = H,W\n",
    "        self._confidence= confidence # equal, linear, exponential\n",
    "        self._nc = nc\n",
    "        self._refine_superpixel = refine_superpixel\n",
    "        self._get_depth_superpixel = get_depth_superpixel\n",
    "        self._window_size = window_size\n",
    "        self._pll = PseudoLabelLoader(base_path = base_path, window_size=window_size, sub=10, h=H,w=W, **cfg_loader )\n",
    "        self._ignore_depth = cfg_loader.get(\"ignore_depth\",False)\n",
    "\n",
    "        # Passed externally\n",
    "        self._visu = visu\n",
    "        self._pre_fusion_function = pre_fusion_function\n",
    "    def __len__(self):\n",
    "      return self._pll.length\n",
    "\n",
    "    def get_gt_label(self, index):\n",
    "        seg, depth, flow, paths = self._pll[index] \n",
    "        return seg[0][1]\n",
    "    \n",
    "    def get_img(self, index):\n",
    "        return self._pll.getImage(index)\n",
    "    \n",
    "    def get_depth(self, index):\n",
    "        seg, depth, flow, paths = self._pll[index]\n",
    "        return depth[0]\n",
    "    \n",
    "    def calculate_label(self, index=None, seg=[],flow=[], image= None ):\n",
    "        if not index is None:\n",
    "            seg_forwarded= self._forward_index(index, self._pre_fusion_function) #return H,W,C\n",
    "        else:\n",
    "            seg_forwarded = self._forward_index(index, seg, flow, self._pre_fusion_function)\n",
    "        \n",
    "        if self._visu_active:\n",
    "            print(\"Forward projected label\")\n",
    "            self._visu_seg_forwarded(seg_forwarded)\n",
    "\n",
    "        # -1 39 -> 0 -> 40 We assume that the network is also able to predict the invalid class\n",
    "        # In reality this is not the case but this way we can use the ground truth labels for testing\n",
    "        \n",
    "        if seg_forwarded[0].shape[2] == 1:\n",
    "            for i in range(len( seg_forwarded) ):\n",
    "                seg_forwarded[i] += 1 \n",
    "        \n",
    "        \n",
    "        confidence_values_list = self._get_confidence_values(seq_length= len(seg_forwarded))\n",
    "\n",
    "        if seg_forwarded[0].shape[2] == 1:\n",
    "            one_hot_acc = np.zeros( (*seg_forwarded[0].shape,self._nc+1), dtype=np.float32) # H,W,C\n",
    "            for conf, seg in zip(confidence_values_list, seg_forwarded):    \n",
    "                one_hot_acc += (np.eye(self._nc+1)[seg.astype(np.int32)]).astype(np.float32) * conf\n",
    "            invalid_labels = np.sum( one_hot_acc[:,:,1:],axis=2 ) == 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        label = np.argmax( one_hot_acc[:,:,1:], axis=2 )\n",
    "        label[ invalid_labels ] = -1 \n",
    "        \n",
    "#         if self._visu_active:\n",
    "#             print(\"Aggregated Label\")\n",
    "#             self._visu.plot_segmentation(seg= label+1, jupyter=True)\n",
    "\n",
    "#         if self._refine_superpixel:\n",
    "#             if image is None:\n",
    "#                 img = self._pll.getImage(index).astype(np.float32)/256\n",
    "#             else:\n",
    "#                 img = image\n",
    "                \n",
    "#             label_super, img, segments = self._superpixel_label(img, label)\n",
    "#             if self._visu_active:\n",
    "#                 print(\"Label Superpixel\")\n",
    "#                 self._visu.plot_segmentation(seg= label_super + 1, jupyter=True)  \n",
    "#                 self._visu.plot_image(img=img, jupyter=True)  \n",
    "#                 self._visu_superpixels(img, segments)\n",
    "#             label = label_super\n",
    "#         print( \"Time rest\", time.time()-st)\n",
    "#         if self._get_depth_superpixel:\n",
    "#             self._superpixel_depth(depth_forwarded[-1], label)\n",
    "        return depth_forwarded[-1], label, (seg_forwarded[-1]-1).astype(np.int32)\n",
    "    \n",
    "    def _get_confidence_values( self, seq_length ):\n",
    "        if self._confidence == 'equal':\n",
    "            return [float( 1/seq_length)] * seq_length \n",
    "\n",
    "        if self._confidence == 'linear':\n",
    "            ret = []\n",
    "            lin_rate = 0.1\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = 1 - lin_rate* (seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "\n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "        elif self._confidence == 'exponential':\n",
    "            ret = []\n",
    "            exp_rate = 0.8\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = exp_rate**(seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "\n",
    "    def _forward_index(self, index=None, seg=[],flow=[] ,pre_fusion_function=None ):\n",
    "        \"\"\"\n",
    "        seg[0] , C,H,W\n",
    "        \n",
    "        pre_fusion_function should be used to integrate the depth measurments \n",
    "        to the semseg before forward projection !\n",
    "\n",
    "        seg_forwarded[0] -> oldest_frame\n",
    "        seg_forwarded[len(seg_forwarded)] -> latest_frame not forwarded\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if not index is None:\n",
    "            if pre_fusion_function is None:\n",
    "                seg, _, flow, _ = self._pll[index]\n",
    "            else:\n",
    "                seg, _, flow, _ = pre_fusion_function( self._pll[index] )\n",
    "        \n",
    "        if len( seg[0].shape ) == 3 and seg[0].shape[0] != 1:\n",
    "            soft = True\n",
    "        else:\n",
    "            soft = False\n",
    "            \n",
    "        assert self._flow_mode == 'sequential'\n",
    "        seg_forwarded = []\n",
    "        \n",
    "        for j in range(len( seg )):\n",
    "            seg[j] = np.moveaxis( seg[j], [0,1,2], [2,0,1] ) #C,H,W -> H,W,C\n",
    "        \n",
    "        for i in range(0,len(seg)-1):\n",
    "            i = len(seg)-1-i\n",
    "            seg_forwarded.append( seg[i].astype(np.float32) )\n",
    "\n",
    "            \n",
    "            # start at oldest frame\n",
    "            if i != 0:\n",
    "                f = flow[i][0]\n",
    "            else:\n",
    "                f = np.zeros(flow[i][0].shape, dtype=np.float32)\n",
    "            \n",
    "            h_, w_ = np.mgrid[0:self._H, 0:self._W].astype(np.float32)\n",
    "            h_ -= f[:,:,1]\n",
    "            w_ -= f[:,:,0]\n",
    "\n",
    "            j = 0\n",
    "            for s in seg_forwarded : #  seg_forwarded, depth_forwarded\n",
    "                if soft:\n",
    "                    print(s.shape, \"seg_forwarded\")\n",
    "                    \n",
    "                    \n",
    "                    print(s.shape, \"seg_forwarded moved axis\")\n",
    "                    s = cv2.remap( s, w_, h_, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "                    print(s.shape, \"seg_forwarded s out\")\n",
    "                else:\n",
    "                    s = cv2.remap( s[None], w_, h_, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=-1)[None]\n",
    "                seg_forwarded[j] = s\n",
    "                \n",
    "                j += 1\n",
    "        \n",
    "  \n",
    "        seg_forwarded.append( seg[0].astype(np.float32) )\n",
    "        print( \"shapes\", [s.shape for s in seg_forwarded])\n",
    "        return seg_forwarded\n",
    "\n",
    "\n",
    "    def _visu_seg_forwarded(self, seg):\n",
    "        s = int( len(seg) ** 0.5 )\n",
    "        ba = torch.zeros( (int(s*s),3, *seg[0].shape), dtype= torch.float32 )\n",
    "        for i in range( int(s*s) ) :\n",
    "            ba[i,:] = torch.from_numpy( seg[-(i+1)] )[None,:,:].repeat(3,1,1)\n",
    "        grid_ba = make_grid( ba ,nrow = s ,padding = 2,\n",
    "          scale_each = False, pad_value = -1)[0]\n",
    "        self._visu.plot_segmentation(seg= grid_ba +1 , jupyter=True)\n",
    "\n",
    "    def _superpixel_label(self, img, label, segments=250):\n",
    "        assert segments < 256 #I think slic fails if segments > 256 given that a 8bit uint is returend!\n",
    "\n",
    "        segments = slic(img, n_segments = segments, sigma = 5, start_label=0)\n",
    "        # show the output of SLIC\n",
    "        out_label = copy.copy(label)\n",
    "        for i in range(0,segments.max()):\n",
    "            m1 = segments == i\n",
    "            m = m1 * ( label != -1 )\n",
    "            unique_val, unique_counts = np.unique( label [m], return_counts=True)\n",
    "            # fill a segment preferable not with invalid !\n",
    "            if unique_counts.shape[0] == 0:\n",
    "                val = -1\n",
    "            else:\n",
    "                ma = unique_counts == unique_counts.max()\n",
    "                while ma.sum() != 1:\n",
    "                    ma[np.random.randint(0,ma.shape[0])] = False\n",
    "                val = unique_val[ma]\n",
    "            out_label[m1] = val \n",
    "\n",
    "        return out_label, img, segments\n",
    "    \n",
    "    def _visu_superpixels(self, img, segments):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from skimage.segmentation import mark_boundaries\n",
    "        fig = plt.figure(\"Superpixels -- segments\" )\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.imshow(mark_boundaries(img, segments))\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size = 3\n",
    "# plot = True \n",
    "# plg = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "#                            visu=visu,\n",
    "#                            window_size=window_size,\n",
    "#                           cfg_loader = {\"ignore_depth\": True},\n",
    "#                           visu_active=plot,\n",
    "#                           refine_superpixel=False)\n",
    "\n",
    "# seg = [ s['fastscnn'][None] for s in label_list ]\n",
    "# seg = [ s['fastscnn'][None].repeat(41,0) for s in label_list ]\n",
    "\n",
    "\n",
    "# print(seg[0].shape)\n",
    "# _, pseudo_label, _ = plg.calculate_label(\n",
    "#                         index=None, \n",
    "#                         seg= seg, \n",
    "#                         flow= flow_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pseudo_label import readSegmentation\n",
    "import time\n",
    "from torchvision import transforms as tf\n",
    "import copy\n",
    "\n",
    "st = time.time()\n",
    "counts = 0\n",
    "counts_flow = 0\n",
    "length = len(dataloader_test)\n",
    "\n",
    "\n",
    "segmentation_list_fastscnn = []\n",
    "global_idx_list = []\n",
    "\n",
    "plot = False\n",
    "# PARAMS LABEL GENERATION\n",
    "weights = [2,0.5,1]\n",
    "weights2 = [1,0.5,1]\n",
    "window_size_2 = 3\n",
    "window_size = 6\n",
    "\n",
    "sub = 10\n",
    "\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "plg = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "                           visu=visu,\n",
    "                           window_size=window_size,\n",
    "                          cfg_loader = {\"ignore_depth\": True},\n",
    "                          visu_active=plot,\n",
    "                          refine_superpixel=False)\n",
    "\n",
    "plg_linear_decay = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "                           visu=visu,\n",
    "                           window_size=window_size,\n",
    "                           cfg_loader = {\"ignore_depth\": True},\n",
    "                           visu_active=plot,\n",
    "                           confidence = 'linear',\n",
    "                           refine_superpixel=False)\n",
    "\n",
    "\n",
    "plg_ws_2 = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "                           visu=visu,\n",
    "                           window_size=window_size_2,\n",
    "                          cfg_loader = {\"ignore_depth\": True},\n",
    "                          visu_active=plot,\n",
    "                          refine_superpixel=False)\n",
    "\n",
    "plg_super = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "                           visu=visu,\n",
    "                           window_size=window_size,\n",
    "                          cfg_loader = {\"ignore_depth\": True},\n",
    "                          visu_active=plot,\n",
    "                          refine_superpixel=True)\n",
    "\n",
    "pllo = PseudoLabelLoaderOnline(base_flow = '/home/jonfrey/results/scannet_pseudo_label/scannet',\n",
    "                        image_paths = dataset_test.image_pths,\n",
    "                        sub=10)\n",
    "\n",
    "\n",
    "def plot_pseudo_labes( res ):\n",
    "    key_list = list(res.keys())\n",
    "    s = int( len( key_list ) ** 0.5 )\n",
    "    if len( key_list ) - s*s != 0:\n",
    "        s +=1\n",
    "    ba = torch.zeros( (int(s*s),3, *res[key_list[0]].shape), dtype= torch.float32 )\n",
    "    for i in range( len( key_list ) ):\n",
    "        k = key_list[i]\n",
    "        if k != 'img':\n",
    "            img = visu.plot_segmentation( seg=res[k]+1 )\n",
    "        else:\n",
    "            img = res[k]\n",
    "        \n",
    "        img = Image.fromarray(img)\n",
    "        img = img.convert(\"RGBA\")\n",
    "        d = ImageDraw.Draw(img)\n",
    "        fnt = ImageFont.truetype(\"/usr/share/fonts/truetype/ttf-dejavu/DejaVuSansMono-Bold.ttf\", 50)   \n",
    "        d.rectangle(((550, 500), (1400, 600)), fill=(254,10,10))\n",
    "        d.text((600,530), k , font=fnt, fill=(254,254,254,254))\n",
    "        img =  img.convert(\"RGB\")\n",
    "        img = np.array( img )\n",
    "        ba[i,:] = torch.from_numpy( img[:,:,:3] ).permute(2,0,1)\n",
    "    \n",
    "    grid_ba = make_grid( ba ,nrow = s ,padding = 2,\n",
    "      scale_each = False, pad_value = -1)\n",
    "    visu.plot_image(img = grid_ba +1 , jupyter=True)\n",
    "\n",
    "\n",
    "down = tf.Resize((320,640))\n",
    "up = tf.Resize((640,1280))\n",
    "label_list = []\n",
    "\n",
    "def print_acc(acc_dict):\n",
    "    avg = {}\n",
    "    for k in acc_dict.keys():\n",
    "        if k.find('flow') != -1:\n",
    "            avg  = acc_dict[k] / counts_flow\n",
    "        else:\n",
    "            avg = acc_dict[k] / counts\n",
    "\n",
    "    print(avg)\n",
    "\n",
    "for j, batch in enumerate( dataloader_test ):\n",
    "    # START EVALUATION  \n",
    "    images = batch[0]\n",
    "    target = batch[1]\n",
    "    ori_img = batch[2]\n",
    "    replayed = batch[3]\n",
    "    BS = images.shape[0]\n",
    "    global_idx = batch[4] \n",
    "    images *= 255\n",
    "    images = images.permute(0,2,3,1).numpy().astype(np.uint8)\n",
    "    pri = False\n",
    "    \n",
    "    for b in range( images.shape[0] ):\n",
    "        # EVALUATE SEMANTIC SEGMENTATION NETWORKS\n",
    "        label = {}\n",
    "        st_ = time.time()\n",
    "        prob_dl = dlh.get_label_prob( images[b] )\n",
    "        prob_yolo = yh.get_label_prob( images[b] )\n",
    "        \n",
    "        inp = down(torch.from_numpy( images[b]).permute(2,0,1)).permute(1,2,0).numpy()\n",
    "        prob_fastscnn = fsh.get_label_prob( inp )\n",
    "        prob_fastscnn = up ( torch.from_numpy( prob_fastscnn[None]) )[0].numpy()\n",
    "        \n",
    "        label['dl'] = np.argmax( prob_dl[:] , axis=0)-1\n",
    "        label['yolo'] = np.argmax( prob_yolo[:] , axis=0)-1\n",
    "        label['fastscnn'] = np.argmax( prob_fastscnn[:] , axis=0)-1\n",
    "        \n",
    "        \n",
    "        prob_sum = prob_dl + prob_yolo + prob_fastscnn\n",
    "        label['sum'] = np.argmax( prob_sum[1:] , axis=0)\n",
    "        \n",
    "        \n",
    "        prob_weighted_sum = weights[0] * prob_dl + weights[1] * prob_yolo + weights[2] * prob_fastscnn\n",
    "        label['weighted_sum'] = np.argmax( prob_weighted_sum[1:] , axis=0)\n",
    "        \n",
    "        \n",
    "        prob_weighted_sum2 = weights2[0] * prob_dl + weights2[1] * prob_yolo + weights2[2] * prob_fastscnn\n",
    "        label['weighted_sum2'] = np.argmax( prob_weighted_sum2[1:] , axis=0)\n",
    "        print(\"time to get predictions\", time.time()-st_ )\n",
    "        \n",
    "        \n",
    "        # RINGBUFFER THE PREDICTIONS\n",
    "        label_list.append( copy.deepcopy( label) )\n",
    "        global_idx_list.append(int( global_idx[b] ))\n",
    "        if len(label_list) > window_size:\n",
    "            label_list = label_list[-window_size:]\n",
    "            global_idx_list = global_idx_list[-window_size:]\n",
    "            \n",
    "            st_ = time.time()\n",
    "            # GET THE FLOW BETWEEN THE FRAMES\n",
    "            suc, flow_list = pllo.get_flow( global_idx = global_idx_list)\n",
    "            print(\"time to load flow\", time.time()-st_ )\n",
    "            \n",
    "            # CHECK IF THE GLOBAL IDX LIST ALIGNS\n",
    "            prev = global_idx_list[0]\n",
    "            prev = int(globale_idx_to_image_path[prev].split('/')[-1][:-4])\n",
    "            for g in global_idx_list[1:]:\n",
    "                g = int(globale_idx_to_image_path[g].split('/')[-1][:-4])\n",
    "                if g != prev + sub:\n",
    "                    suc = False\n",
    "                    break\n",
    "                prev = g\n",
    "                \n",
    "            # CREATE PSEUDO LABEL\n",
    "            if suc:\n",
    "                st_ = time.time()\n",
    "                \n",
    "                for k in list( [\"weighted_sum\",'dl',\"fastscnn\"] ): \n",
    "                    seg = [ s[None] for s in label_list ]\n",
    "                    seg.reverse()\n",
    "                    _, pseudo_label, _ = plg.calculate_label(\n",
    "                        index=None, \n",
    "                        seg= seg, \n",
    "                        flow= flow_list)\n",
    "                    label[k+'_normal_flow'] = pseudo_label\n",
    "                    \n",
    "                    _, pseudo_2, _ = plg_ws_2.calculate_label(\n",
    "                        index=None, \n",
    "                        seg= seg[:window_size_2], \n",
    "                        flow= flow_list[:window_size_2])\n",
    "                    \n",
    "                    label[k+'_w2_flow'] = pseudo_2\n",
    "                    \n",
    "                    _, pseudo_linear, _ = plg_ws_2.calculate_label(\n",
    "                        index=None, \n",
    "                        seg= seg, \n",
    "                        flow= flow_list)\n",
    "                    \n",
    "                    label[k+'_pseudo_linear_flow'] = pseudo_linear\n",
    "                    \n",
    "                print(\"time to create all pseudo labels\", time.time()-st_ )   \n",
    "                pri =True\n",
    "                counts_flow += 1\n",
    "                \n",
    "\n",
    "        # EVALUATE ALL LABELS\n",
    "        ret = get_max_acc(\n",
    "                label = list( label.values()) , \n",
    "                gt=target[b].numpy(), \n",
    "                names= list( label.keys()))\n",
    "\n",
    "\n",
    "        for k in ret.keys():\n",
    "            if k in acc_dict:\n",
    "                acc_dict[k] += ret[k]\n",
    "            else:\n",
    "                acc_dict[k] = ret[k]\n",
    "        counts += 1\n",
    "    \n",
    "    # LOGGING\n",
    "    if j % 1 == 0 and j != 0:\n",
    "        print_acc(acc_dict)\n",
    "        mini =int((time.time()-st)/60)\n",
    "        mini_left = int((time.time()-st)/j*(length-j)/60)\n",
    "        print(f'{j}/{length} total time elapsed: {mini}min; time left {mini_left}min')\n",
    "        plot = label\n",
    "        plot['img'] = images[b]\n",
    "        plot['gt'] = target[b].numpy()  \n",
    "        plot_pseudo_labes( plot )\n",
    "        \n",
    "    if j > 20: \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
