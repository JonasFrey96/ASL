{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "roman-ethiopia",
   "metadata": {},
   "source": [
    "Done:\n",
    "- Segmentation (1280x960) and Depth (640x480) are aligned\n",
    "Does\n",
    "- Align Opical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append( \"\"\"/home/jonfrey/ASL/src\"\"\")\n",
    "\n",
    "from torchvision import transforms as tf \n",
    "import torch\n",
    "import time \n",
    "from pathlib import Path\n",
    "import imageio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from glob import glob\n",
    "import matplotlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "# Modules\n",
    "from visu import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pseudo_label import *\n",
    "depth_paths = getPathsDepth()\n",
    "segmentation_paths = getPathsSegmentation()\n",
    "flow_paths = getFlowPaths()\n",
    "depth_paths = getPathsFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "base = \"/home/jonfrey/datasets/scannet\"\n",
    "image_pths = [str(p) for p in glob( base+'/**/*.jpg', recursive=True ) if str(p).find('color') != -1]\n",
    "fun = lambda x : x.split('/')[-3][-7:] + '_'+ str( \"0\"*(6-len( x.split('/')[-1][:-4]))) + x.split('/')[-1][:-4]  \n",
    "image_pths.sort(key=fun)\n",
    "image_pths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depths\n",
    "base = \"/home/jonfrey/datasets/scannet/scans/scene0000_00/depth_estimate\"\n",
    "depth_pths = [str(p) for p in glob( base+'/**/*.png', recursive=True ) if str(p).find('depth_estimate') != -1 and str(p).find('preview') == -1 ]\n",
    "fun = lambda x : x.split('/')[-3][-7:] + '_'+ str( \"0\"*(6-len( x.split('/')[-1][:-4]))) + x.split('/')[-1][:-4]  \n",
    "depth_pths.sort(key=fun)\n",
    "\n",
    "depth_pths = [d for d in depth_pths if int( d.split('/')[-1][:-4])%10 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flows\n",
    "base = \"/home/jonfrey/results/scannet_eval/run_24h_train_1gpu/scannet\"\n",
    "flow_pths = [str(p) for p in glob( base+'/**/*.png', recursive=True ) if str(p).find('flow') != -1]\n",
    "#flow_low_pths = [str(p) for p in glob( base+'/**/*.png', recursive=True ) if str(p).find('flow_low_') != -1]\n",
    "fun = lambda x :x.split('/')[-3]+ '0'*(8-len((x.split('/')[-1]).split('_')[-1]))+(x.split('/')[-1]).split('_')[-1]\n",
    "flow_pths.sort(key=fun)\n",
    "\n",
    "flow_pths\n",
    "#flow_low_pths.sort(key=fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "base = \"/home/jonfrey/results/scannet_eval/run_24h_train_1gpu\"\n",
    "segmentation_pths = [str(p) for p in glob( base+'/**/*.png', recursive=True ) if str(p).find('segmentation_estimate') != -1]\n",
    "fun = lambda x : x.split('/')[-3][-7:] + '_'+ str( \"0\"*(6-len( x.split('/')[-1][:-4]))) + x.split('/')[-1][:-4]  \n",
    "segmentation_pths.sort(key=fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFlowKITTI(filename):\n",
    "    flow = cv2.imread(filename, cv2.IMREAD_ANYDEPTH|cv2.IMREAD_COLOR)\n",
    "    flow = flow[:,:,::-1].astype(np.float32)\n",
    "    flow, valid = flow[:, :, :2], flow[:, :, 2].astype(bool)\n",
    "    flow = (flow - 2**15) / 64.0\n",
    "    H,W = 960,1280\n",
    "    return flow, valid\n",
    "flow, valid = readFlowKITTI(flow_pths[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDepth(filename): \n",
    "    H,W = 960,1280\n",
    "    im = imageio.imread(filename)\n",
    "    im = im.astype(np.float32)\n",
    "    im = im / 1000\n",
    "    im = ndimage.zoom(im, (H/im.shape[0],W/im.shape[1]) , order=1)\n",
    "    return im\n",
    "readDepth(depth_pths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSegmentation(filename):\n",
    "    im = imageio.imread(filename)\n",
    "    pred = im[:,:,0].astype(np.int32)\n",
    "    target = im[:,:,1].astype(np.int32)\n",
    "    valid = im[:,:,2].astype(bool)\n",
    "    pred -= 1\n",
    "    target -= 1\n",
    "    return pred, target, valid\n",
    "pred, target, valid = readSegmentation(segmentation_pths[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)\n",
    "pred, target, valid = readSegmentation(segmentation_pths[20])\n",
    "#ret = visu.plot_segmentation(seg=pred, jupyter=True)\n",
    "ret = visu.plot_segmentation(seg=target, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow, valid = readFlowKITTI(flow_up_pths[20])\n",
    "ret = visu.plot_flow(flow=flow, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = readDepth(depth_pths[20])\n",
    "ret = visu.plot_depth( depth , jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
