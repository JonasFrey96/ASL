{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"/home/jonfrey/ASL\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/\"\"\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/pseudo_label\"\"\")\n",
    "\n",
    "from pseudo_label.yolo import YoloHelper\n",
    "from pseudo_label.deeplab import DeeplabHelper\n",
    "from pseudo_label.fast_scnn import FastSCNNHelper\n",
    "from pseudo_label.detectron import DetectronHelper\n",
    "from visu import Visualizer\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "yh = YoloHelper()\n",
    "dlh = DeeplabHelper(device=DEVICE)\n",
    "fsh = FastSCNNHelper(device=DEVICE)\n",
    "deh = DetectronHelper(device=DEVICE)\n",
    "\n",
    "# -> visu, yh, dlh, fsh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104cb89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "from math import ceil\n",
    "import torch\n",
    "\n",
    "from utils_asl import load_yaml\n",
    "from task import TaskGenerator\n",
    "from task import TaskGenerator\n",
    "from datasets_asl import get_dataset\n",
    "\n",
    "ASL = os.path.join( str(Path.home()), \"ASL\" )\n",
    "name = os.getenv('ENV_WORKSTATION_NAME')\n",
    "env_cfg_path =os.path.join( ASL, f\"cfg/env/{name}.yml\")  \n",
    "exp_cfg_path =os.path.join( ASL, \"cfg/exp/debug.yml\")\n",
    "eva_cfg_path =os.path.join( ASL, \"cfg/eval/eval.yml\")\n",
    "\n",
    "env = load_yaml(env_cfg_path)\n",
    "\n",
    "use_eva = True\n",
    "if use_eva:\n",
    "  exp = load_yaml(eva_cfg_path)\n",
    "else:\n",
    "  exp = load_yaml(exp_cfg_path)\n",
    "\n",
    "# SETUP DATALOADERS\n",
    "\n",
    "tc = TaskGenerator(**exp['task_generator'], output_size=(640,1280) )\n",
    "\n",
    "use_tc = True\n",
    "if use_tc:    \n",
    "    cfgs = []\n",
    "    for idx, out in enumerate(tc):\n",
    "      task, eval_lists = out\n",
    "      cfgs.append(  task.dataset_train_cfg )\n",
    "else:\n",
    "    cfgs  = [exp['dataset']]\n",
    "\n",
    "for cfg in cfgs:\n",
    "  dataset= get_dataset(\n",
    "    **cfg,\n",
    "    env = env,\n",
    "    output_trafo = None,\n",
    "  )\n",
    "  dataloader = torch.utils.data.DataLoader(dataset,\n",
    "    shuffle = False,\n",
    "    num_workers = exp['loader']['num_workers'],\n",
    "    pin_memory = exp['loader']['pin_memory'],\n",
    "    batch_size = 1, \n",
    "    drop_last = True)\n",
    "  break\n",
    "    \n",
    "# -> dataset, dataloader, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2730c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_acc(label, gt , names = ['detectron', 'fastscnn', 'gt'] ):\n",
    "    m = gt != -1\n",
    "    acc_indi = {}\n",
    "    for l,n in zip(label,names):\n",
    "        correct = ( l[m] == gt[m]).sum()\n",
    "        m2 = m * (l != -1)\n",
    "        total = m2.sum()\n",
    "        acc_indi[n] = correct/total\n",
    "        \n",
    "    # Optimal upper bound\n",
    "    m = gt != -1\n",
    "    m_correct = np.zeros( label[0].shape )\n",
    "    for l,n in zip(label,names):\n",
    "        m_est = l == gt\n",
    "        m_correct[m_est] = 1\n",
    "        \n",
    "    \n",
    "    acc_upper_bound = m_correct[m].sum() / m.sum()\n",
    "    acc_indi['upper_bound'] = acc_upper_bound\n",
    "    return acc_indi\n",
    "# -> get indiviual ACC per network but also upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1fd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24222872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pseudo_label import *\n",
    "\n",
    "class PseudoLabelLoaderOnline():\n",
    "    def __init__(self, image_paths, mapping, h=640, w=1280, sub=10):\n",
    "        self.image_paths = image_paths\n",
    "        self.sub = sub\n",
    "        self.H, self.W= h,w \n",
    "        self.mapping = mapping\n",
    "        \n",
    "    def get_flow(self, global_idx):\n",
    "        flow = []\n",
    "        for idx in global_idx:\n",
    "            fp = self.mapping( self.image_paths[idx] )\n",
    "            \n",
    "            try:\n",
    "                print(\"Flow Path\", fp)\n",
    "                flow.append( readFlowKITTI( fp, H=self.H ,W=self.W))\n",
    "            except:\n",
    "                return False, False\n",
    "        flow.reverse()\n",
    "        return True, flow\n",
    "    \n",
    "def mapping_labdata(s, sub=10):\n",
    "    return s.replace(\"/2/\",f\"/2_flow_sub{sub}/\")\n",
    "def mapping_scannet(s, sub=10):\n",
    "    return str(os.path.join( \"/home/jonfrey/datasets/scannet/flow\", s[s.find('scans'):])).replace('.jpg','.png').replace('color', f'flow_sub{sub}')\n",
    "\n",
    "\n",
    "mapping = mapping_scannet if use_tc else mapping_labdata\n",
    "pllo = PseudoLabelLoaderOnline( \n",
    "    image_paths = dataset.image_pths,\n",
    "    mapping = mapping,\n",
    "    sub=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba068d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_check_labdata(global_idx_list, global_idx_pths, sub=10): \n",
    "    assert len(global_idx_list) > 1\n",
    "    for a,b in zip(global_idx_list[:-1], global_idx_list[1:]):\n",
    "        a = int(global_idx_pths[a].split('/')[-1].replace(\"undistorted_frame\",\"\")[:-4])\n",
    "        b = int(global_idx_pths[b].split('/')[-1].replace(\"undistorted_frame\",\"\")[:-4])\n",
    "        if a + sub != b:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "TODO:\n",
    "- Depth\n",
    "- BoundingBox Predicitons\n",
    "\"\"\"\n",
    "from torch.nn.functional import one_hot\n",
    "class PseudoLabelGenerator():\n",
    "    def __init__(self, base_path, sub=10, confidence='equal', \n",
    "            flow_mode='sequential', H=640, W=1280, \n",
    "            nc=40, refine_superpixel=True,\n",
    "            get_depth_superpixel=False,window_size=10,\n",
    "            visu=None, pre_fusion_function=None, visu_active=True, cfg_loader={}):\n",
    "        \"\"\"  \n",
    "        confidence:\n",
    "          'equal': perfect optical flow -> all project labels are equally good\n",
    "          'linear': linear rate -> per frame\n",
    "          'exponential': exponential rate -> per frame \n",
    "        flow_mode:\n",
    "          'sequential': #-> 0->1, 1->2, 2->3\n",
    "          'target': 0->3 1->3 2->3\n",
    "        \"\"\"\n",
    "        self._visu_active = visu_active\n",
    "        self._sub = sub\n",
    "        self._flow_mode = flow_mode #'sequential' #-> 0->1, 1->2, 2->3 # 'target' 0->3 1->3 2->3\n",
    "        self._H,self._W = H,W\n",
    "        self._confidence= confidence # equal, linear, exponential\n",
    "        self._nc = nc\n",
    "        self._refine_superpixel = refine_superpixel\n",
    "        self._get_depth_superpixel = get_depth_superpixel\n",
    "        self._window_size = window_size\n",
    "        self._pll = PseudoLabelLoader(base_path = base_path, window_size=window_size, sub=10, h=H,w=W, **cfg_loader )\n",
    "        self._ignore_depth = cfg_loader.get(\"ignore_depth\",False)\n",
    "\n",
    "        # Passed externally\n",
    "        self._visu = visu\n",
    "        self._pre_fusion_function = pre_fusion_function\n",
    "    def __len__(self):\n",
    "      return self._pll.length\n",
    "\n",
    "    def get_gt_label(self, index):\n",
    "        seg, depth, flow, paths = self._pll[index] \n",
    "        return seg[0][1]\n",
    "    \n",
    "    def get_img(self, index):\n",
    "        return self._pll.getImage(index)\n",
    "    \n",
    "    def get_depth(self, index):\n",
    "        seg, depth, flow, paths = self._pll[index]\n",
    "        return depth[0]\n",
    "    \n",
    "    def calculate_label(self, index=None, seg=[],flow=[], image= None ):\n",
    "        if not index is None:\n",
    "            seg_forwarded= self._forward_index(index, self._pre_fusion_function) #return H,W,C\n",
    "        else:\n",
    "            seg_forwarded = self._forward_index(index, seg, flow, self._pre_fusion_function)\n",
    "        \n",
    "        if self._visu_active:\n",
    "            self._visu_seg_forwarded(seg_forwarded)\n",
    "\n",
    "        # -1 39 -> 0 -> 40 We assume that the network is also able to predict the invalid class\n",
    "        # In reality this is not the case but this way we can use the ground truth labels for testing\n",
    "        \n",
    "        if seg_forwarded[0].shape[2] == 1:\n",
    "            for i in range(len( seg_forwarded) ):\n",
    "                seg_forwarded[i] += 1\n",
    "                seg_forwarded[i][seg_forwarded[i]>40] = 40\n",
    "        confidence_values_list = self._get_confidence_values(seq_length= len(seg_forwarded))\n",
    "        if seg_forwarded[0].shape[2] == 1:\n",
    "            import pdb; pdb.set_trace()\n",
    "            one_hot_acc = np.zeros( (*seg_forwarded[0].shape, self._nc+1), dtype=np.float32) # H,W,C\n",
    "            \n",
    "            for conf, seg in zip(confidence_values_list, seg_forwarded):    \n",
    "                one_hot_acc += (np.eye(self._nc+1)[seg.astype(np.int32)]).astype(np.float32) * conf\n",
    "            one_hot_acc = one_hot_acc[:,:,0,:]\n",
    "            invalid_labels = np.sum( one_hot_acc[:,:,1:],axis=2 ) == 0\n",
    "            \n",
    "        \n",
    "        label = np.argmax( one_hot_acc[:,:,1:], axis=2 )\n",
    "        label[ invalid_labels ] = -1 \n",
    "        \n",
    "#         if self._visu_active:\n",
    "#             print(\"Aggregated Label\")\n",
    "#             self._visu.plot_segmentation(seg= label+1, jupyter=True)\n",
    "\n",
    "#         if self._refine_superpixel:\n",
    "#             if image is None:\n",
    "#                 img = self._pll.getImage(index).astype(np.float32)/256\n",
    "#             else:\n",
    "#                 img = image\n",
    "                \n",
    "#             label_super, img, segments = self._superpixel_label(img, label)\n",
    "#             if self._visu_active:\n",
    "#                 print(\"Label Superpixel\")\n",
    "#                 self._visu.plot_segmentation(seg= label_super + 1, jupyter=True)  \n",
    "#                 self._visu.plot_image(img=img, jupyter=True)  \n",
    "#                 self._visu_superpixels(img, segments)\n",
    "#             label = label_super\n",
    "#         print( \"Time rest\", time.time()-st)\n",
    "#         if self._get_depth_superpixel:\n",
    "#             self._superpixel_depth(depth_forwarded[-1], label)\n",
    "        return label, (seg_forwarded[-1]-1).astype(np.int32)\n",
    "    \n",
    "    def _get_confidence_values( self, seq_length ):\n",
    "        if self._confidence == 'equal':\n",
    "            return [float( 1/seq_length)] * seq_length \n",
    "\n",
    "        if self._confidence == 'linear':\n",
    "            ret = []\n",
    "            lin_rate = 0.1\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = 1 - lin_rate* (seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "\n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "        elif self._confidence == 'exponential':\n",
    "            ret = []\n",
    "            exp_rate = 0.8\n",
    "            s = 0\n",
    "            for i in range(seq_length):\n",
    "                res = exp_rate**(seq_length-i)\n",
    "                if res < 0: \n",
    "                    res = 0\n",
    "                s += res\n",
    "                ret.append(res)\n",
    "            return [r/s for r in ret]\n",
    "\n",
    "\n",
    "    def _forward_index(self, index=None, seg=[],flow=[] ,pre_fusion_function=None ):\n",
    "        \"\"\"\n",
    "        seg[0] , C,H,W\n",
    "        \n",
    "        pre_fusion_function should be used to integrate the depth measurments \n",
    "        to the semseg before forward projection !\n",
    "\n",
    "        seg_forwarded[0] -> oldest_frame\n",
    "        seg_forwarded[len(seg_forwarded)] -> latest_frame not forwarded\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if not index is None:\n",
    "            if pre_fusion_function is None:\n",
    "                seg, _, flow, _ = self._pll[index]\n",
    "            else:\n",
    "                seg, _, flow, _ = pre_fusion_function( self._pll[index] )\n",
    "        \n",
    "        if len( seg[0].shape ) == 3 and seg[0].shape[0] != 1:\n",
    "            soft = True\n",
    "        else:\n",
    "            soft = False\n",
    "            \n",
    "        assert self._flow_mode == 'sequential'\n",
    "        seg_forwarded = []\n",
    "        \n",
    "        for j in range(len( seg )):\n",
    "            seg[j] = np.moveaxis( seg[j], [0,1,2], [2,0,1] ) #C,H,W -> H,W,C\n",
    "        \n",
    "        for i in range(0,len(seg)-1):\n",
    "            i = len(seg)-1-i\n",
    "            seg_forwarded.append( seg[i].astype(np.float32) )\n",
    "\n",
    "            \n",
    "            # start at oldest frame\n",
    "            if i != 0:\n",
    "                f = flow[i][0]\n",
    "            else:\n",
    "                f = np.zeros(flow[i][0].shape, dtype=np.float32)\n",
    "            \n",
    "            h_, w_ = np.mgrid[0:self._H, 0:self._W].astype(np.float32)\n",
    "            h_ -= f[:,:,1]\n",
    "            w_ -= f[:,:,0]\n",
    "\n",
    "            j = 0\n",
    "            for s in seg_forwarded : #  seg_forwarded, depth_forwarded\n",
    "                if soft:\n",
    "                    s = cv2.remap( s, w_, h_, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "                else:\n",
    "                    s = cv2.remap( s[None], w_, h_, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=-1)[None]\n",
    "                seg_forwarded[j] = s\n",
    "                \n",
    "                j += 1\n",
    "    \n",
    "        if not soft:\n",
    "            for i in range(len( seg_forwarded) ):\n",
    "                seg_forwarded[i] = np.moveaxis(  seg_forwarded[i] , [0,1,2], [2,0,1] )\n",
    "        seg_forwarded.append( seg[0] )\n",
    "        return seg_forwarded # H,W,C\n",
    "\n",
    "\n",
    "    def _visu_seg_forwarded(self, seg):\n",
    "        s = int( len(seg) ** 0.5 )\n",
    "        ba = torch.zeros( (int(s*s),3, *seg[0].shape), dtype= torch.float32 )\n",
    "        for i in range( int(s*s) ) :\n",
    "            ba[i,:] = torch.from_numpy( seg[-(i+1)] )[None,:,:].repeat(3,1,1)\n",
    "        grid_ba = make_grid( ba ,nrow = s ,padding = 2,\n",
    "          scale_each = False, pad_value = -1)[0]\n",
    "        self._visu.plot_segmentation(seg= grid_ba +1 , jupyter=True)\n",
    "\n",
    "    def _superpixel_label(self, img, label, segments=250):\n",
    "        assert segments < 256 #I think slic fails if segments > 256 given that a 8bit uint is returend!\n",
    "\n",
    "        segments = slic(img, n_segments = segments, sigma = 5, start_label=0)\n",
    "        # show the output of SLIC\n",
    "        out_label = copy.copy(label)\n",
    "        for i in range(0,segments.max()):\n",
    "            m1 = segments == i\n",
    "            m = m1 * ( label != -1 )\n",
    "            unique_val, unique_counts = np.unique( label [m], return_counts=True)\n",
    "            # fill a segment preferable not with invalid !\n",
    "            if unique_counts.shape[0] == 0:\n",
    "                val = -1\n",
    "            else:\n",
    "                ma = unique_counts == unique_counts.max()\n",
    "                while ma.sum() != 1:\n",
    "                    ma[np.random.randint(0,ma.shape[0])] = False\n",
    "                val = unique_val[ma]\n",
    "            out_label[m1] = val \n",
    "\n",
    "        return out_label, img, segments\n",
    "    \n",
    "    def _visu_superpixels(self, img, segments):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from skimage.segmentation import mark_boundaries\n",
    "        fig = plt.figure(\"Superpixels -- segments\" )\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.imshow(mark_boundaries(img, segments))\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# plg_ws_2 = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "#                            visu=visu,\n",
    "#                            window_size=window_size_2,\n",
    "#                           cfg_loader = {\"ignore_depth\": True},\n",
    "#                           visu_active=plot,\n",
    "#                           refine_superpixel=False)\n",
    "# pseudo_2, _ = plg_ws_2.calculate_label(\n",
    "#                         index=None, \n",
    "#                         seg= seg[:window_size_2], \n",
    "#                         flow= flow_list[:window_size_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80455205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pseudo_label import readSegmentation\n",
    "import time\n",
    "from torchvision import transforms as tf\n",
    "import copy\n",
    "# from torch import one_hot_acc\n",
    "st = time.time()\n",
    "counts = 0\n",
    "counts_flow = 0\n",
    "length = len(dataloader)\n",
    "globale_idx_to_image_path = dataset.image_pths\n",
    "\n",
    "segmentation_list_fastscnn = []\n",
    "global_idx_list = []\n",
    "\n",
    "plot = False\n",
    "# PARAMS LABEL GENERATION\n",
    "weights = [2,0.5,1]\n",
    "weights2 = [1,0.5,1]\n",
    "window_size_2 = 3\n",
    "window_size = 3\n",
    "\n",
    "sub = 10\n",
    "\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "plg = PseudoLabelGenerator(base_path='/home/jonfrey/results/scannet_pseudo_label/scannet', \n",
    "    visu=visu,\n",
    "    window_size=window_size,\n",
    "    cfg_loader = {\"ignore_depth\": True},\n",
    "    visu_active=plot,\n",
    "    refine_superpixel=False)\n",
    "\n",
    "def plot_pseudo_labes( res, jupyter = False, label=False, save=True, out_pth =\"\"):\n",
    "    key_list = list(res.keys())\n",
    "    s = int( len( key_list ) ** 0.5 )\n",
    "    if len( key_list ) - s*s != 0:\n",
    "        s +=1\n",
    "    ba = torch.zeros( (int(s*s),3, *res[key_list[0]].shape), dtype= torch.float32 )\n",
    "    ref_img = copy.deepcopy( res['img'] )\n",
    "    for i in range( len( key_list ) ):\n",
    "        k = key_list[i]\n",
    "        if k.find(\"img\") == -1:\n",
    "            img = visu.plot_detectron( img = copy.deepcopy(ref_img ), label = res[k]+1 )\n",
    "        else:\n",
    "            img = res[k]\n",
    "            \n",
    "        img = Image.fromarray(img)\n",
    "        if label:\n",
    "            img = img.convert(\"RGBA\")\n",
    "            d = ImageDraw.Draw(img)\n",
    "            fnt = ImageFont.truetype(\"/usr/share/fonts/truetype/ttf-dejavu/DejaVuSansMono-Bold.ttf\", 50)   \n",
    "            d.rectangle(((550, 500), (1400, 600)), fill=(254,10,10))\n",
    "            d.text((600,530), k , font=fnt, fill=(254,254,254,254))\n",
    "            img =  img.convert(\"RGB\")\n",
    "        if save:\n",
    "            out_pth = out_pth.replace(\"/2/\", f\"/2_{k}/\")\n",
    "            Path(out_pth).parent.mkdir(parents=True, exist_ok=True)\n",
    "            print( out_pth)\n",
    "            img.save( out_pth )\n",
    "        \n",
    "        img = np.array( img )\n",
    "        ba[i,:] = torch.from_numpy( img[:,:,:3] ).permute(2,0,1)\n",
    "    \n",
    "    grid_ba = make_grid( ba ,nrow = s ,padding = 2, scale_each = False, pad_value = 0)\n",
    "    return visu.plot_image(img = grid_ba, jupyter= jupyter)\n",
    "\n",
    "\n",
    "down = tf.Resize((320,640))\n",
    "up = tf.Resize((640,1280))\n",
    "label_list = []\n",
    "\n",
    "def print_acc(acc_dict, counts, counts_flow):\n",
    "    avg = {}\n",
    "    for k in acc_dict.keys():\n",
    "        if k.find('flow') != -1:\n",
    "            avg  = acc_dict[k] / counts_flow\n",
    "        else:\n",
    "            avg = acc_dict[k] / counts\n",
    "    \n",
    "        print(k ,\": \", avg)\n",
    "\n",
    "for j, batch in enumerate( dataloader ):\n",
    "    # START EVALUATION \n",
    "    if j > 10:\n",
    "        break \n",
    "        \n",
    "    images = batch[0]\n",
    "    target = batch[1]\n",
    "    ori_img = batch[2]\n",
    "    replayed = batch[3]\n",
    "    BS = images.shape[0]\n",
    "    global_idx = batch[4] \n",
    "    \n",
    "    print(\"Input image\", images.max(), images.min())\n",
    "    images *= 255\n",
    "    images = images.permute(0,2,3,1).numpy().astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    pri = False\n",
    "    \n",
    "    \n",
    "    for b in range( images.shape[0] ):\n",
    "        # EVALUATE SEMANTIC SEGMENTATION NETWORKS\n",
    "        label = {}\n",
    "        st_ = time.time()\n",
    "        prob_de = deh.get_label_prob( images[b] )\n",
    "        \n",
    "        inp = down(torch.from_numpy( images[b]).permute(2,0,1)).permute(1,2,0).numpy()\n",
    "        prob_fastscnn = fsh.get_label_prob( inp )\n",
    "        prob_fastscnn = up ( torch.from_numpy( prob_fastscnn[None]) )[0].numpy()\n",
    "        \n",
    "        label['fastscnn'] = np.argmax( prob_fastscnn[:] , axis=0)-1\n",
    "        label['detectron'] = np.argmax( prob_de, axis=0)-1\n",
    "        \n",
    "        # RINGBUFFER THE PREDICTIONS\n",
    "        label_list.append( copy.deepcopy( label) )\n",
    "        global_idx_list.append(int( global_idx[b] ))\n",
    "        if len(label_list) > window_size:\n",
    "            label_list = label_list[-window_size:]\n",
    "            global_idx_list = global_idx_list[-window_size:]\n",
    "            \n",
    "            # GET THE FLOW BETWEEN THE FRAMES\n",
    "            suc, flow_list = pllo.get_flow( global_idx = global_idx_list)\n",
    "            \n",
    "            # CHECK IF THE GLOBAL IDX LIST ALIGNS\n",
    "            suc *= index_check_labdata(global_idx_list= global_idx_list, \n",
    "                                       global_idx_pths=globale_idx_to_image_path, \n",
    "                                       sub=10)    \n",
    "                \n",
    "            # CREATE PSEUDO LABEL\n",
    "            if suc:\n",
    "                st_ = time.time()\n",
    "                for k in list( [\"detectron\",\"fastscnn\"] ): \n",
    "                \n",
    "                    seg = [ s[k][None] for s in label_list ]\n",
    "                    # seg[0] 1,H,W\n",
    "                    seg.reverse()\n",
    "                    pseudo_label, _ = plg.calculate_label(index=None, \n",
    "                                                          seg=copy.deepcopy(seg), \n",
    "                                                          flow=copy.deepcopy(flow_list) )\n",
    "                    label[k+'_normal_flow'] = pseudo_label\n",
    "                \n",
    "                \n",
    "                print(\"time to create all pseudo labels\", time.time()-st_ )   \n",
    "                pri =True\n",
    "                counts_flow += 1\n",
    "\n",
    "\n",
    "        # EVALUATE ALL LABELS\n",
    "        ret = get_max_acc( label = list(label.values()), gt=target[b].numpy(), names=list( label.keys()))\n",
    "        \n",
    "        print(\"Return values\" , ret)\n",
    "        for k in ret.keys():\n",
    "            if k in acc_dict:\n",
    "                acc_dict[k] += ret[k]\n",
    "            else:\n",
    "                acc_dict[k] = ret[k]\n",
    "        counts += 1\n",
    "\n",
    "    #     LOGGING\n",
    "    if (j % 1) == 0 and j != 0:\n",
    "        print_acc(acc_dict,counts,counts_flow)\n",
    "        mini =int((time.time()-st)/60)\n",
    "        mini_left = int((time.time()-st)/j*(length-j)/60)\n",
    "        print(f'{j}/{length} Total time elapsed: {mini}min; Projected finish in {mini_left}min')\n",
    "        plot = label\n",
    "        print(images[b].max(), images[b].min() )\n",
    "        \n",
    "        plot['img'] =  images[b]\n",
    "        plot['gt'] = target[b].numpy()\n",
    "        \n",
    "        try:\n",
    "            plot['img_flow'] = visu.plot_flow(flow= flow_list[1][0])\n",
    "        except:\n",
    "            print(\"no flow\")\n",
    "        \n",
    "        out_pth = globale_idx_to_image_path[ global_idx_list[-1] ]    \n",
    "        res = plot_pseudo_labes( plot, jupyter = True, label=True, save=False, out_pth = out_pth )\n",
    "#         img = Image.fromarray(res)\n",
    "#         display(img)\n",
    "#         out_pth = globale_idx_to_image_path[ global_idx_list[-1] ].replace(\"/2/\", \"/2_all/\")   \n",
    "#         Path(out_pth).parent.mkdir(parents=True, exist_ok=True)\n",
    "#         img.save( out_pth )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0511a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot['img'] = np.uint8( (dataloader.dataset[0][0]*255).permute(1,2,0)[b].cpu().numpy() )\n",
    "# plot['gt'] = target[b].numpy()\n",
    "globale_idx_to_image_path[ global_idx_list[-1] ]    \n",
    "\n",
    "# Image.fromarray( np.uint8((((batch[0][0].cpu().permute(1,2,0) )*255).numpy()))) \n",
    "# img = Image.fromarray( plot['img'] )\n",
    "# display(img)\n",
    "# Image.fromarray(  np.uint8(  dataloader.dataset[0][0].permute(1,2,0) * 255 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape\n",
    "# batch[0][0].permute(0,1,2).shape\n",
    "ay = np.uint8( (batch[0][0]).permute(0,1,2).cpu().numpy()*255) \n",
    "ay.shape, ay.dtype\n",
    "\n",
    "ay = np.zeros((10,10,3), dtype=np.uint8)\n",
    "from PIL import Image\n",
    "Image.fromarray(ay)\n",
    "# Image.fromarray( np.uint8( (batch[0][0]).permute(0,1,2).cpu().numpy()*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "def print_acc(acc_dict, counts, counts_flow):\n",
    "    avg = {}\n",
    "    \n",
    "    for k in acc_dict.keys():\n",
    "        if k.find('flow') != -1:\n",
    "            avg[k]  = acc_dict[k] / counts_flow\n",
    "        else:\n",
    "            avg[k] = acc_dict[k] / counts\n",
    "    return avg\n",
    "\n",
    "res = print_acc( acc_dict, counts, counts_flow)\n",
    "res\n",
    "x_label = [k for k in res.keys()]\n",
    "data = np.array( [res[k] for k in res.keys()] )\n",
    "y_label='Acc'\n",
    "title = \"PseudoLabelAcc\"\n",
    "\n",
    "# if type(data) == list:\n",
    "#     pass\n",
    "# elif type(data) == torch.Tensor:\n",
    "#     data = check_shape(data)\n",
    "#     data = list( data.clone().cpu())\n",
    "# elif type(data) == np.ndarray:\n",
    "#     data = check_shape(data)\n",
    "#     data = list(data)\n",
    "# else:\n",
    "#     raise Exception(\"plot_hist: Unknown Input Type\"+str(type(data)))\n",
    "# data = data.tolist()\n",
    "# if sort:\n",
    "#     data.sort(reverse=reverse)\n",
    "fig,ax = plt.subplots()\n",
    "# fig,ax = plt.figure()\n",
    "plt.bar(list(range(len(data))), data )\n",
    "ax.set_xticks(np.arange(len(x_label)))\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_xticklabels(x_label)\n",
    "# plt.xlabel(x_label,rotation=90)\n",
    "plt.ylabel(y_label)\n",
    "plt.title(title)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt\n",
    "# arr = get_img_from_fig(fig, dpi=300)\n",
    "# plt.close()\n",
    "# return np.uint8(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xticks(np.arange(len(label_x)))\n",
    "    ax.set_yticks(np.arange(len(label_y)))\n",
    "    ax.set_xticklabels(list(mappings['nyu_name_id'].keys())[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
