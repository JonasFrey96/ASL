{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gradient statistic -> over full dataset\n",
    "# For each weight -> mean and std.\n",
    "\n",
    "import os\n",
    "import sys \n",
    "os.chdir(os.path.join(os.getenv('HOME'), 'ASL'))\n",
    "sys.path.insert(0, os.path.join(os.getenv('HOME'), 'ASL'))\n",
    "sys.path.append(os.path.join(os.path.join(os.getenv('HOME'), 'ASL') + '/src'))\n",
    "\n",
    "from torchvision import transforms as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils_asl import file_path, load_yaml\n",
    "from models_asl import FastSCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP MODEL\n",
    "\n",
    "eval_cfg_path=\"cfg/eval/eval.yml\"\n",
    "env_cfg_path = os.path.join('cfg/env', os.environ['ENV_WORKSTATION_NAME']+ '.yml')\n",
    "env_cfg = load_yaml(env_cfg_path)\t\n",
    "eval_cfg = load_yaml(eval_cfg_path)\n",
    "device= \"cuda\"\n",
    "model = FastSCNN(**eval_cfg['model']['cfg'])\n",
    "\n",
    "\n",
    "p = os.path.join( env_cfg['base'], eval_cfg['checkpoint_load'])\n",
    "print(p)\n",
    "\n",
    "def load(model, p):\n",
    "    if os.path.isfile( p ):\n",
    "        res = torch.load(p)\n",
    "        new_statedict = {}\n",
    "        for k in res['state_dict'].keys():\n",
    "            if k.find('model.') != -1: \n",
    "                new_statedict[ k[6:]] = res['state_dict'][k]\n",
    "        res = model.load_state_dict( new_statedict, strict=True)\n",
    "        print('Restoring weights: ' + str(res))\n",
    "    else:\n",
    "        raise Exception('Checkpoint not a file')\n",
    "    return model\n",
    "model = load(model,p)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_asl import get_dataset\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "\n",
    "# SETUP DATALOADER\n",
    "dataset_test = get_dataset(\n",
    "  **eval_cfg['dataset'],\n",
    "  env = env_cfg,\n",
    "  output_trafo = None\n",
    "  )\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test,\n",
    "  shuffle = False,\n",
    "  num_workers = 0,\n",
    "  pin_memory = True,\n",
    "  batch_size = 2, \n",
    "  drop_last = True)\n",
    "\n",
    "globale_idx_to_image_path = dataset_test.image_pths\n",
    "from visu import Visualizer\n",
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task import TaskCreator\n",
    "from datasets_asl import get_dataloader_train, eval_lists_into_dataloaders\n",
    "\n",
    "def get_mutiple_dataloaders(exp, env, train=True):\n",
    "    tc = TaskCreator(**exp['task_generator'],output_size=exp['dataset']['output_size'])\n",
    "    ret_list = []\n",
    "    for t in tc:\n",
    "        task, eval_lists = t\n",
    "        dataloader_train, dataloader_buffer= get_dataloader_train(d_train= task.dataset_train_cfg,\n",
    "                                                              env=env,exp = exp)\n",
    "        if train: \n",
    "            ret_list.append( dataloader_train )\n",
    "        else: \n",
    "            # RETURNS ALL VALIDATION DATALOADERS\n",
    "            return eval_lists_into_dataloaders(eval_lists, env=env, exp=exp)\n",
    "    return ret_list\n",
    "        \n",
    "dataloader_list = get_mutiple_dataloaders(exp = eval_cfg , env = env_cfg, train=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [ '/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task0-epoch=29--step=016259.ckpt',\n",
    "'/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task1-epoch=63--step=030846.ckpt',\n",
    "'/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task2-epoch=95--step=045503.ckpt',\n",
    "'/media/scratch1/jonfrey/models/cluster/2021-03-19T19:20:20_check_val_every_2_random/task3-epoch=135--step=060290.ckpt']\n",
    "print( model_paths )\n",
    "for f in dataloader_list:\n",
    "    print(f.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTED AND WORKS\n",
    "import copy\n",
    "\n",
    "def get_grad( named_params ):\n",
    "    summary_grad = []\n",
    "    for i, (n,p) in enumerate( named_params ):\n",
    "        if p.grad is not None:  \n",
    "            summary_grad.append( p.grad.view(-1).detach()  )\n",
    "    summary_grad = torch.cat( summary_grad )\n",
    "    return summary_grad\n",
    "\n",
    "def write_back_grad( grad, named_params ):\n",
    "    count = 0\n",
    "            \n",
    "    for i, (n,p) in enumerate( named_params ):\n",
    "        if p.grad is not None:\n",
    "            s = p.grad.shape\n",
    "            c = p.grad.view(-1).shape[0]\n",
    "            new_grad = grad[count: (count+c) ].contiguous().view(s)\n",
    "            p.grad.data.copy_(new_grad)  \n",
    "            count +=c\n",
    "\n",
    "def project(g: torch.Tensor, g_ref: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "    corr = torch.dot(g , g_ref) / torch.dot(g_ref, g_ref)\n",
    "    return g - corr * g_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = True\n",
    "\n",
    "trafo = tf.Compose([\n",
    "      tf.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
    "      tf.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "\n",
    "model = load(model, model_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, batch in enumerate( dataloader_test ):\n",
    "    # START EVALUATION  \n",
    "    images = (batch[0]).cuda()\n",
    "    target = batch[1].cuda()\n",
    "    ori_img = batch[2]\n",
    "    replayed = batch[3]\n",
    "    BS = images.shape[0]\n",
    "    global_idx = batch[4] \n",
    "    \n",
    "    if augmentation:\n",
    "                images = trafo(images)\n",
    "    if j > 1:\n",
    "        break\n",
    "        \n",
    "    if j == 0: \n",
    "            # normal forward pass and store gradient\n",
    "            \n",
    "            ret = model(images)\n",
    "            loss = F.cross_entropy(ret[0], target, ignore_index=-1)\n",
    "            loss.backward()\n",
    "            g_ref = get_grad( model.named_parameters() )\n",
    "    if j == 1:\n",
    "            ret = model(images)\n",
    "            loss = F.cross_entropy(ret[0], target, ignore_index=-1)\n",
    "            loss.backward()\n",
    "            g = get_grad( model.named_parameters() )\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "g_tilde = project( g, g_ref)\n",
    "write_back_grad( g_tilde, model.named_parameters() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        print(\"init\")\n",
    "        self.b = 2\n",
    "    def test(self):\n",
    "        print ( hasattr(self, 'b') )\n",
    "        print ( hasattr(self, 'a') )\n",
    "        a = self.b\n",
    "        print (locals())\n",
    "        print( \"a_variable\" in locals() )\n",
    "tei = Test()\n",
    "tei.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track3",
   "language": "python",
   "name": "track3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
