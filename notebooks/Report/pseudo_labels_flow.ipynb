{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"/home/jonfrey/ASL\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/\"\"\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/pseudo_label\"\"\")\n",
    "\n",
    "import numpy as np\n",
    "from visu import Visualizer\n",
    "import imageio\n",
    "\n",
    "\n",
    "# STD\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# MISC\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943181e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "\n",
    "def readFlowKITTI(filename):\n",
    "    flow = cv2.imread(filename, cv2.IMREAD_ANYDEPTH|cv2.IMREAD_COLOR)\n",
    "    flow = flow[:,:,::-1].astype(np.float32)\n",
    "    flow, valid = flow[:, :, :2], flow[:, :, 2].astype(bool)\n",
    "    flow = (flow - 2**15) / 64.0\n",
    "    H,W = 960,1280\n",
    "    return flow, valid\n",
    "#flow, valid = readFlowKITTI(flow_pths[10])\n",
    "\n",
    "# GENERATION METHOD FLOW\n",
    "def load_image(imfile):\n",
    "    img = np.array(Image.open(imfile)).astype(np.uint8)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    img = img[:, 12:-12, 12:-12]\n",
    "    return img[None]\n",
    "\n",
    "# GENERATION METHOD LABELS\n",
    "H,W = 640, 1280\n",
    "def readImage(filename, H=640, W=1280, scale=True):\n",
    "    _crop_center = tf.CenterCrop((H,W))\n",
    "    img = Image.open(filename)    \n",
    "    if scale:\n",
    "        img = _crop_center( img )\n",
    "    return np.array( img )   \n",
    "\n",
    "from utils_asl import LabelLoaderAuto\n",
    "lla = LabelLoaderAuto(root_scannet=\"/home/jonfrey/Datasets/scannet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317518ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)\n",
    "\n",
    "i0= \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/300.jpg\"\n",
    "l0 = \"/home/jonfrey/Datasets/labels_generated/create_labels_from_pretrained/scans/scene0000_00/create_labels_from_pretrained/300.png\"\n",
    "f0 = \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/flow_sub_10/flow_up_300.png\"\n",
    "l0_gt = \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/label-filt/300.png\"\n",
    "def get_aligned_flow(f):\n",
    "    return readFlowKITTI(f)\n",
    "def get_alinged_label(l):\n",
    "    return lla.get(l)[0][12:-12, 12:-12]\n",
    "\n",
    "def get_aligned_image(i):\n",
    "    return readImage(i, H=640, W=1280, scale=False)[ 12:-12, 12:-12,:]\n",
    "def get_alinged_label_probs(l):\n",
    "    return lla.get_probs(l)[12:-12, 12:-12]\n",
    "\n",
    "f,l,i,l_gt = get_aligned_flow(f0),get_alinged_label(l0),get_aligned_image(i0),get_alinged_label(l0_gt)\n",
    "l_soft = get_alinged_label_probs(l0)\n",
    "\n",
    "textwidth = 12.7 #cm\n",
    "fig, ax = plt.subplots(1, 4, figsize=(textwidth, 2.3), sharex=False, sharey=False)\n",
    "left  = 0.05  # the left side of the subplots of the figure\n",
    "right = 0.99    # the right side of the subplots of the figure\n",
    "bottom = 0.3   # the bottom of the subplots of the figure\n",
    "top = 0.88      # the top of the subplots of the figure\n",
    "wspace = 0.25   # the amount of width reserved for blank space between subplots\n",
    "hspace = 0.2  # the amount of height reserved for white space between subplots\n",
    "plt.subplots_adjust(left=left, bottom=bottom, right=right, top=top, wspace=wspace, hspace=hspace)\n",
    "\n",
    "\n",
    "ax[0].imshow( visu.plot_image(i,jupyter=False))\n",
    "ax[1].imshow(  visu.plot_flow(f[0],jupyter=False))\n",
    "ax[2].imshow( visu.plot_detectron(i, l,jupyter=False))\n",
    "ax[3].imshow( visu.plot_detectron(i, l_gt,jupyter=False))\n",
    "\n",
    "for a in fig.axes:\n",
    "    a.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6dc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "l = slic(i,n_segments=40, compactness=10.0)\n",
    "res = visu.plot_detectron(i, l,jupyter=True,text_off =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "i0= \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/0.jpg\"\n",
    "l0 = \"/home/jonfrey/Datasets/labels_generated/create_labels_from_pretrained/scans/scene0000_00/create_labels_from_pretrained/0.png\"\n",
    "f0 = \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/flow_sub_10/flow_up_0.png\"\n",
    "l0_gt = \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/label-filt/0.png\"\n",
    "\n",
    "images = [str(s) for s in Path( \"/home/jonfrey/Datasets/scannet/scans/scene0000_00/color/\").rglob('*.jpg')]\n",
    "images.sort(\n",
    "    key=lambda x: int(x.split(\"/\")[-3][-7:]) * 10000 + int(x.split(\"/\")[-1][:-4])\n",
    ")\n",
    "flows = [ i.replace(\"color/\",\"flow_sub_10/flow_up_\").replace(\".jpg\",\".png\") for i in images]\n",
    "labels_gt = [ f.replace(\"flow_sub_10/flow_up_\",\"label-filt/\") for f in flows]\n",
    "labels_pred = [ f.replace(\"/home/jonfrey/Datasets/scannet/scans/scene0000_00/flow_sub_10/flow_up_\",\"/home/jonfrey/Datasets/labels_generated/create_labels_from_pretrained/scans/scene0000_00/create_labels_from_pretrained/\") for f in flows]\n",
    "\n",
    "n = 0\n",
    "f = get_aligned_flow(flows[n])\n",
    "l_pred_hard = get_alinged_label(labels_pred[n])\n",
    "i = get_aligned_image(images[n])\n",
    "l_gt = get_alinged_label(labels_gt[n])\n",
    "l_pred_soft = get_alinged_label_probs( labels_pred[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class AccMonitor():\n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "        self.metric_dict = {'correct': 0,\n",
    "                            'correct_valid': 0,\n",
    "                            'correct_valid_both': 0,\n",
    "                            'total': 0, \n",
    "                            'total_valid':0,\n",
    "                            'total_valid_both':0,\n",
    "                            'images': 0}\n",
    "    def register(self,name):\n",
    "        self.metrics[name] = copy.deepcopy(self.metric_dict)\n",
    "        \n",
    "    def update(self,name, label, gt):\n",
    "        if name not in self.metrics.keys():\n",
    "            self.register(name)\n",
    "        m1 = gt != -1\n",
    "        self.metrics[name][\"total_valid\"] += (m1).sum()\n",
    "        self.metrics[name][\"correct_valid\"] += np.sum(gt[m1] == label[m1])\n",
    "        \n",
    "        m2 = (gt != -1 )*(label != -1)\n",
    "        self.metrics[name][\"total_valid\"] += (m2).sum()\n",
    "        self.metrics[name][\"correct_valid\"] += np.sum(gt[m2] == label[m2])\n",
    "        \n",
    "        self.metrics[name][\"total\"] += gt.size\n",
    "        self.metrics[name][\"correct\"] += np.sum(gt == label)\n",
    "        self.metrics[name][\"images\"] += 1\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"Acc-Monitor:\\n\"\n",
    "        for k in self.metrics.keys():\n",
    "            acc = self.metrics[k]['correct_valid'] / self.metrics[k]['total_valid']\n",
    "            s += f\"  {k}: Nr-Images: {self.metrics[k]['images']} , Avg-Acc: {acc} \\n\"  \n",
    "        return s\n",
    "        \n",
    "accm = AccMonitor()\n",
    "accm.update(\"Test\", np.ones( (100,100)) ,np.ones( (100,100)))\n",
    "accm.update(\"Test2\", np.ones( (100,100)) ,np.ones( (100,100)))\n",
    "print(accm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db304fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "TODO:\n",
    "- Depth\n",
    "- BoundingBox Predicitons\n",
    "\"\"\"\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "\n",
    "def get_confidence_values( seq_length ):\n",
    "    return [float( 1/seq_length)] * seq_length \n",
    "\n",
    "def calculate_label( index=None, seg=[],flow=[], img=[] ):\n",
    "    seg_forwarded, img_forwarded = forward_labels( seg, flow, img)\n",
    "    # -1 39 -> 0 -> 40 We assume that the network is also able to predict the invalid class\n",
    "    # In reality this is not the case but this way we can use the ground truth labels for testing\n",
    "\n",
    "    if seg_forwarded[0].shape[2] == 1:\n",
    "        for i in range(len( seg_forwarded) ):\n",
    "            seg_forwarded[i] += 1 \n",
    "\n",
    "    confidence_values_list = get_confidence_values(seq_length= len(seg_forwarded))\n",
    "    \n",
    "    if seg_forwarded[0].shape[2] == 1:\n",
    "        one_hot_acc = np.zeros( (*seg_forwarded[0].shape,40+1), dtype=np.float32) # H,W,C\n",
    "        for conf, seg in zip(confidence_values_list, seg_forwarded):    \n",
    "            one_hot_acc += (np.eye(40+1)[seg.astype(np.int32)]).astype(np.float32) * conf\n",
    "        invalid_labels = np.sum( one_hot_acc[:,:,0,1:],axis=2 ) == 0\n",
    "    else:\n",
    "        res = np.argmax( np.stack( out ).sum( axis = 0 ), axis=2 )\n",
    "        return res, seg_forwarded\n",
    "    \n",
    "    label = np.argmax( one_hot_acc[:,:,0,1:], axis=2 )\n",
    "    label[ invalid_labels ] = -1 \n",
    "    \n",
    "    \n",
    "    return label[:,:], [s[:,:,0] for s in seg_forwarded]\n",
    "\n",
    "\n",
    "def forward_labels( seg=[],flow=[], img= [] ):\n",
    "    \"\"\"\n",
    "    seg[0] , C,H,W   0 == lastes frame, -1 == oldest frame\n",
    "\n",
    "    pre_fusion_function should be used to integrate the depth measurments \n",
    "    to the semseg before forward projection !\n",
    "\n",
    "    seg_forwarded[0] -> oldest_frame\n",
    "    seg_forwarded[len(seg_forwarded)] -> latest_frame not forwarded\n",
    "\n",
    "    \"\"\"\n",
    "    C,_H,_W = seg[0].shape\n",
    "    \n",
    "    if len( seg[0].shape ) == 3 and seg[0].shape[0] != 1:\n",
    "        soft = True\n",
    "    else:\n",
    "        soft = False\n",
    "    \n",
    "    seg_forwarded = []\n",
    "    img_forwarded = []\n",
    "    \n",
    "    for j in range(len( seg )):\n",
    "        seg[j] = np.moveaxis( seg[j], [0,1,2], [2,0,1] ) #C,H,W -> H,W,C\n",
    "        # img[j] = np.moveaxis( img[j], [0,1,2], [2,0,1] ) #C,H,W -> H,W,C\n",
    "\n",
    "    for i in range(0,len(seg)-1):\n",
    "        i = len(seg)-1-i\n",
    "        \n",
    "        seg_forwarded.append( seg[i].astype(np.float32) )\n",
    "        img_forwarded.append( img[i].astype(np.float32) )\n",
    "        \n",
    "        # start at oldest frame\n",
    "        if i != 0:\n",
    "            f = flow[i]\n",
    "        else:\n",
    "            f = np.zeros(flow[i].shape, dtype=np.float32)\n",
    "        \n",
    "        h_, w_ = np.mgrid[0:_H, 0:_W].astype(np.float32)\n",
    "        h_ -= f[:,:,1]\n",
    "        w_ -= f[:,:,0]\n",
    "\n",
    "        j = 0\n",
    "        for s,_img in zip(seg_forwarded, img_forwarded) : #  seg_forwarded, depth_forwarded\n",
    "            if soft:\n",
    "                s = cv2.remap( s, w_, h_, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            else:\n",
    "                # in H,W,1\n",
    "                s = cv2.remap( s, w_, h_, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=-1)[:,:,None]\n",
    "                # out H,W,1\n",
    "            img_forwarded[j] = cv2.remap( _img, w_, h_, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            seg_forwarded[j] = s\n",
    "\n",
    "            j += 1\n",
    "\n",
    "    img_forwarded.append( img[0] )\n",
    "    seg_forwarded.append( seg[0].astype(np.float32) )\n",
    "    return seg_forwarded, img_forwarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccfb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "accm = AccMonitor()\n",
    "live_plot = True\n",
    "seg_ls=[]\n",
    "flow_ls=[]\n",
    "img_ls= []\n",
    "lengths = [6,4,6,12]\n",
    "\n",
    "start = 0\n",
    "\n",
    "plotted_images = []\n",
    "st = time.time()\n",
    "for length in lengths:\n",
    "    for f, l_p, l_gt, i in zip(flows[start:],labels_pred[start:],labels_gt[start:],images[start:]):\n",
    "        if int(i.split('/')[-1][:-4])%10==0:\n",
    "            if int(i.split('/')[-1][:-4]) == 5570: \n",
    "                break\n",
    "            if int(i.split('/')[-1][:-4]) % 100 == 0:\n",
    "                print(\"N:\", int( len(flows)/10 ),\"/\",int(int(i.split('/')[-1][:-4])/10),\" Time:\", time.time()-st)\n",
    "            flow = get_aligned_flow( f )[0]\n",
    "            l_pred_hard = get_alinged_label( l_p )\n",
    "            img = get_aligned_image( i )\n",
    "            l_gt = get_alinged_label(l_gt )\n",
    "            l_pred_soft = get_alinged_label_probs( l_p )\n",
    "\n",
    "            seg_ls.append( np.argmax( np.moveaxis( l_pred_soft , [0,1,2], [1,2,0] ), axis=0)[None] )\n",
    "            flow_ls.append( flow )\n",
    "            img_ls.append( img )\n",
    "\n",
    "            if len(seg_ls) > length:\n",
    "                seg_ls = seg_ls[-length:]\n",
    "                flow_ls = flow_ls[-length:]\n",
    "                img_ls = img_ls[-length:]\n",
    "            if len(seg_ls) == length:\n",
    "                label, seg_forwarded = calculate_label( seg= copy.deepcopy(seg_ls)[::-1],\n",
    "                                                       flow= copy.deepcopy(flow_ls)[::-1], \n",
    "                                                       img = copy.deepcopy(img_ls)[::-1] )\n",
    "\n",
    "                if live_plot:\n",
    "                    for s,im,ori_seg in zip( seg_forwarded, img_ls, seg_ls ) :\n",
    "                        plotted_images.append( visu.plot_detectron(img, s , jupyter=True, text_off=True))\n",
    "                        plotted_images.append( visu.plot_detectron(im, ori_seg[0]+1 , jupyter=True, text_off=True))\n",
    "                    plotted_images.append(visu.plot_detectron(img, label+1, jupyter=True, text_off=True) )\n",
    "                    plotted_images.append(visu.plot_detectron(img, l_gt, jupyter=True, text_off=True) )\n",
    "                    plotted_images.append(visu.plot_detectron(img, seg_ls[-1][0]+1, jupyter=True, text_off=True) )\n",
    "\n",
    "\n",
    "                accm.update( f\"PSEUDO_{length}\", label , l_gt-1)   \n",
    "                accm.update( f\"GT_{length}\", l_gt-1, l_gt-1)   \n",
    "                accm.update( f\"NETWORK_{length}\", l_pred_hard-1, l_gt-1)\n",
    "                \n",
    "                if live_plot: break\n",
    "    if live_plot: break\n",
    "    print(f\"ACCM {length}:\", accm)\n",
    "print(\"Final\", accm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d878f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,i in enumerate( plotted_images):\n",
    "    Image.fromarray(i).save(f\"docs/flow/a_{k}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "textwidth = 12.7 #cm\n",
    "fig, ax = plt.subplots(2, 4, figsize=(textwidth, 4.7), sharex=False, sharey=False)\n",
    "left  = 0  # the left side of the subplots of the figure\n",
    "right = 1    # the right side of the subplots of the figure\n",
    "bottom = 0   # the bottom of the subplots of the figure\n",
    "top = 1     # the top of the subplots of the figure\n",
    "wspace = 0.02   # the amount of width reserved for blank space between subplots\n",
    "hspace = 0.05  # the amount of height reserved for white space between subplots\n",
    "plt.subplots_adjust(left=left, bottom=bottom, right=right, top=top, wspace=wspace, hspace=hspace)\n",
    "\n",
    "for i in range(0,8):\n",
    "    ax[i%2,int(i/2)].imshow( plotted_images[i] )\n",
    "for a in fig.axes:\n",
    "    a.axis('off')\n",
    "    \n",
    "from visu.visualizer import get_img_from_fig\n",
    "res = get_img_from_fig(fig, dpi=180)\n",
    "imageio.imwrite( 'docs/optical_flow_propagation_4.png', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "textwidth = 12.7 #cm\n",
    "fig, ax = plt.subplots(2, 6, figsize=(textwidth, 4), sharex=False, sharey=False)\n",
    "left  = 0  # the left side of the subplots of the figure\n",
    "right = 1    # the right side of the subplots of the figure\n",
    "bottom = 0   # the bottom of the subplots of the figure\n",
    "top = 1     # the top of the subplots of the figure\n",
    "wspace = 0.08   # the amount of width reserved for blank space between subplots\n",
    "hspace = 0.03  # the amount of height reserved for white space between subplots\n",
    "plt.subplots_adjust(left=left, bottom=bottom, right=right, top=top, wspace=wspace, hspace=hspace)\n",
    "\n",
    "for i in range(0,12):\n",
    "    ax[i%2,int(i/2)].imshow( plotted_images[i] )\n",
    "for a in fig.axes:\n",
    "    a.axis('off')\n",
    "    \n",
    "from visu.visualizer import get_img_from_fig\n",
    "res = get_img_from_fig(fig, dpi=360)\n",
    "imageio.imwrite( 'docs/optical_flow_propagation_6.png', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "acc_noice = AccMonitor()\n",
    "accm.update(\"Test2\", np.ones( (100,100)) ,np.ones( (100,100)))\n",
    "\n",
    "\n",
    "print(accm)\n",
    "\n",
    "\n",
    "import time\n",
    "visu = Visualizer(os.getenv('HOME')+'/tmp', logger=None, epoch=0, store=False, num_classes=41)\n",
    "accm = AccMonitor()\n",
    "live_plot = True\n",
    "seg_ls=[]\n",
    "flow_ls=[]\n",
    "img_ls= []\n",
    "gt_ls = []\n",
    "start = 0\n",
    "\n",
    "plotted_images = []\n",
    "st = time.time()\n",
    "length = 4\n",
    "for f, l_p, l_gt, i in zip(flows[start:],labels_pred[start:],labels_gt[start:],images[start:]):\n",
    "    if int(i.split('/')[-1][:-4])%10==0:\n",
    "        if int(i.split('/')[-1][:-4]) == 5570: \n",
    "            break\n",
    "        if int(i.split('/')[-1][:-4]) % 100 == 0:\n",
    "            print(\"N:\", int( len(flows)/10 ),\"/\",int(int(i.split('/')[-1][:-4])/10),\" Time:\", time.time()-st)\n",
    "        flow = get_aligned_flow( f )[0]\n",
    "        l_pred_hard = get_alinged_label( l_p )\n",
    "        img = get_aligned_image( i )\n",
    "        l_gt = get_alinged_label(l_gt )\n",
    "        \n",
    "        \n",
    "        l_pred_soft = get_alinged_label_probs( l_p )\n",
    "        \n",
    "        seg_inp = l_gt[None]-1\n",
    "        \n",
    "        rand_label = np.random.randint(-1,39, seg_inp.shape )\n",
    "        val = 0.5\n",
    "        rand_mask = np.random.random( seg_inp.shape) > val\n",
    "        seg_inp[rand_mask] = rand_label[rand_mask]\n",
    "        \n",
    "        gt_ls.append( l_gt)\n",
    "        seg_ls.append( seg_inp)\n",
    "        flow_ls.append( flow )\n",
    "        img_ls.append( img )\n",
    "\n",
    "        if len(seg_ls) > length:\n",
    "            gt_ls= gt_ls[-length:]\n",
    "            seg_ls = seg_ls[-length:]\n",
    "            flow_ls = flow_ls[-length:]\n",
    "            img_ls = img_ls[-length:]\n",
    "        if len(seg_ls) == length:\n",
    "            label, seg_forwarded = calculate_label( seg= copy.deepcopy(seg_ls)[::-1],\n",
    "                                                   flow= copy.deepcopy(flow_ls)[::-1], \n",
    "                                                   img = copy.deepcopy(img_ls)[::-1] )\n",
    "\n",
    "            if live_plot:\n",
    "                for s,im,ori_seg,gg in zip( seg_forwarded, img_ls, seg_ls,l_gt ) :\n",
    "                    print(\"Plot\")\n",
    "                    plotted_images.append( visu.plot_detectron(img, s , draw_bound=False, jupyter=False, text_off=True))\n",
    "                    plotted_images.append( visu.plot_detectron(im, ori_seg[0]+1, draw_bound=False , jupyter=False, text_off=True))  \n",
    "            accm.update( f\"PSEUDO_{length}\", label , l_gt-1)   \n",
    "            accm.update( f\"GT_{length}\", seg_inp[0], l_gt-1)   \n",
    "            accm.update( f\"NETWORK_{length}\", l_pred_hard-1, l_gt-1)\n",
    "            plotted_images.append(visu.plot_detectron_true_false( img = img, pred = seg_ls[-1][0]+1, gt = l_gt, draw_bound=False, jupyter=False, text_off=True))\n",
    "            print(\"Done\")\n",
    "            if live_plot: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = []\n",
    "for i in range( len(img_ls)):\n",
    "    wrong.append( \n",
    "        visu.plot_detectron_true_false( img = img_ls[-1], pred =seg_forwarded[i] , gt = gt_ls[-1], draw_bound=False, jupyter=False, text_off=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc564bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_static = []\n",
    "for i in range( len(img_ls)):\n",
    "    wrong_static.append( \n",
    "        visu.plot_detectron_true_false(img = img_ls[i], pred =seg_ls[i][0]+1 , gt = gt_ls[i], draw_bound=False, jupyter=True, text_off=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = visu.plot_detectron(img, label+1, draw_bound=False, jupyter=True, text_off=True) \n",
    "fp_best = visu.plot_detectron_true_false( img = img, pred = label+1 , gt = l_gt, draw_bound=False, jupyter=True, text_off=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1522c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,i in enumerate( plotted_images+wrong):\n",
    "    Image.fromarray(i).save(f\"docs/flow/b_{k}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "textwidth = 12.7 #cm\n",
    "fig, ax = plt.subplots(2, 5, figsize=(textwidth, 3.8), sharex=False, sharey=False)\n",
    "left  = 0  # the left side of the subplots of the figure\n",
    "right = 1    # the right side of the subplots of the figure\n",
    "bottom = 0   # the bottom of the subplots of the figure\n",
    "top = 1     # the top of the subplots of the figure\n",
    "wspace = 0.04   # the amount of width reserved for blank space between subplots\n",
    "hspace = 0.03  # the amount of height reserved for white space between subplots\n",
    "plt.subplots_adjust(left=left, bottom=bottom, right=right, top=top, wspace=wspace, hspace=hspace)\n",
    "\n",
    "ax[0,0].imshow( plotted_images[0] )\n",
    "ax[1,0].imshow( wrong[0] )\n",
    "#ax[2,0].imshow( plotted_images[1] )\n",
    "#ax[3,0].imshow( wrong_static[0] )\n",
    "\n",
    "ax[0,1].imshow( plotted_images[2] )\n",
    "ax[1,1].imshow( wrong[1] )\n",
    "#ax[2,1].imshow( plotted_images[3] )\n",
    "#ax[3,1].imshow( wrong_static[0] )\n",
    "\n",
    "ax[0,2].imshow( plotted_images[4] )\n",
    "ax[1,2].imshow( wrong[2] )\n",
    "#ax[2,2].imshow( plotted_images[5] )\n",
    "#ax[3,2].imshow( wrong_static[0] )\n",
    "\n",
    "ax[0,3].imshow( plotted_images[6] )\n",
    "ax[1,3].imshow( wrong[3] )\n",
    "#ax[2,3].imshow( plotted_images[7] )\n",
    "#ax[3,3].imshow( wrong_static[0] )\n",
    "\n",
    "ax[0,4].imshow( final )\n",
    "ax[1,4].imshow( fp_best )\n",
    "\n",
    "for a in fig.axes:\n",
    "    a.axis('off')\n",
    "    \n",
    "from visu.visualizer import get_img_from_fig\n",
    "res = get_img_from_fig(fig, dpi=360)\n",
    "imageio.imwrite( 'docs/random_noice_flow_res360.png', res)\n",
    "\n",
    "res = get_img_from_fig(fig, dpi=180)\n",
    "imageio.imwrite( 'docs/random_noice_flow_res180.png', res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a70b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
