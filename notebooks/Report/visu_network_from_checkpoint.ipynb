{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034429b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ASL = os.path.join(str(Path.home()), \"ASL\")\n",
    "src = os.path.join(str(Path.home()), \"ASL\", \"src\")\n",
    "os.chdir( ASL )\n",
    "sys.path.append(ASL)\n",
    "sys.path.append(src)\n",
    "\n",
    "from lightning import Network\n",
    "from utils_asl import load_yaml\n",
    "from visu import Visualizer\n",
    "\n",
    "textwidth = 12.7\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio \n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import pandas\n",
    "from visu import *\n",
    "from datasets_asl import MLHypersim\n",
    "from datasets_asl import ScanNet\n",
    "\n",
    "from utils_asl import load_yaml\n",
    "from task import get_task_generator\n",
    "from datasets_asl import adapter_tg_to_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b987c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Step: Load config\n",
    "# 2 Load: Dataloaders\n",
    "# 3 Load: Model from each checkpoint \n",
    "# 4 Inference and plot\n",
    "# 5 Creates a new folder in the ceckpoint path called visu_report and puts images there. \n",
    "checkpoint_path = \"/home/jonfrey/Results/semi_4_scenes/2021-07-28T21:02:55_cl_005_unltimited_mem_ratio05\"\n",
    "show_in_jupyter = True\n",
    "\n",
    "exp_path = [str(s) for s in Path(checkpoint_path).rglob(\"*.yml\") if str(s).find(\"euler\") == -1 ][0]\n",
    "env_path = os.path.join(\"cfg/env\", os.environ[\"ENV_WORKSTATION_NAME\"] + \".yml\")\n",
    "\n",
    "visu_report = os.path.join(checkpoint_path,\"visu_report\")\n",
    "\n",
    "vi = Visualizer(p_visu=visu_report, store=True)\n",
    "\n",
    "exp = load_yaml( exp_path )\n",
    "env = load_yaml( env_path )\n",
    "tg = get_task_generator(\n",
    "    name=exp[\"task_generator\"].get(\"name\", \"scannet\"),\n",
    "    mode=exp[\"task_generator\"][\"mode\"], \n",
    "    cfg=exp[\"task_generator\"][\"cfg\"],\n",
    ")\n",
    "task_nr = 4\n",
    "# Reinitalizing of all datasets\n",
    "train_dataloader, val_dataloaders, task_name = adapter_tg_to_dataloader(\n",
    "    tg, task_nr, exp[\"loader\"], exp[\"replay\"][\"cfg_ensemble\"], env\n",
    ")\n",
    "\n",
    "ckpt_paths = exp_path = [str(s) for s in Path(checkpoint_path).rglob(\"*.ckpt\") if str(s).find(\"last\") == -1]\n",
    "ckpt_paths.sort()\n",
    "ckpt_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exp Path: \\n\", exp_path , \"\\n\\n\")\n",
    "print(\"Found Checkpoints: \\n\", ckpt_paths, \"\\n\\n\")\n",
    "print(str(tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb399b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pseudo_label import FastSCNNHelperTorch\n",
    "from utils_asl import load_yaml\n",
    "frames = [0, 10, 20, 30]\n",
    "\n",
    "def parse_batch(batch):\n",
    "    ba = {}\n",
    "    if len(batch) == 1:\n",
    "      raise Exception(\"Dataloader is set to unique and not implemented\")\n",
    "    ba[\"images\"] = batch[0]\n",
    "    ba[\"label\"] = batch[1]\n",
    "    print(len( batch ))\n",
    "    if len(batch) == 2:\n",
    "      ba[\"ori_img\"] = batch[2]\n",
    "    if len(batch) == 4:\n",
    "      ba[\"aux_label\"] = batch[2]\n",
    "      ba[\"aux_valid\"] = batch[3]\n",
    "    if len(batch) == 6:\n",
    "      ba[\"aux_label\"] = batch[3]\n",
    "      ba[\"aux_valid\"] = batch[4]\n",
    "      ba[\"ori_img\"] = batch[5]\n",
    "    return ba\n",
    "train_dataloader.visu=True\n",
    "for kk, ckpt in enumerate( ckpt_paths[1:] ):\n",
    "    exp[\"checkpoint_load\"] = ckpt\n",
    "    scnn = FastSCNNHelperTorch(device=\"cpu\", exp=exp )\n",
    "    print(ckpt)\n",
    "    for i in range( len(train_dataloader) ):\n",
    "            ba = parse_batch( train_dataloader.dataset[i])\n",
    "            print(ba.keys())\n",
    "            image = ba[\"images\"][None]\n",
    "            img =  ba[\"ori_img\"]\n",
    "\n",
    "            out = scnn.get_label_prob( image )\n",
    "            la = torch.argmax( out,dim= 0)\n",
    "            vi.epoch = i\n",
    "            vi.plot_detectron( img , la , alpha=0.85, \n",
    "                                    text_off =True,\n",
    "                                    draw_bound=False, \n",
    "                                    jupyter=show_in_jupyter, tag = \"pred\")\n",
    "\n",
    "            vi.plot_detectron(  img , ba[\"label\"]+1 , alpha=0.85, \n",
    "                                    text_off =True,\n",
    "                                        draw_bound=False, \n",
    "                                        jupyter=show_in_jupyter, tag = \"gt\")\n",
    "            try:\n",
    "                vi.plot_detectron(  img , ba[\"aux_label\"]+1 , alpha=0.85, \n",
    "                                        text_off =True,\n",
    "                                            draw_bound=False, \n",
    "                                            jupyter=show_in_jupyter, tag = \"aux\")\n",
    "            except:\n",
    "                pass\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbe60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pseudo_label import FastSCNNHelperTorch\n",
    "from utils_asl import load_yaml\n",
    "frames = [0, 10, 20, 30]\n",
    "\n",
    "def parse_batch(batch):\n",
    "    ba = {}\n",
    "    if len(batch) == 1:\n",
    "      raise Exception(\"Dataloader is set to unique and not implemented\")\n",
    "    ba[\"images\"] = batch[0]\n",
    "    ba[\"label\"] = batch[1]\n",
    "\n",
    "    if len(batch) == 3:\n",
    "      ba[\"ori_img\"] = batch[2]\n",
    "    if len(batch) == 4:\n",
    "      ba[\"aux_label\"] = batch[2]\n",
    "      ba[\"aux_valid\"] = batch[3]\n",
    "    if len(batch) == 5:\n",
    "      ba[\"aux_label\"] = batch[2]\n",
    "      ba[\"aux_valid\"] = batch[3]\n",
    "      ba[\"ori_img\"] = batch[4]\n",
    "    return ba\n",
    "def plot_seq(seq):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 40))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(1, 4),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, im in zip(grid, seq):\n",
    "        # Iterating over the grid returns the Axes.\n",
    "        ax.imshow(im)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "ref_pred = []\n",
    "for kk, ckpt in enumerate( ckpt_paths ):\n",
    "    exp[\"checkpoint_load\"] = ckpt\n",
    "    scnn = FastSCNNHelperTorch(device=\"cpu\", exp=exp )\n",
    "    print(ckpt)\n",
    "    for i in range( len(val_dataloaders) ):\n",
    "        seq = []\n",
    "        gts = []\n",
    "        dets = []\n",
    "        a = []\n",
    "        for f in frames:\n",
    "            ba = parse_batch( val_dataloaders[i].dataset[f] )\n",
    "            image = ba[\"images\"][None]\n",
    "            img =  ba[\"ori_img\"]\n",
    "\n",
    "            out = scnn.get_label_prob( image )\n",
    "            la = torch.argmax( out,dim= 0)\n",
    "            name = ckpt.split(\"/\")[-1] + f\"_vaidation_{i}_frame_{f}\"\n",
    "            \n",
    "            seq.append( vi.plot_detectron( img , la , alpha=0.85, \n",
    "                                    text_off =True,\n",
    "                                    draw_bound=False, \n",
    "                                    jupyter=show_in_jupyter, tag = name) ) \n",
    "            if kk == 0:\n",
    "                a.append(  vi.plot_detectron( img , la , alpha=0.85, \n",
    "                                    text_off =True,\n",
    "                                    draw_bound=False, \n",
    "                                    jupyter=show_in_jupyter, tag = name) \n",
    "                )\n",
    "                \n",
    "            name = f\"gt_{i}_frame_{f}\"\n",
    "            gts.append( vi.plot_detectron(  img , ba[\"label\"]+1 , alpha=0.85, \n",
    "                                    text_off =True,\n",
    "                                        draw_bound=False, \n",
    "                                        jupyter=show_in_jupyter, tag = name))\n",
    "            try:\n",
    "                name = f\"aux_{i}_frame_{f}\"\n",
    "                dets.append( vi.plot_detectron(  img , ba[\"aux_label\"]+1 , alpha=0.85, \n",
    "                                        text_off =True,\n",
    "                                            draw_bound=False, \n",
    "                                            jupyter=show_in_jupyter, tag = name))\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        ref_pred.append(a)\n",
    "        if i == kk-1:\n",
    "            plot_seq( seq )\n",
    "            plot_seq( gts )\n",
    "            try:\n",
    "                plot_seq( ref_pred[i] ) \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                plot_seq( dets )\n",
    "            except:\n",
    "                pass\n",
    "            print(\"Done\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ab337",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88395c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
