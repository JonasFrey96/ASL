{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"/home/jonfrey/ASL\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/\"\"\")\n",
    "sys.path.append(\"\"\"/home/jonfrey/ASL/src/pseudo_label\"\"\")\n",
    "\n",
    "import numpy as np\n",
    "from visu import Visualizer\n",
    "import imageio\n",
    "\n",
    "\n",
    "# STD\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# MISC\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dceb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "from utils_asl import LabelLoaderAuto\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(p,sub=1,la=\"png\"):\n",
    "    p = [str(s) for s in Path(p).rglob(f'*.{la}') if str(s).find(\"_.png\") == -1]\n",
    "    \n",
    "    p.sort(\n",
    "        key=lambda x: int(x.split(\"/\")[-1][:-4])\n",
    "    )\n",
    "    return p[::sub]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1afe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "kimera_interfacer_path = \"/home/jonfrey/catkin_ws/src/Kimera-Interfacer/kimera_interfacer\"\n",
    "mapping = np.genfromtxt(\n",
    "  f\"{kimera_interfacer_path}/cfg/nyu40_segmentation_mapping.csv\", delimiter=\",\"\n",
    ")\n",
    "rgb = torch.from_numpy(mapping[2:, 1:4]).type(torch.float32)\n",
    "\n",
    "filt = np.array( [255**2, 255**1,1])[None,:].repeat(rgb.shape[0],0)\n",
    "ind = (rgb * filt).sum(axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "346412e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W,H = 640,480\n",
    "path_labels = \"/home/jonfrey/Datasets/labdata/result/full_run_2/pseudo_label\"\n",
    "path_visu = \"/home/jonfrey/Datasets/labdata/result/full_run_2/pseudo_label\".replace(\"pseudo_label\", \"visu\")\n",
    "\n",
    "visu = Visualizer(path_visu, logger=None, epoch=0, store=True, num_classes=41)\n",
    "lla = LabelLoaderAuto(root_scannet=\"/home/jonfrey/Datasets/scannet\", confidence= 0.1,H = 480, W = 640)\n",
    "\n",
    "labels_p = get_labels(path_labels)\n",
    "img_p = [p.replace(\"pseudo_label\",\"color\").replace(\".png\",\".jpg\") for p in labels_p]\n",
    "\n",
    "filt = np.array( [255**2, 255**1,1])[None,None,:].repeat(480,0).repeat(640,1)\n",
    "\n",
    "# VIDEO\n",
    "import cv2\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "FPS = 30\n",
    "fourcc = VideoWriter_fourcc(\"M\", \"J\", \"P\",\"G\")\n",
    "video = VideoWriter(path_visu+ \"/conference_video_pseudo.avi\", fourcc, float(FPS), (W,H))\n",
    "fourcc2 = VideoWriter_fourcc(\"M\", \"J\", \"P\",\"G\")\n",
    "video2 = VideoWriter(path_visu+ \"/conference_video_network.avi\", fourcc2, float(FPS), (W,H))\n",
    "\n",
    "\n",
    "for i in range(len(labels_p)):\n",
    "    visu.epoch = int(labels_p[i].split('/')[-1][:-4])\n",
    "    gt = lla.get(labels_p[i])[0]\n",
    "    img = imageio.imread(img_p[i]) \n",
    "    \n",
    "    img2 = imageio.imread(labels_p[i].replace(\"pseudo_label\",\"label-filt\"))\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)  \n",
    "    \n",
    "    label = (img2* filt ).sum(axis=2)\n",
    "    out = np.zeros_like(label)\n",
    "    \n",
    "    for i in range(0,ind.shape[0]):\n",
    "        out[ label == int( ind[i]) ] = i+1\n",
    "    \n",
    "    visu.plot_image(img2, tag =\"conference_room_image\", jupyter=False)\n",
    "    res2 = visu.plot_detectron( img , out, tag=\"conference_network\", jupyter=False,text_off=True )\n",
    "    res = visu.plot_detectron( img , gt, tag=\"conference_pseudo\", jupyter=False, text_off=True)\n",
    "    \n",
    "    img = Image.fromarray(res)\n",
    "    r, g, b = img.split()\n",
    "    img = np.array( Image.merge(\"RGB\", (b, g, r)) )\n",
    "    video.write(img)\n",
    "    \n",
    "    img = Image.fromarray(res2)\n",
    "    r, g, b = img.split()\n",
    "    img = np.array( Image.merge(\"RGB\", (b, g, r)) )\n",
    "    video2.write(img)\n",
    "    if i == 10: break\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filt = np.array( [255**2, 255**1,1])[None,None,:].repeat(480,0).repeat(640,1)\n",
    "visu = Visualizer(\"/home/jonfrey/Documents/master_thesis/Report/images/labdata\", logger=None, epoch=0, store=True, num_classes=41)\n",
    "lla = LabelLoaderAuto(root_scannet=\"/home/jonfrey/Datasets/scannet\", confidence= 0.1,H = H, W = W)\n",
    "\n",
    "import cv2\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "FPS = 30\n",
    "fourcc = VideoWriter_fourcc(\"M\", \"J\", \"P\",\"G\")\n",
    "video = VideoWriter(f'/home/jonfrey/Videos/hypersim_labe_{s}.avi', fourcc, float(FPS), (W,H))\n",
    "\n",
    "    \n",
    "for i in  range( len( labels_p) ):\n",
    "    visu.epoch = int(labels_p[i].split('/')[-1][:-4])\n",
    "    gt = lla.get(labels_p[i])[0]\n",
    "    img = imageio.imread(img_p[i]) \n",
    "    \n",
    "    img2 = imageio.imread(labels_p[i].replace(\"pseudo_label\",\"label-filt\"))\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)  \n",
    "    \n",
    "    label = (img2* filt ).sum(axis=2)\n",
    "    out = np.zeros_like(label)\n",
    "    \n",
    "    for i in range(0,ind.shape[0]):\n",
    "        out[ label == int( ind[i]) ] = i+1\n",
    "    \n",
    "    #visu.plot_image(img2, tag =\"conference_room_image\", jupyter=True)\n",
    "    #visu.plot_detectron( img , out, tag=\"conference_network\", jupyter=True,text_off=True )\n",
    "    \n",
    "    ps = visu.plot_detectron( img , gt, tag=\"conference_pseudo\", jupyter=True, text_off=True)\n",
    "\n",
    "    img = Image.fromarray(ps)\n",
    "    \n",
    "    r, g, b = img.split()\n",
    "    img = np.array( Image.merge(\"RGB\", (b, g, r)) )\n",
    "    video.write(img)\n",
    "\n",
    "        \n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScanNet\n",
    "for s in [\"scene0000_00\", \"scene0001_00\", \"scene0002_00\", \"scene0003_00\"]:\n",
    "\n",
    "    labels_p = get_labels(f\"/home/jonfrey/Datasets/scannet/scans/{s}/label-filt\")\n",
    "    img_p = [p.replace(\"label-filt\",\"color\").replace(\".png\",\".jpg\") for p in labels_p]\n",
    "    labels_p[:10]\n",
    "\n",
    "    from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "    import cv2\n",
    "    FPS = 30\n",
    "    fourcc = VideoWriter_fourcc(\"M\", \"J\", \"P\",\"G\")\n",
    "    video = VideoWriter(f'/home/jonfrey/Videos/hypersim_labe_{s}.avi', fourcc, float(FPS), (W,H))\n",
    "    \n",
    "    fourcc2 = VideoWriter_fourcc(\"M\", \"J\", \"P\",\"G\")\n",
    "    video2 = VideoWriter(f'/home/jonfrey/Videos/hypersim_images_{s}.avi', fourcc2, float(FPS), (W,H))\n",
    "    \n",
    "    \n",
    "    filt = np.array( [255**2, 255**1,1])[None,None,:].repeat(H,0).repeat(W,1)\n",
    "    visu = Visualizer(\"/home/jonfrey/Documents/master_thesis/Report/images/labdata\", logger=None, epoch=0, store=False, num_classes=41)\n",
    "\n",
    "\n",
    "    import cv2\n",
    "    for i in  range( len( labels_p) ):\n",
    "        visu.epoch = int(labels_p[i].split('/')[-1][:-4])\n",
    "        gt = lla.get(labels_p[i])[0]\n",
    "        img = imageio.imread(img_p[i]) \n",
    "        t = np.copy(img)\n",
    "        #label = (img2* filt ).sum(axis=2)\n",
    "        #out = np.zeros_like(label)\n",
    "\n",
    "        #for i in range(0,ind.shape[0]):\n",
    "        #    out[ label == int( ind[i]) ] = i+1\n",
    "\n",
    "        #visu.plot_image(img2, tag =\"conference_room_image\", jupyter=True)\n",
    "\n",
    "        #visu.plot_detectron( img , out, tag=\"conference_network\", jupyter=True,text_off=True )\n",
    "        ps = visu.plot_detectron( img , gt, tag=\"conference_pseudo\", jupyter=False, text_off=True)\n",
    "\n",
    "        img = Image.fromarray(ps)\n",
    "\n",
    "        r, g, b = img.split()\n",
    "        img = np.array( Image.merge(\"RGB\", (b, g, r)) )\n",
    "        video.write(img)\n",
    "        \n",
    "        img = Image.fromarray(t)\n",
    "\n",
    "        r, g, b = img.split()\n",
    "        img = np.array( Image.merge(\"RGB\", (b, g, r)) )\n",
    "        video2.write(img)\n",
    "        \n",
    "    video2.release()    \n",
    "    video.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
