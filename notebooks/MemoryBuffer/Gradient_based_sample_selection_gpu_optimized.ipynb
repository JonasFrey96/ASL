{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "ASL = os.path.join( str(Path.home()), \"ASL\" )\n",
    "src = os.path.join( str(Path.home()), \"ASL\", \"src\" )\n",
    "sys.path.append( ASL )\n",
    "sys.path.append( src )\n",
    "\n",
    "from lightning import Network\n",
    "from utils_asl import load_yaml\n",
    "name = os.getenv('ENV_WORKSTATION_NAME')\n",
    "env_cfg_path =os.path.join( ASL, f\"cfg/env/{name}.yml\")  \n",
    "exp_cfg_path =os.path.join( ASL, \"cfg/exp/debug.yml\")\n",
    "device = \"cuda:0\"\n",
    "\n",
    "env = load_yaml(env_cfg_path)\n",
    "exp = load_yaml(exp_cfg_path)\n",
    "\n",
    "model = Network(exp=exp, env=env)\n",
    "done = model.model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from random import randint\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "\n",
    "def get_fast_distance( x ):\n",
    "    NR, C = x.shape\n",
    "    x1 = x[:,None,:].repeat(1,NR,1)\n",
    "    # BS x BS distance matrix\n",
    "    res = torch.cdist(x1, x1, p=2.0) \n",
    "    return res.mean() \n",
    "\n",
    "def get_knn_distance( x ):\n",
    "    return knn_search_nearest(x,x,k=2) \n",
    "\n",
    "def knn_search_nearest(ref, query, k=2, norm=None):\n",
    "    \"\"\"return mean distance to the 5 losest datapoints over all vectors\n",
    "    Args:\n",
    "        ref ([type]): NR * C\n",
    "        query ([type]): NR * C\n",
    "    \"\"\"\n",
    "    mp2 = ref.unsqueeze(0).repeat(query.shape[0], 1, 1)\n",
    "    tp2 = query.unsqueeze(1).repeat(1, ref.shape[0], 1)\n",
    "    dist = torch.norm(mp2 - tp2, dim=2, p=norm)\n",
    "    knn = dist.topk(k, largest=False)\n",
    "    res = knn.values.mean()\n",
    "    return res\n",
    "\n",
    "def angle(x, k=2):\n",
    "    NR,C = x.shape\n",
    "    ref = x\n",
    "    query = x\n",
    "    mp2 = ref.unsqueeze(0).repeat(query.shape[0], 1, 1)\n",
    "    tp2 = query.unsqueeze(1).repeat(1, ref.shape[0], 1)\n",
    "    dist = F.cosine_similarity(mp2.view((-1,C)) , tp2.view((-1,C)) ) # if 1 same dir , if -1 other direction\n",
    "    dist = dist.reshape( NR, NR) \n",
    "    dist = -dist\n",
    "    return dist.mean()\n",
    "\n",
    "def gradient_dissimilarity_fast(X, K=50, iterations= 1000, early_stopping = 0.00001):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: torch.tensor NRxC -> move X on GPU before passing to the function \n",
    "    \"\"\"\n",
    "    st = time.time()\n",
    "    \n",
    "    if X.shape[0] <= K:\n",
    "        ret = torch.arange(0, X.shape[0])\n",
    "        ret = ret.type(torch.int64)\n",
    "        return ret \n",
    "    \n",
    "    init_selection = torch.randperm( X.shape[0] )[:K]\n",
    "    buffer_features_list = X[init_selection]\n",
    "    \n",
    "    prev_score = 0\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        swap_candidate = torch.randint(0, K, (1,))\n",
    "        swap_candidate.to( swap_candidate.device )\n",
    "        while True:\n",
    "            replacement_candidate = torch.randint(0,X.shape[0],(1,))[0]\n",
    "            if replacement_candidate not in init_selection:\n",
    "                break\n",
    "        \n",
    "        stored_feature = buffer_features_list[swap_candidate].clone()\n",
    "        buffer_features_list[swap_candidate] = X[replacement_candidate]\n",
    "        \n",
    "        new_score = angle( buffer_features_list)\n",
    "        ra = random.random() \n",
    "        if new_score > prev_score or  ra > 0.95:\n",
    "            # apply change\n",
    "            init_selection[swap_candidate] = int(replacement_candidate)\n",
    "            prev_score = new_score\n",
    "        else:\n",
    "            buffer_features_list[swap_candidate] = stored_feature\n",
    "    print(f\"Time {i} takes {time.time()-st}\")\n",
    "    init_selection = init_selection.type(torch.int64)\n",
    "    return init_selection #, prev_score\n",
    "\n",
    "def hierarchical_dissimilarity(X, K=50, maxSize=100, device=\"cuda:0\"):\n",
    "    print(\"INPUT HIERARCHICAL\", X.shape)\n",
    "    if X.shape[0] < maxSize:\n",
    "        # LEAF perform\n",
    "        print(\"Leaf\", X.shape, device)\n",
    "        input_X = X.clone()\n",
    "        input_X = input_X.to(device)\n",
    "        c = gradient_dissimilarity_fast( input_X, K=K)\n",
    "        del input_X\n",
    "        print(\"Leaf returns \",c.shape[0] )\n",
    "        return c\n",
    "    else:\n",
    "        # BRANCHE\n",
    "        s = X.shape[0]\n",
    "        split = int(s/2)\n",
    "        indices = torch.arange( 0, s )\n",
    "        indices = torch.randperm( s )\n",
    "        indices = indices.type(torch.int64)\n",
    "        r = s-split\n",
    "        right_indices = indices[split:]\n",
    "        left_indices = indices[:split]\n",
    "        print( f\"Branch into l{split}, r{r}\")\n",
    "        \n",
    "        print(right_indices.max(),left_indices.max(), X.shape)\n",
    "        r = hierarchical_dissimilarity(X[right_indices], K=K, maxSize = maxSize, device=device)\n",
    "        l = hierarchical_dissimilarity(X[left_indices], K=K, maxSize = maxSize, device=device)\n",
    "        sel_indices = torch.cat( (indices[left_indices][l], indices[right_indices][r]))      \n",
    "        in_data = (X[sel_indices]).clone()\n",
    "        in_data = in_data.to(device)\n",
    "        c = gradient_dissimilarity_fast(in_data, K = K)\n",
    "        del in_data\n",
    "        \n",
    "        print(f\"Joined -> \", c.shape)\n",
    "        print(\"select\", c.max(), x.min(), sel_indices.shape)\n",
    "        sel_indices = sel_indices[c]\n",
    "        return sel_indices\n",
    "\n",
    "samples_per_task = 5000\n",
    "# current_gradient = current_gradient.cpu()\n",
    "sub = 10\n",
    "grad_rep = torch.randint( 0,10,(samples_per_task,110760) ) #1140760\n",
    "grad_rep = grad_rep[:,::10].type(torch.float32)\n",
    "# buffer_gradients_list = current_gradient[None].repeat( samples_per_task,1)\n",
    "hierarchical_dissimilarity( grad_rep, K=50, maxSize=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones( (10,1))\n",
    "b = -torch.ones((10,1)) \n",
    "print(a.shape, b.shape)\n",
    "F.cosine_similarity(a,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track4",
   "language": "python",
   "name": "track4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
