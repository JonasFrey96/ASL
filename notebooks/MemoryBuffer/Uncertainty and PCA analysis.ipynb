{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "__all__ = ['get_softmax_uncertainty_distance']\n",
    "\n",
    "def get_softmax_uncertainty_distance(pred,mask = None):\n",
    "  \"\"\"\n",
    "  pred: BS,C,H,W before softmax is applied! \n",
    "  \n",
    "  distance between sec and first element\n",
    "  # 1 if fully uncertain -> 2th best pixel estimate = 1th best pixel estimate, for all pixels\n",
    "  # 0 if absolutly confident for all pixels. One class probability 1, 2th best class probability 0, for all pixels\n",
    "  \"\"\"\n",
    "  BS,C,H,W = pred.shape\n",
    "  if mask is None:\n",
    "    mask = torch.ones( (BS,H,W), device=pred.device, dtype=torch.bool)\n",
    "    \n",
    "  argm1 = torch.argmax(pred, 1)\n",
    "  soft1 = torch.nn.functional.softmax(pred, dim=1)\n",
    "\n",
    "  onehot_argm1 = torch.nn.functional.one_hot(argm1, num_classes=C).permute(0,3,1,2).type(torch.bool)\n",
    "  ten2 = pred.clone()\n",
    "  ten2[ onehot_argm1 ] = 0\n",
    "\n",
    "  argm2 = torch.argmax(ten2, 1)\n",
    "  onehot_argm2 = torch.nn.functional.one_hot(argm2, num_classes=C).permute(0,3,1,2).type(torch.bool)\n",
    "  res = [] \n",
    "\n",
    "  soft1 = soft1.permute(0,2,3,1)\n",
    "  onehot_argm1 = onehot_argm1.permute(0,2,3,1)\n",
    "  onehot_argm2 = onehot_argm2.permute(0,2,3,1)\n",
    "  \n",
    "  for b in range(BS):\n",
    "    res_ = soft1[b][mask[b]][onehot_argm1[b][mask[b]]] - soft1[b][mask[b]][onehot_argm2[b][mask[b]]]\n",
    "    res.append( res_.mean() )\n",
    "\n",
    "  return torch.tensor(res, dtype=pred.dtype, device=pred.device)\n",
    "\n",
    "\n",
    "def test():\n",
    "  BS,C,H,W = 16,40,300,320\n",
    "  mask = torch.rand( ( BS,H,W) ) > 0.5\n",
    "    \n",
    "  pred = torch.rand( ( BS,C,H,W) )\n",
    "  res = get_softmax_uncertainty_distance(pred)\n",
    "  print(res, \"should be very low\")\n",
    "  \n",
    "  pred = torch.rand( ( BS,C,H,W) ) /1000\n",
    "  pred[:,0,:,:] = 10\n",
    "  res = get_softmax_uncertainty_distance(pred, mask)\n",
    "  print(res, 'should be nearly 0')\n",
    "  \n",
    "  pred[:,1,:,:] = 8\n",
    "  res = get_softmax_uncertainty_distance(pred, mask)\n",
    "  print(res, 'should be betweem 0-1')\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softmax_uncertaintiy_max(pred):\n",
    "    \"\"\"\n",
    "    pred: BS,C,H,W before softmax is applied! \n",
    "    \n",
    "    (1 - max( softmax(pred))) mean over batch size\n",
    "    \n",
    "    # 1 if fully uncertain\n",
    "    # 0 if absolutly confident for all pixels\n",
    "    \"\"\"\n",
    "    BS,C,H,W = pred.shape\n",
    "    \n",
    "    argm1 = torch.argmax(pred, 1)\n",
    "    soft1 = torch.nn.functional.softmax(pred, dim=1)\n",
    "    onehot_argm1 = torch.nn.functional.one_hot(argm1, num_classes=C).permute(0,3,1,2).type(torch.bool)\n",
    "    \n",
    "    soft1 = soft1.permute(0,2,3,1)\n",
    "    onehot_argm1 = onehot_argm1.permute(0,2,3,1)\n",
    "    \n",
    "    res = []\n",
    "    for b in range(BS):\n",
    "        res_ = soft1[b][onehot_argm1[b]]\n",
    "        res.append( torch.mean(res_)  )\n",
    "#     print(res)\n",
    "    return torch.tensor(res, dtype=pred.dtype, device=pred.device)\n",
    "\n",
    "def test():\n",
    "    BS,C,H,W = 16,40,300,320\n",
    "    pred = torch.rand( ( BS,C,H,W) )\n",
    "    res = get_softmax_uncertaintiy_max(pred)\n",
    "    print(res, \"should be very low\")\n",
    "    \n",
    "    pred = torch.rand( ( BS,C,H,W) ) /1000\n",
    "    pred[:,0,:,:] = 10\n",
    "    res = get_softmax_uncertaintiy_max(pred)\n",
    "    print(res, 'should be nearly 0')\n",
    "    \n",
    "    pred[:,1,:,:] = 8\n",
    "    res = get_softmax_uncertaintiy_max(pred)\n",
    "    print(res, 'should be betweem 0-1')\n",
    "    \n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "os.chdir('/home/jonfrey/ASL')\n",
    "import sys\n",
    "sys.path.append('/home/jonfrey/ASL/src')\n",
    "from visu import Visualizer\n",
    "\n",
    "\n",
    "images = [torch.rand((3,480,640)) for i in range(16)]\n",
    "labels = [torch.randint(-1,40,(3,480,640)) for i in range(16)]\n",
    "\n",
    "grid_images = make_grid(images,nrow = 4,padding = 2,\n",
    "         scale_each = False, pad_value = 0)\n",
    "grid_labels = make_grid(labels,nrow = 4,padding = 2,\n",
    "         scale_each = False, pad_value = -1)\n",
    "\n",
    "print( grid_labels.shape)\n",
    "\n",
    "visu = Visualizer( p_visu='/home/jonfrey/tmp', logger=None, epoch=0, store=False, num_classes=40)\n",
    "visu.plot_image(grid_images, jupyter=True)\n",
    "visu.plot_segmentation( seg = grid_labels[0], jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "ten = torch.rand( ( 100 ) )\n",
    "\n",
    "def plot_hist(data, nr_bins=5, x_label='X', y_label='Y', title='Histogramm'):\n",
    "    if len(data.shape)>1:\n",
    "        if data.shape[0] == 0:\n",
    "            data = data[0,:]\n",
    "        elif data.shape[1] == 0:\n",
    "            data = data[:,0]\n",
    "        else:\n",
    "            raise Exception('plot_hist: Invalid Data Shape')\n",
    "    if type(data) == torch.Tensor:\n",
    "        data = list( data.clone().cpu())\n",
    "    elif type(data) == np.array:\n",
    "        data = list(data)\n",
    "    elif type(data) == list:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"plot_hist: Unknown Input Type\"+str(type(data)))\n",
    "    \n",
    "    # the histogram of the data\n",
    "    n, bins, patches = plt.hist(x = data, bins= nr_bins, density=True, facecolor='g', alpha=0.75)\n",
    "    print(bins)\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(ten)\n",
    "print(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "ten = torch.rand( ( 100 ) )\n",
    "col = { \"red\":[255,89,94],\n",
    " \"yellow\":[255,202,58],\n",
    " \"green\":[138,201,38],\n",
    " \"blue\":[25,130,196],\n",
    " \"purple\":[106,76,147] }\n",
    "\n",
    "li = [ [*(v),255] for v in col.values()]\n",
    "li = (np.array(li)/255).tolist()\n",
    "COL_MAP = cm.colors.ListedColormap(li)\n",
    "COL_MAP(0)\n",
    "\n",
    "def plot_bar(data, nr_bins=5, x_label='Sample', y_label='Value', title='Bar Plot', sort=True, reverse=True):\n",
    "    def check_shape(data):\n",
    "        if len(data.shape)>1:\n",
    "            if data.shape[0] == 0:\n",
    "                data = data[0,:]\n",
    "            elif data.shape[1] == 0:\n",
    "                data = data[:,0]\n",
    "            else:\n",
    "                raise Exception('plot_hist: Invalid Data Shape')\n",
    "        return data\n",
    "    \n",
    "    if type(data) == list:\n",
    "        pass\n",
    "    elif type(data) == torch.Tensor:\n",
    "        data = check_shape(data)\n",
    "        data = list( data.clone().cpu())\n",
    "    elif type(data) == np.ndarray:\n",
    "        data = check_shape(data)\n",
    "        data = list(data)\n",
    "    else:\n",
    "        raise Exception(\"plot_hist: Unknown Input Type\"+str(type(data)))\n",
    "    \n",
    "    if sort:\n",
    "        data.sort(reverse=reverse)\n",
    "    c = [106,76,147]\n",
    "    \n",
    "    col = { \"red\":[255,89,94],\n",
    "     \"yellow\":[255,202,58],\n",
    "     \"green\":[138,201,38],\n",
    "     \"blue\":[25,130,196],\n",
    "     \"purple\":[106,76,147] }\n",
    "\n",
    "    li = [ [*(v),255] for v in col.values()]\n",
    "    li = (np.array(li)/255).tolist()\n",
    "    col_map = cm.colors.ListedColormap(li)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    # n, bins, patches = plt.hist(x = data, bins= nr_bins, density=True, facecolor='g', alpha=0.75)\n",
    "    plt.bar(list(range(len(data))), data, facecolor=COL_MAP(2))\n",
    "    lab = [ 'ID'+ str(i) for i in range(len(data)) ]\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    fig.show()\n",
    "    plt.close()\n",
    "plot_bar(ten.numpy())\n",
    "# print(ten)\n",
    "ten\n",
    "# x = np.arange(4)\n",
    "# money = [1.5e5, 2.5e6, 5.5e6, 2.0e7]\n",
    "\n",
    "\n",
    "# def millions(x, pos):\n",
    "#     'The two args are the value and tick position'\n",
    "#     return '$%1.1fM' % (x * 1e-6)\n",
    "\n",
    "\n",
    "# formatter = FuncFormatter(millions)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# plt.xticks(x, ('Bill', 'Fred', 'Mary', 'Sue'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "# img = np.array(f['dataset'])\n",
    "# img[img > 1] = 1\n",
    "i =5\n",
    "p = f'/media/scratch2/jonfrey/datasets/mlhypersim/ai_026_001/images/scene_cam_00_final_hdf5/frame.000{i}.color.hdf5'\n",
    "import h5py\n",
    "with h5py.File(p, 'r') as f:\n",
    "    img = np.array(f['dataset'])\n",
    "\n",
    "img = torch.from_numpy(img).type(torch.float32) #.permute( 2, 0, 1)  # C H W\n",
    "img[img>1] = 1\n",
    "img = img.numpy()\n",
    "print(img.max(), img.min() )\n",
    "H,W,C = img.shape\n",
    "\n",
    "img = img*255\n",
    "img = np.uint8(img)\n",
    "out = cv2.resize( img , dsize=(int(W/2), int(H/2)), interpolation=cv2.INTER_CUBIC)\n",
    "#out = np.moveaxis(out, [0, 1, 2], [2, 1, 0])\n",
    "print(out.max(), out.shape, out.dtype)\n",
    "# out = np.uint8(out)\n",
    "display(Image.fromarray(out))\n",
    "\n",
    "np.float32( out )/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indi, counts = torch.unique( torch.randint(0,40,(100,1)) , return_counts = True)\n",
    "\n",
    "\n",
    "plot_bar(counts.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/media/scratch1/jonfrey/models/master_thesis/dev/uncertainty_integration/latent_feature_tensor_0.pt\"\n",
    "data = torch.load( p )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def get_image_indices(feat, gloable_indices, dis_metric= 'cos',\n",
    "                     K_aggregate=50, K_return=50, most_dissimilar= True,\n",
    "                     pick_mode='class_balanced'):\n",
    "    N, NC, C = feat.shape   \n",
    "    T = int(N*NC)\n",
    "    y = torch.range(0,NC-1)[None].repeat(N,1).flatten()\n",
    "    \n",
    "    gloable_indices_all = gloable_indices[:,None].repeat(1,NC).flatten()\n",
    "    feat = feat.view( (T,C) )\n",
    "    \n",
    "    # only mark a features as valid if the vector is not 0!\n",
    "    y[ feat.sum(dim=1) == 0 ] = 999\n",
    "    \n",
    "    # create centroids over valid features\n",
    "    feat_centroids = torch.zeros( (NC,C), device=feat.device, dtype=feat.dtype)\n",
    "    for i in range(NC):\n",
    "        feat_centroids[i] = feat[y==i].mean(dim=0)\n",
    "        \n",
    "    # create expanded centroid tensor that aligns with feat\n",
    "    expanded_centroids = feat.clone()\n",
    "    for i in range(NC):\n",
    "        m = y == i\n",
    "        expanded_centroids[ m,: ] = feat_centroids[i][None,:].repeat(T,1)[m, :]\n",
    "    \n",
    "    # compute similarity metric\n",
    "    if dis_metric == 'cos':\n",
    "        metric = F.cosine_similarity(\n",
    "            feat.type(torch.float32), \n",
    "            expanded_centroids.type(torch.float32),\n",
    "            dim=1, eps=1e-6) \n",
    "    elif dis_metric == 'pairwise':\n",
    "        metric = F.pairwise_distance(\n",
    "            feat.type(torch.float32), \n",
    "            expanded_centroids.type(torch.float32),\n",
    "            dim=1, eps=1e-6)\n",
    "    else:\n",
    "        raise Exception(f'In get_image_indices dis_metric {dis_metric} not implemented')\n",
    "    \n",
    "    if pick_mode== 'most_hits':\n",
    "\n",
    "        # select K best for each class\n",
    "        candidates = []\n",
    "        for i in range(NC):\n",
    "            m = y==i\n",
    "            _K = min(m.sum(), K_aggregate)\n",
    "            values, indices = torch.topk( metric[m] ,_K, \n",
    "                largest = not most_dissimilar)\n",
    "            candidates +=  gloable_indices_all[m][indices].tolist()\n",
    "        candidates = torch.tensor( candidates )\n",
    "\n",
    "        # select the globale_image_indicies that are selected most\n",
    "        indi, counts = torch.unique(candidates, return_counts=True, sorted=False)\n",
    "\n",
    "        values, indices_of_indices = torch.topk( counts ,K_return) \n",
    "        ret_globale_indices = gloable_indices[indices_of_indices]\n",
    "    \n",
    "    elif pick_mode == 'class_balanced':\n",
    "        candidates = []\n",
    "        nr_features_valid = (y!=999).sum()\n",
    "        \n",
    "        for i in range(NC):\n",
    "            m = y==i\n",
    "            nr_features_valid_i = (y==i).sum()\n",
    "            \n",
    "            factor = float( nr_features_valid_i/nr_features_valid)\n",
    "            if i == NC-1:\n",
    "                _K = int(K_return-len(candidates))\n",
    "            else:\n",
    "                _K = int( K_return*factor )\n",
    "                \n",
    "            if _K > 0:\n",
    "                max_ele = metric[m].shape[0]\n",
    "                top_K = min(max_ele, _K+ len(candidates)+1)\n",
    "                \n",
    "                values, indices = torch.topk( metric[m] ,_K, \n",
    "                    largest = not most_dissimilar)\n",
    "                added = 0\n",
    "                for ele in gloable_indices_all[m][indices].tolist():\n",
    "                    if not ele in candidates and added < _K:\n",
    "                        added += 1\n",
    "                        candidates = candidates + [int(ele)]\n",
    "                \n",
    "        if len(candidates) > K_return:\n",
    "            candidates = candidates[:K_return]\n",
    "        \n",
    "        # select the globale_image_indicies that are selected most\n",
    "        ret_globale_indices = torch.tensor(candidates)\n",
    "        \n",
    "    return ret_globale_indices\n",
    "    \n",
    "ret_gloable_indices = get_image_indices(data, torch.range(0,data.shape[0]-1))\n",
    "classes = torch.zeros( (data.shape[1]) )\n",
    "for i in range(ret_gloable_indices.shape[0]):\n",
    "    idx = int( ret_gloable_indices[i] )\n",
    "    for n in range( data.shape[1] ):\n",
    "        if data[idx,n,:].sum() != 0:\n",
    "            classes[n] += 1\n",
    "plot_bar(classes.numpy(), sort=False, title='Buffer Label Dist class_balanced cos')\n",
    "\n",
    "ret_gloable_indices = get_image_indices(data, torch.range(0,data.shape[0]-1), pick_mode='most_hits')\n",
    "classes = torch.zeros( (data.shape[1]) )\n",
    "for i in range(ret_gloable_indices.shape[0]):\n",
    "    idx = int( ret_gloable_indices[i] )\n",
    "    for n in range( data.shape[1] ):\n",
    "        if data[idx,n,:].sum() != 0:\n",
    "            classes[n] += 1\n",
    "plot_bar(classes.numpy(), sort=False, title='Buffer Label Dist most_hits cos')\n",
    "\n",
    "\n",
    "classes = torch.zeros( (data.shape[1]) )\n",
    "for i in range(data.shape[0]):\n",
    "    idx = int(i)\n",
    "    for n in range( data.shape[1] ):\n",
    "        if data[idx,n,:].sum() != 0:\n",
    "            classes[n] += 1\n",
    "            \n",
    "plot_bar(classes.numpy(), sort=False, title='Task Label Dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = []\n",
    "yy = []\n",
    "\n",
    "image_idx = []\n",
    "\n",
    "#creates hierachical list of all feature vectors\n",
    "for ne in range(data.shape[1]):\n",
    "    classes = []\n",
    "    labels = []\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i,ne].sum() != 0:\n",
    "            image_idx.append( i )\n",
    "            classes.append( data[i,ne] )\n",
    "            labels.append(ne)\n",
    "    yy.append(labels)\n",
    "    print(len(classes))\n",
    "    elements.append( classes )\n",
    "\n",
    "len( image_idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the hierachical list\n",
    "\n",
    "ele = 0\n",
    "for e in elements:\n",
    "    ele += len(e)\n",
    "X = torch.zeros( (ele,128))\n",
    "y = torch.zeros( (ele) )\n",
    "\n",
    "s = 0\n",
    "for e in elements:\n",
    "    for i in e:\n",
    "        X[s] = i\n",
    "        s+=1 \n",
    "        \n",
    "s = 0\n",
    "for e in yy:\n",
    "    for i in e:\n",
    "        y[s] = i\n",
    "        s+=1 \n",
    "\n",
    "X = X.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X,y)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X_pca.shape, X_pca[y==0].shape\n",
    "\n",
    "X_pca[y==0].shape, y[y==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "\n",
    "N = 100\n",
    "r0 = 0.6\n",
    "col = ['r','b','g','y','r','b','g','y']\n",
    "ma = ['^','^','^','^','o','o','o','o']\n",
    "nr = 400\n",
    "for i in range(1):\n",
    "    if X_pca[y==i,0].shape[0] > nr:\n",
    "        plt.scatter(X_pca[y==i,0][:nr], X_pca[y==i,1][:nr], marker='^', c=col[i])\n",
    "    else:\n",
    "        plt.scatter(X_pca[y==i,0], X_pca[y==i,1], marker='^', c=col[i])\n",
    "        \n",
    "display( plt.show() )\n",
    "\n",
    "# K-Means : Track uncertainty of the samples in the buffer,Measuring overfitting and the perfomance on the buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centroids = np.zeros( (data.shape[1],data.shape[2]) )\n",
    "for i in range(data.shape[1]):\n",
    "    X_centroids[i] = X[y==i].mean(axis=0)\n",
    "    \n",
    "X_centroids [ np.isnan(X_centroids) ] = 0\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_centroids)\n",
    "X_centroids_pca = pca.transform(X_centroids)\n",
    "\n",
    "plt.scatter(X_centroids_pca[:,1], X_centroids_pca[:,2], marker='^', c=col)\n",
    "\n",
    "display( plt.show() )\n",
    "X_centroids_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "try:\n",
    "    y = torch.from_numpy( y ).type(torch.int64)\n",
    "    X_centroids = torch.from_numpy( X_centroids ).type(torch.float16)\n",
    "except:\n",
    "    pass\n",
    "accum = torch.zeros( (*X.shape), dtype=torch.float16 )\n",
    "\n",
    "#create the accum tensor with the same size as the full dataset filled with the centroids\n",
    "for cen in range(X_centroids.shape[0]):\n",
    "    m = y == cen\n",
    "    accum[ m,: ] =  X_centroids[cen][None,:].repeat(accum.shape[0],1)[m, :]\n",
    "\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "simil = cos(torch.from_numpy(X).type(torch.float32), accum.type(torch.float32))\n",
    "\n",
    "print(simil)\n",
    "K = 50\n",
    "image_idx = torch.tensor( image_idx )\n",
    "candidates = []\n",
    "for cen in range(X_centroids.shape[0]):\n",
    "    # take the minus for least similar samples\n",
    "    m = y==cen\n",
    "    values, indices = torch.topk( -simil[m] ,min(m.sum(), K)) \n",
    "    candidates += image_idx[m][indices].tolist()\n",
    "\n",
    "candidates = torch.tensor( candidates )\n",
    "indi, counts = torch.unique(candidates, return_counts=True, sorted=False)\n",
    "K_ = 50\n",
    "values, indices_of_indices = torch.topk( counts ,K_) \n",
    "final_results_of_image_indexes = indi[indices_of_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = y == cen \n",
    "torch.where(m)[0][0]\n",
    "accum[torch.where(m)[0][0]] - accum[torch.where(m)[0][100]] \n",
    "#LGTM\n",
    "accum.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNET_COLOR_MAP = {\n",
    "    0: (0.0, 0.0, 0.0),\n",
    "    1: (174.0, 199.0, 232.0),\n",
    "    2: (152.0, 223.0, 138.0),\n",
    "    3: (31.0, 119.0, 180.0),\n",
    "    4: (255.0, 187.0, 120.0),\n",
    "    5: (188.0, 189.0, 34.0),\n",
    "    6: (140.0, 86.0, 75.0),\n",
    "    7: (255.0, 152.0, 150.0),\n",
    "    8: (214.0, 39.0, 40.0),\n",
    "    9: (197.0, 176.0, 213.0),\n",
    "    10: (148.0, 103.0, 189.0),\n",
    "    11: (196.0, 156.0, 148.0),\n",
    "    12: (23.0, 190.0, 207.0),\n",
    "    14: (247.0, 182.0, 210.0),\n",
    "    15: (66.0, 188.0, 102.0),\n",
    "    16: (219.0, 219.0, 141.0),\n",
    "    17: (140.0, 57.0, 197.0),\n",
    "    18: (202.0, 185.0, 52.0),\n",
    "    19: (51.0, 176.0, 203.0),\n",
    "    20: (200.0, 54.0, 131.0),\n",
    "    21: (92.0, 193.0, 61.0),\n",
    "    22: (78.0, 71.0, 183.0),\n",
    "    23: (172.0, 114.0, 82.0),\n",
    "    24: (255.0, 127.0, 14.0),\n",
    "    25: (91.0, 163.0, 138.0),\n",
    "    26: (153.0, 98.0, 156.0),\n",
    "    27: (140.0, 153.0, 101.0),\n",
    "    28: (158.0, 218.0, 229.0),\n",
    "    29: (100.0, 125.0, 154.0),\n",
    "    30: (178.0, 127.0, 135.0),\n",
    "    31: (255.0, 0.0, 135.0),\n",
    "    32: (146.0, 111.0, 194.0),\n",
    "    33: (44.0, 160.0, 44.0),\n",
    "    34: (112.0, 128.0, 144.0),\n",
    "    35: (96.0, 207.0, 209.0),\n",
    "    36: (227.0, 119.0, 194.0),\n",
    "    37: (213.0, 92.0, 176.0),\n",
    "    38: (94.0, 106.0, 211.0),\n",
    "    39: (82.0, 84.0, 163.0),\n",
    "    40: (100.0, 85.0, 144.0),\n",
    "}\n",
    "col = np.array( [v for v in SCANNET_COLOR_MAP.values()] )/255\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track3",
   "language": "python",
   "name": "track3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
