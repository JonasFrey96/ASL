{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "from random import randint\n",
    "from torch.nn import functional as F\n",
    "\n",
    "__all__ = ['distribution_matching']\n",
    "\n",
    "def compute_metric(selected, features):\n",
    "    target_dist = features.sum(0).type(torch.float32)\n",
    "    target_dist = target_dist / target_dist.sum() #normalize\n",
    "\n",
    "    selected_dist = features[selected,:].sum(0).type(torch.float32)\n",
    "    selected_dist = selected_dist/ selected_dist.sum() #normalize\n",
    "\n",
    "    number = F.mse_loss( selected_dist, target_dist)\n",
    "    return number\n",
    "\n",
    "def distribution_matching(features, K_return=50, iterations= 1000, early_stopping = 0.00001):\n",
    "    \"\"\" returns k indexe from globale_indices such that the returned indexed match the total feature distribution the best\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : torch.tensor NRxC\n",
    "    K_return : int, optional\n",
    "            number of returned indices, by default 50\n",
    "    \"\"\"\n",
    "    indices = torch.arange( 0, features.shape[0] )\n",
    "    start_indices = torch.randperm( indices.shape[0] )[:K_return]\n",
    "    selected = torch.zeros( (indices.shape[0]), dtype=torch.bool)\n",
    "    for i in range(start_indices.shape[0]):\n",
    "        selected[start_indices[i]] = True\n",
    "        \n",
    "    \n",
    "    old_metric = compute_metric( selected, features)\n",
    "    for i in range(iterations):\n",
    "        if old_metric < early_stopping:\n",
    "            break\n",
    "        \n",
    "        current_selection = torch.where(selected)[0]\n",
    "        candidate = current_selection[randint(0,K_return-1)]\n",
    "\n",
    "        # get a new candidate sample\n",
    "        while True:\n",
    "            sample = randint(0,selected.shape[0]-1)\n",
    "            if sample not in current_selection:\n",
    "                break\n",
    "\n",
    "        selected[ candidate ] = False\n",
    "        selected[ sample ] = True\n",
    "        new_metric = compute_metric( selected, features)\n",
    "\n",
    "        if new_metric < old_metric:\n",
    "            # keep candidate change\n",
    "            old_metric = new_metric\n",
    "        else:\n",
    "            if random.random() < 0.05:\n",
    "                old_metric = new_metric\n",
    "            else:\n",
    "                selected[ candidate ] = True\n",
    "                selected[ sample ] = False\n",
    "        \n",
    "    return selected, old_metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    from PIL import Image\n",
    "    import os, sys\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    os.chdir('/home/jonfrey/ASL')\n",
    "    sys.path.append('/home/jonfrey/ASL')\n",
    "    sys.path.append('/home/jonfrey/ASL/src')\n",
    "    from visu import Visualizer\n",
    "    \n",
    "    vis = Visualizer('/home/jonfrey/tmp', logger=None, epoch=0, store=True, num_classes=41)\n",
    "\n",
    "    features = torch.load( '/media/scratch1/jonfrey/models/master_thesis/dev/uncertainty_integration3/labels_tensor_0.pt')\n",
    "    globale_indices = torch.load( '/media/scratch1/jonfrey/models/master_thesis/dev/uncertainty_integration3/indices_tensor_0.pt')\n",
    "\n",
    "    st = time.time()\n",
    "    selected, metric = distribution_matching(features)\n",
    "    selected_globale_indices = globale_indices[selected]\n",
    "    t =  time.time()-st\n",
    "    print(selected.sum(), metric, 'Total time',t)                 \n",
    "    # features = features_l.clone()\n",
    "    # globale_indices = globale_indices_l.clone()\n",
    "    # K_return=50\n",
    "    # print(new_metric)\n",
    "    \n",
    "    res = vis.plot_bar(features.sum(dim=0), x_label='Label', y_label='Count',\n",
    "            sort=False, reverse=True, title= 'All', \n",
    "            tag=f'Pixelwise_Class_Count_Task', method='left',jupyter=True)\n",
    "    display(Image.fromarray(res))\n",
    "\n",
    "\n",
    "    res = vis.plot_bar(features[selected,:].sum(dim=0), x_label='Label', y_label='Count',\n",
    "            sort=False, reverse=True, title= 'Selected',\n",
    "            tag=f'Pixelwise_Class_Count_Task', method='left',jupyter=True)\n",
    "\n",
    "    \n",
    "    display(Image.fromarray(res))\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "track3",
   "language": "python",
   "name": "track3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
