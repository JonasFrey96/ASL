{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag\n",
    "import rospy\n",
    "\n",
    "import yaml\n",
    "from rosbag.bag import Bag\n",
    "p = \"/home/jonfrey/Datasets/labdata/2021-06-17-17-56-33.bag\"\n",
    "with rosbag.Bag(p, 'r') as bag:\n",
    "    pass\n",
    "info_dict = yaml.load(Bag(p, 'r')._get_yaml_info())\n",
    "info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259abb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensor_msgs.msg import CameraInfo as RosCameraInfo\n",
    "camera_info = RosCameraInfo()\n",
    "camera_inf = RosCameraInfo()\n",
    "camera_inf.header.frame_id =\"2\"\n",
    "camera_info.header = camera_inf.header\n",
    "camera_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geometry_msgs  \n",
    "import sensor_msgs\n",
    "from sensor_msgs.msg import Image as RosImage\n",
    "from geometry_msgs.msg import Pose as RosPose\n",
    "import rosbag\n",
    "import rospy\n",
    "\n",
    "import cv2\n",
    "from sensor_msgs.msg import CameraInfo as RosCameraInfo\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy \n",
    "class KimeraAdapterNode():\n",
    "    def __init__(self):\n",
    "        rospy.init_node('kimera_adapter_node')\n",
    "        self.bridge = CvBridge()\n",
    "        self.pub_img = rospy.Publisher('/mono/image_raw', RosImage, queue_size=10)\n",
    "        self.pub_camera_info = rospy.Publisher('/mono/camera_info', RosImage, queue_size=10)\n",
    "        self.pub_pose = rospy.Publisher('/vicon/firefly_sbx/firefly_sbx', RosPose, queue_size=10)\n",
    "\n",
    "        rospy.Subscriber(\"/rgb/image_raw\", RosImage, self.callback_rgb)\n",
    "        rospy.Subscriber(\"/rgb/camera_info\", RosCameraInfo, self.callback_rgb_camera_info)\n",
    "        \n",
    "        self.map1, self.map2 = None, None\n",
    "        self.camera_info = None\n",
    "        \n",
    "        self.po = RosPose()\n",
    "        self.po.orientation.w = 1\n",
    "        self.r = rospy.Rate(10)\n",
    "        \n",
    "    def run(self):\n",
    "        print(\"Running\")\n",
    "        self.pub_pose.publish(self.po)\n",
    "        self.r.sleep()\n",
    "\n",
    "    \n",
    "    def callback_rgb(self,data):\n",
    "        rgb = self.bridge.imgmsg_to_cv2(data)\n",
    "        if not self.map1 is None:\n",
    "            rgb_undistorted = cv2.remap(rgb, self.map1, self.map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "            mono = cv2.cvtColor(rgb_undistorted, cv2.COLOR_BGR2GRAY)\n",
    "            mono_msg = self.bridge.cv2_to_imgmsg(mono)\n",
    "            display(Image.fromarray(mono))\n",
    "            mono_msg.header = data.header\n",
    "            self.pub_img.publish( mono_msg )\n",
    "        else:\n",
    "            print(\"Map not initalized\")\n",
    "    \n",
    "    def callback_rgb_camera_info(self, data):\n",
    "        \n",
    "        if self.camera_info is None:\n",
    "            self.camera_info = data\n",
    "            h,  w = data.height,data.width\n",
    "            K = np.array( data.K ).reshape(3,3)\n",
    "            D = np.array( data.D )\n",
    "            \n",
    "            new_K, validPixROI = cv2.getOptimalNewCameraMatrix( K, D[None,:],(w,h), alpha = 0)\n",
    "            self.map1, self.map2 = cv2.initUndistortRectifyMap( K , D[None,:], np.eye(3), new_K, (w,h) , cv2.CV_16SC2)\n",
    "            \n",
    "            self.camera_info.K = new_K.reshape(-1)\n",
    "            self.camera_info.D = D.fill(0)\n",
    "            self.camera_info.header = data.header\n",
    "            print(\"type(data)1\", type(data), type(self.camera_info))\n",
    "        \n",
    "            self.pub_camera_info.publish(copy.deepcopy( self.camera_info) ) \n",
    "            return\n",
    "        self.camera_info.header = data.header\n",
    "        print(\"type(data)\", type(data), type(self.camera_info))\n",
    "        \n",
    "        self.pub_camera_info.publish(copy.deepcopy( self.camera_info) ) \n",
    "        \n",
    "       \n",
    "        \n",
    "kan = KimeraAdapterNode()\n",
    "\n",
    "print(\"STARTED\", rospy.is_shutdown())\n",
    "while not rospy.is_shutdown():\n",
    "    kan.run()\n",
    "    print(\"Run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd0e00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef11265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensor_msgs.msg import CameraInfo as RosCameraInfo\n",
    "camera_info = RosCameraInfo()\n",
    "\n",
    "#camera_info.height = \n",
    "#camera_info.width =\n",
    "import numpy as np\n",
    "camera_info.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "RosImage\n",
    "dir(bridge)\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a654be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosimg = RosImage()\n",
    "dir(rosimg.serialize_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d703ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv_bridge import CvBridge\n",
    "bridge = CvBridge()\n",
    "\n",
    "with rosbag.Bag(p, 'r') as bag:\n",
    "    count = 0\n",
    "    max_counts = 1\n",
    "    image_topics = [t['topic'] for t in info_dict['topics'] if t['topic'].find('image') != -1]\n",
    "    \n",
    "    out = {}\n",
    "    for topic, msg, t in bag.read_messages( topics=image_topics ):\n",
    "        image = bridge.imgmsg_to_cv2(msg , desired_encoding='passthrough')\n",
    "        try:\n",
    "            out[topic].append(image)\n",
    "        except:\n",
    "            out[topic] = [image]\n",
    "        count += 1\n",
    "\n",
    "        if count > len(image_topics)*max_counts: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "out['/rgb/image_raw'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97da31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rosbag.Bag(p, 'r') as bag:\n",
    "    for topic, msg, t in bag.read_messages( topics=\"/points2\"):\n",
    "        print(topic, msg, t)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ros_numpy  # apt install ros-noetic-ros-numpy\n",
    "import rosbag\n",
    "import sensor_msgs\n",
    "\n",
    "def convert_pc_msg_to_np(pc_msg):\n",
    "    pc_msg.__class__ = sensor_msgs.msg._PointCloud2.PointCloud2\n",
    "    offset_sorted = {f.offset: f for f in pc_msg.fields}\n",
    "    pc_msg.fields = [f for (_, f) in sorted(offset_sorted.items())]\n",
    "\n",
    "    pc_np = ros_numpy.point_cloud2.pointcloud2_to_xyz_array(pc_msg, remove_nans=True)\n",
    "    return pc_np\n",
    "    \n",
    "pcd = convert_pc_msg_to_np( msg )\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_birds_eye(pcd,N_max = 1000):\n",
    "    data = np.random.permutation(pcd)[:1000,:]\n",
    "    x = data[:,0]\n",
    "    y = data[:, 1]\n",
    "    plt.scatter(x, y,s=4, alpha=1)\n",
    "    \n",
    "    plt.scatter(0, 0,c=\"r\", alpha=1)\n",
    "    plt.show()\n",
    "plot_birds_eye(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cefe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "to = [t['topic'] for t in info_dict['topics'] if t['topic'].find('image') != -1]\n",
    "to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "white = np.uint8( np.full((1080,50,3), 255 ))\n",
    "images = [out[k][-1] for k in  list(out.keys())[1:]]\n",
    "res = [images[0], white, images[1], white, images[2]]\n",
    "\n",
    "t = np.concatenate(res, axis=1)\n",
    "Image.fromarray( t )\n",
    "#     img = Image.fromarray( )\n",
    "#     display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if topic == \"/tf\" and msg.transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rosbag.Bag(p, 'r') as bag:\n",
    "    for topic, msg, t in bag.read_messages( topics=\"/rgb/camera_info\"):\n",
    "        topic= topic\n",
    "        msg = msg\n",
    "        t = t\n",
    "        print(topic, msg, t)\n",
    "        break\n",
    "\n",
    "K = np.array( msg.K ).reshape(3,3)\n",
    "D = np.array( msg.D )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "listener.allFramesAsDot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf\n",
    "# ROS and SCIPY use XYZW\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import rospy\n",
    "import numpy as np\n",
    "import rospy\n",
    "\n",
    "rospy.init_node('as')\n",
    "listener = tf.TransformListener()\n",
    "\n",
    "def get(a,b):\n",
    "    (trans,rot) = listener.lookupTransform(a,b, rospy.Time(0))\n",
    "    H = np.eye(4)\n",
    "    H[:3,:3] = R.from_quat(rot).as_matrix() \n",
    "    H[:3,3] = trans\n",
    "    print(trans)\n",
    "    return H\n",
    "\n",
    "try:\n",
    "    H_imu_rgb_lab = get('/pickelhaubeimu_link', \"/cam1\")\n",
    "    print(H_imu_rgb_lab)\n",
    "except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import os\n",
    "def replace(f, H):\n",
    "    #input file\n",
    "    fin = open(f, \"rt\")\n",
    "    #output file to write the result to\n",
    "    fout = open(\"out.yaml\", \"wt\")\n",
    "    #for each line in the input file\n",
    "    for line in fin:\n",
    "        if line.find(\"data\") != -1:\n",
    "            print( \"  data: \" + str(list(H.reshape(-1)) ) +'\\n')\n",
    "            fout.write(\"  data: \" + str(list(H.reshape(-1)) ) +'\\n')\n",
    "        else:\n",
    "            fout.write(line)\n",
    "    #close input and output files\n",
    "    fin.close()\n",
    "    fout.close()\n",
    "    os.system( f\"cp out.yaml {f}\")\n",
    "\n",
    "    \n",
    "def replace_K(f, K):\n",
    "    #input file\n",
    "    fin = open(f, \"rt\")\n",
    "    #output file to write the result to\n",
    "    fout = open(\"out.yaml\", \"wt\")\n",
    "    #for each line in the input file\n",
    "    for line in fin:\n",
    "        if line.find(\"intrinsics\") != -1:\n",
    "            print( \"intrinsics: \" + str([K[0,0],K[1,1],K[0,2],K[1,2]] ) +'\\n')\n",
    "            fout.write(\"intrinsics: \" + str([K[0,0],K[1,1],K[0,2],K[1,2]]) +'\\n')\n",
    "        else:\n",
    "            fout.write(line)\n",
    "    #close input and output files\n",
    "    fin.close()\n",
    "    fout.close()\n",
    "    os.system( f\"cp out.yaml {f}\")\n",
    "\n",
    "def replace_gen(f, data, tmp):\n",
    "    #input file\n",
    "    fin = open(f, \"rt\")\n",
    "    #output file to write the result to\n",
    "    fout = open(\"out.yaml\", \"wt\")\n",
    "    #for each line in the input file\n",
    "    for line in fin:\n",
    "        if line.find(tmp) != -1:\n",
    "            print( f\"{tmp}: \" + str(data) +'\\n')\n",
    "            fout.write(f\"{tmp}: \" + str(data) +'\\n')\n",
    "        else:\n",
    "            fout.write(line)\n",
    "    #close input and output files\n",
    "    fin.close()\n",
    "    fout.close()\n",
    "    os.system( f\"cp out.yaml {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c851328",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_kinect:\n",
    "    K = np.load ( \"/home/jonfrey/ASL/docker/vio/scripts/K_Kinect.npy\")\n",
    "    a = [1280, 720]\n",
    "else:\n",
    "    K = np.load ( \"/home/jonfrey/ASL/docker/vio/scripts/K_Cam1.npy\")\n",
    "    a = [1440, 700]\n",
    "    \n",
    "replace_gen(\"/home/jonfrey/ASL/docker/vio/params/labdata/RightCameraParams.yaml\",a,\"resolution\")\n",
    "replace_gen(\"/home/jonfrey/ASL/docker/vio/params/labdata/LeftCameraParams.yaml\",a,\"resolution\")\n",
    "replace_K('/home/jonfrey/ASL/docker/vio/params/labdata/RightCameraParams.yaml', K)\n",
    "replace_K('/home/jonfrey/ASL/docker/vio/params/labdata/LeftCameraParams.yaml', K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70646d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( R.from_quat( [-0.356063, 0.615575 ,0.612224, -0.345642]).as_matrix() )\n",
    "\n",
    "H_imu_rgb_lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_inv = False\n",
    "# trafo = R.from_euler(['x','z'],[-90,90], degrees=True).as_matrix() \n",
    "\n",
    "H_trafo = np.eye(4)\n",
    "# H_trafo[:3,:3] = trafo\n",
    "H_trafo_imu = np.eye(4)\n",
    "replace('/home/jonfrey/ASL/docker/vio/params/labdata/ImuParams.yaml',H_trafo_imu )\n",
    "l = H_imu_rgb_lab\n",
    "use_left = False\n",
    "if use_left:  \n",
    "    if use_inv:\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/LeftCameraParams.yaml',np.linalg.inv( l @ H_trafo) )\n",
    "        r = l\n",
    "        r[1,3] += 0.1\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/RightCameraParams.yaml',np.linalg.inv( r @ H_trafo))\n",
    "    else:\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/LeftCameraParams.yaml',l @ H_trafo )\n",
    "        r = l\n",
    "        r[1,3] += 0.1\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/RightCameraParams.yaml',r @ H_trafo)\n",
    "\n",
    "        \n",
    "else:\n",
    "    if use_inv:\n",
    "        l[1,3] -= 0.1\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/LeftCameraParams.yaml',np.linalg.inv( l @ H_trafo))\n",
    "        r = l\n",
    "        r[1,3] += 0.1\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/RightCameraParams.yaml',np.linalg.inv( r @ H_trafo))\n",
    "    else:            \n",
    "        l[1,3] -= 0.1\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/LeftCameraParams.yaml',l @ H_trafo)\n",
    "        r = l\n",
    "        r[1,3] += 0.1\n",
    "        replace('/home/jonfrey/ASL/docker/vio/params/labdata/RightCameraParams.yaml',r @ H_trafo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4b2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff929d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = H_imu_rgb\n",
    "new[:3,:3] = H_imu_rgb[:3,:3] # @ R.from_euler('zyx', [90, 0, 0], degrees=True).as_matrix()\n",
    "print( \"Left\", new.reshape(-1).tolist() ) \n",
    "\n",
    "new2 = new\n",
    "new2[1,3] += 0.1\n",
    "print(\"Right\", new2.reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_imu_rgb.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img = out['/rgb/image_raw'][0][:,:,:3]\n",
    "## OpenCV 4.4.0 !!!\n",
    "display(Image.fromarray(out['/rgb/image_raw'][0][:,:,:3]))\n",
    "h,  w = img.shape[:2]\n",
    "retval, validPixROI\t= cv2.getOptimalNewCameraMatrix(K ,D[None,:],(w,h), alpha = 0)\n",
    "map1, map2 = cv2.initUndistortRectifyMap( K , D[None,:], np.eye(3), new_K, (w,h) , cv2.CV_16SC2)\n",
    "\n",
    "undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT) # cv2.BORDER_CONSTANT cv2.BORDER_REFLECT\n",
    "display(Image.fromarray(undistorted_img))\n",
    "\n",
    "new_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN WRITE A ROS-NODE CHOOSE NEW KAMERA MATRIX AT THE START ALWAYS RECTIFY THE DEPTH AND LIVE IMAGE TO THE FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502dae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf28091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( \"new_K.npy\",new_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483862b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.load( \"new_K.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
