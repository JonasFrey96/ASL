name: test_functions2/metric_loss
offline_mode: false
timestamp: true
weights_restore: false
checkpoint_restore: false
checkpoint_load: template/hypersim/task0-epoch=46.ckpt
tramac_restore: false
lr: 0.003
tag_list:
  - mlhypersim
  - replay
  - single_gpu

# Experiment Settings
start_at_task: 0
max_tasks: 4
task_specific_early_stopping:
  patience: 20
  timelimit_in_min: 50
  verbose: True

teaching:
  active: False
  soft_labels: False
  soft_labels_weight: 10
  loss_function: MSE

latent_replay:
  # currently latent replay is the same as freezing the layers
  active: False
buffer:
  fill_after_fit: True
  mode: latent_feat # 'softmax_max', 'softmax_distance', 'loss'
    # 'latent_feat', 'distribution_matching' 
  distribution_matching_cfg:
    iterations: 1000
    early_stopping: 0.00001
  metric_cfg:
    use_highest_uncertainty: True
  latent_feat:
    get_image_cfg:
      dis_metric: cos
      K_aggregate: 50
      most_dissimilar: True
      pick_mode: class_balanced

  sync_back: True # if this is not ture the actual bins are not updated
  
replay_state_sync_back:
  active: true
  get_size_from_task_generator: true

# Standard Setting
lr_scheduler:
  active: true
  cfg:
    power: 0.9
    max_epochs: 1000
    target_lr: 1.0e-04
optimizer:
  name: ADAM
  sgd_cfg:
    momentum: 0.9
    weight_decay: 4.0e-05
trainer:
  precision: 16
  accumulate_grad_batches: 1
  fast_dev_run: false
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  progress_bar_refresh_rate: 1
  max_epochs: 1000
  gpus: -1
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 2
loader:
  pin_memory: true
  batch_size: 16
  shuffle: true
  num_workers: 16
visu:
  every_n_epochs: 1
  log_training_metric_every_n_epoch: 1
  train_images: 1
  val_images: 1
  test_images: 1
model:
  name: Fast-SCNN
  input_size: 384
  cfg:
    num_classes: 40
    aux: false
    extraction:
      active: false
      layer: 'learn_to_down'
  freeze:
    active: false
    mask:
      - true
      - true
      - false 
      - false

task_generator:
  total_tasks: 4
  mode: mlhypersim_random4_tests
  cfg_replay:
    bins: 4
    elements: 50
    add_p: 0.5
    replay_p: 0.5
    current_bin: 0
  replay_adaptive_add_p: True
  replay: True
  data_augmentation: True
  data_augmentation_for_replay: True

cb_early_stopping:
  active: false
  cfg:
    monitor: val_loss_epoch
    patience: 10000
    strict: true
    verbose: true
    mode: min
    min_delta: -0.0001
cb_checkpoint:
  nameing: 1
  cfg:
    verbose: true
    monitor: train_loss
    mode: min
    prefix: ''
    save_last: true
    save_top_k: 1
lr_monitor:
  cfg:
    logging_interval: step

move_datasets:
  # - env_var: coco
  - env_var: mlhypersim
